---
title: "Modellutvärdering"
editor_options: 
  chunk_output_type: console

---
<!-- New commands for matrices in regression -->
\newcommand{\Xmatrix}{\begin{bmatrix}1 & X_{11} & X_{12} & \cdots & X_{1k}\\1 & X_{21} & X_{22} & \cdots & X_{2k}\\\vdots & \vdots & \vdots & \ddots & \vdots\\1 & X_{n1} & X_{n2} & \cdots & X_{nk}\end{bmatrix}
}

\newcommand{\Xonematrix}{\begin{bmatrix}1 & X_{11}\\1 &X_{21}\\\vdots\\1 & X_{n1}\end{bmatrix}}

\newcommand{\Ymatrix}{\begin{bmatrix}Y_1\\Y_2\\\vdots\\Y_n\end{bmatrix}}

\newcommand{\betamatrix}{\begin{bmatrix}\beta_0\\\beta_1\\\vdots\\\beta_k\end{bmatrix}}

\newcommand{\betaonematrix}{\begin{bmatrix}\beta_0\\\beta_1\end{bmatrix}}

\newcommand{\Ematrix}{\begin{bmatrix}E_1\\E_2\\\vdots\\E_n\end{bmatrix}}

 <!-- Creates a shortcommand for sums -->
\newcommand{\Sum}[1]{\sum_{i=1}^#1}

<!-- CONTENT -->

::: {.video-container}
{{< video https://youtu.be/Nr-vtnNZk78 >}}
:::

Efter att vi har anpassat en modell baserat på iakttagelser från visualiseringar och beskrivande statistik har vi möjlighet att tolka det skattade sambandet mellan de förklarande variablerna och responsvariabeln, vilket vi också gjorde i @sec-model-fit-example. Det finns dock två aspekter som vi ännu inte funderat på; 

- vi kan inte anse att dessa tolkningar beskriver det sanna sambandet då vi ännu inte vet om modellen är lämplig,
- dessa tolkningar beskriver endast urvalet som samlats in, inte den population som vi vill dra slutsatser om.

För att kunna bedöma lämpligheten av modellen måste vi undersöka huruvida modellen uppfyller de antaganden som presenterades i @sec-model-assumptions genom *residualanalys* och slutsatser om populationen kan göras med hjälp av statistisk inferens. Vi börjar alltid med att undersöka modellens lämplighet eftersom inferensmetodernas beräkningar också förutsätter att dessa antaganden är uppfyllda. 

## Residualanalys {#sec-residual-simple}
Residualanalys innebär att beräkna och visuellt utforska residualerna från en modell gentemot modellantaganden $E\overset{iid}{\sim}N(0, \sigma^2)$, det vill säga att residualerna är oberoende, normalfördelade med väntevärde 0 och lika varians. Residualerna kan också användas för att undersöka ifall den linjära modell som anpassats är lämplig. Vi kommer titta närmare på mer detaljerad residualanalys i ett senare kapitel.

För enkelhetens skull kan vi plocka ut residualerna samt de observerade och skattade värdena på responsvariabeln från den skattade modellen (se @tip-lm-objects).

```{r}
#| code-fold: false

# Skapa ett datamaterial för visualiseringar

residualData <- 
  tibble(
    residuals = residuals(simpleModel),
    y = modelData$bill_length_mm,
    yHat = fitted(simpleModel)
  )
```

Vi kommer visualisera dessa variabler i olika former med hjälp av `ggplot2` vilket kräver att vi har en `data.frame` eller `tibble` med data.

### Normalfördelning
Vi kan undersöka antagandet om normalfördelade residualer genom ett histogram och ett QQ-diagram (**q**uantile-**q**uantile diagram).

```{r}
#| fig-cap: Residualernas fördelning
#| fig-height: 3
#| fig-width: 5 

ggplot(residualData) + 
  aes(x = residuals, y = after_stat(density)) +
  geom_histogram(binwidth = 1, fill = "steelblue", color = "black") + 
  theme_bw() + 
  labs(x = "Residualer", y = "Densitet")

```


```{r}
#| fig-cap: Residualernas observerade kvantiler jämfört med teoretiska normalfördelade kvantiler. 
#| fig-height: 3
#| fig-width: 5 


ggplot(residualData) + 
  # Använder standardiserade residualer
  aes(sample = scale(residuals)) + 
  geom_qq_line() +
  geom_qq(color = "steelblue") +
  theme_bw() + 
  labs(x = "Teoretiska kvantiler", y = "Observerade kvantiler")

```

```{r}
#| include: false
#| eval: false

  # Markerar potentiella extremvärden
  geom_mark_ellipse(
    aes(x = seq(0.5 / nrow(residualData), 1 - 0.5 / nrow(residualData), length = nrow(residualData)) %>% 
          as_tibble() %>% 
          slice_tail(n = 2) %>% 
          mutate(value = qnorm(value)) %>% unlist() %>% rev(), 
        y = scale(residuals, center = mean(residualData$residuals), scale = sd(residualData$residuals))
      ), 
    data = residualData %>% 
      arrange(residuals %>% desc()) %>% 
      slice_head(n = 2),
    color = "#d9230f",
    linewidth = 1, 
    expand = unit(2, "mm")
    )

```


I histogrammet vill vi se normalfördelningens symmetriska och klockliknande form centrerad kring 0 vilket ibland kan vara svårt att utläsa speciellt om datamaterialet är litet. QQ-diagrammet visar de observerade och de teoretiska kvantilerna där vi vill att punkterna ska följa den inritade linjen för en "perfekt" normalfördelning. 

För denna modell ser vi inga tydliga avvikelser från det mönster vi vill se, men vi kan utläsa ett fåtal avvikande observationer som skulle kunna betraktas som extremvärden. Två stora positiva residualer kan identifieras i  diagrammen men det finns även enstaka negativa som ligger långt från de övriga.

::: {.callout-important}
Vi kan betrakta antagandet om normalfördelning som inte uppfyllt om dessa diagram visar på starka avvikelser från det vi vill se. Även när vi vet att ett urval är draget från en normalfördelning är det inte alltid som histogrammet visar den form som vi söker.

```{r}
#| fig-cap: Fördelning av ett urval från den faktiska normalfördelningen
#| fig-height: 3
#| fig-width: 5 
set.seed(1234)

tibble(
  x = rnorm(30)
) %>% 
 ggplot() + 
  aes(x = x, y = after_stat(density)) +
  geom_histogram(bins = 10, fill = "steelblue", color = "black") + 
  theme_bw() + 
  labs(x = "x", y = "Densitet")

```

Starka avvikelser från normalfördelningen innebär exempelvis att vi ser flera områden med hög densitet:

```{r}
#| fig-cap: Fördelning av ett urval från andra fördelningar
#| fig-height: 3
#| fig-width: 5 
set.seed(1234)

tibble(
  x = runif(30)
) %>% 
 ggplot() + 
  aes(x = x, y = after_stat(density)) +
  geom_histogram(bins = 10, fill = "steelblue", color = "black") + 
  theme_bw() + 
  labs(x = "x", y = "Densitet")

```

eller en väldigt skev fördelning:

```{r}
#| fig-cap: Fördelning av ett urval från andra fördelningar
#| fig-height: 3
#| fig-width: 5
set.seed(1234)

tibble(
  x = rchisq(30, df = 2)
) %>% 
 ggplot() + 
  aes(x = x, y = after_stat(density)) +
  geom_histogram(bins = 10, fill = "steelblue", color = "black") + 
  theme_bw() + 
  labs(x = "x", y = "Densitet")
```

Dessa diagram indikerar att modellen saknar en förklarande variabel eller måste transformeras på något sätt för att uppfylla antagandet.

Om QQ-diagrammet uppvisar tydliga mönster, till exempel om punkterna är krökta runt linjen, betyder det att modellen inte uppfyller antagandet om linjärt samband.

```{r}
#| echo: false
#| fig-cap: Exempel på mönster i QQ-diagram
#| fig-height: 3
#| fig-width: 5 

data <- 
  tibble(
    x = seq(0, 10, by = 0.1),
    y = sin(x) + rnorm(n = 101, sd = 0.2)
  )

exModel <- lm(y ~ x, data = data)

ggplot(tibble(residuals = resid(exModel))) + 
  # Använder standardiserade residualer
  aes(sample = scale(residuals)) + 
  geom_qq_line() +
  geom_qq(color = "steelblue") +
  theme_bw() + 
  labs(x = "Teoretiska kvantiler", y = "Observerade kvantiler")

```
:::

### Lika varians
Vi kan kontrollera antagandet om residualernas lika varians genom ett spridningsdiagram med residualerna på y-axeln och någon av anpassade värden eller  observerade värden på förklarande eller responsvariabeln. Vanligtvis används de anpassade värdena för att x-axeln ska beskriva hela modellen, men andra variabler kan vara användbara att visualisera för att identifiera potentiella orsaker till ett brustet antagande.

```{r}
#| fig-cap: Residualernas spridning mot anpassade värden.
#| fig-height: 3
#| fig-width: 5
#| label: fig-ex-eq-var 

ggplot(residualData) + 
  aes(x = yHat, y = residuals) + 
  geom_point(color = "steelblue") + 
  theme_bw() +
  labs(x = "Anpassade värden", y = "Residualer") + 
  geom_hline(
    aes(yintercept = 0)
  ) + 
  # Imaginära gränser
  geom_hline(
    aes(yintercept = -5),
    color = "#d9230f",
    linetype = 2
  ) + 
  geom_hline(
    aes(yintercept = 5),
    color = "#d9230f",
    linetype = 2
  )


```

För att uppfylla antagandet om lika varians, ska punkterna i varje tvärsnitt av värden på x-axeln vara jämnt utspridda. Tänk som att vi vill placera två stycken parallella linjer längs med maximum och minimum-värden för residualerna (de två rödstreckade linjerna i @fig-ex-eq-var) och en stor majoritet av punkterna bör ligga utspridda emellan dessa. Vi ser i @fig-ex-eq-var att några enstaka observationer faktiskt hamnar utanför och ökar variationen i vissa tvärsnitt, men då det inte är tydliga avvikelser kan vi anse att residualerna har uppfyllt antagandet om lika varians.

::: {.callout-important}
Om linjerna som täcker maximum och minimum-värden för residualerna inte är parallella uppfyller inte modellen kravet om lika varians.

```{r}
#| fig-cap: Exempel på icke-konstant varians i residualerna
#| fig-height: 3
#| fig-width: 5 
#| echo: false


n <- 100

data <- 
  tibble(
    x = seq(1, 10, length.out = n),
    yInc = 3 * x + rnorm(n, sd = 0.5 * x),
    yDec = 3 * x + rnorm(n, sd = 5 / x),
    y2 = x^2 + rnorm(n, sd = 2)
  )

model1 <- lm(yInc ~ x, data = data)
model2 <- lm(yDec ~ x, data = data)
model3 <- lm(y2 ~ x, data = data)

ggplot(tibble(residuals = resid(model1), yHat = fitted(model1))) + 
  aes(x = yHat, y = residuals) + 
  geom_point(color = "steelblue") + 
  theme_bw() +
  labs(x = "Anpassade värden", y = "Residualer") + 
  geom_hline(
    aes(yintercept = 0)
  ) + 
  # Imaginära gränser
  geom_abline(
    slope = 0.35,
    intercept = 0,
    color = "#d9230f",
    linetype = 2
  ) + 
  geom_abline(
    slope = -0.35,
    intercept = 0,
    color = "#d9230f",
    linetype = 2
  ) 

ggplot(tibble(residuals = resid(model2), yHat = fitted(model2))) + 
  aes(x = yHat, y = residuals) + 
  geom_point(color = "steelblue") + 
  theme_bw() +
  labs(x = "Anpassade värden", y = "Residualer") + 
  geom_hline(
    aes(yintercept = 0)
  ) + 
  # Imaginära gränser
  geom_abline(
    slope = -0.15,
    intercept = 6,
    color = "#d9230f",
    linetype = 2
  ) + 
  geom_abline(
    slope = 0.15,
    intercept = -6,
    color = "#d9230f",
    linetype = 2
  )

```

Dessa fenomen betyder oftast att hela eller delar av modellen behöver transformeras för att uppfylla antagandet om lika varians. 

Vi kan också identifiera problem med linjäritet i detta spridningsdiagram. Figuren nedan uppvisar någorlunda konstant varians i avseende på variationen i varje tvärsnitt av x-axeln, men det finns ett tydligt mönster i residualerna. Detta betyder att modellen inte lyckats modellera sambandet på rätt sätt. I detta läge vore det lämpligt att visualisera residualerna mot respektive förklarande variabel för att identifiera vilken/vilka utav de som verkar bidra med det icke-linjära sambandet.

```{r}
#| fig-cap: Mönster i residualerna som tyder på ett icke-linjärt samband
#| fig-height: 3
#| fig-width: 5 
#| echo: false
#| message: false

ggplot(tibble(residuals = resid(model3), yHat = fitted(model3))) + 
  aes(x = yHat, y = residuals) + 
  geom_point(color = "steelblue") + 
  theme_bw() +
  labs(x = "Anpassade värden", y = "Residualer") + 
  geom_hline(
    aes(yintercept = 0)
  ) + 
  geom_smooth(aes(y = residuals + 0.45*sd(residuals)), method = "loess", se = FALSE, color = "#d9230f", linetype = 2, linewidth = 0.5) +
  geom_smooth(aes(y = residuals - 0.45*sd(residuals)), method = "loess", se = FALSE, color = "#d9230f", linetype = 2, linewidth = 0.5)

```
:::

### Oberoende
Ofta är det svårt eller omöjligt att undersöka om observationerna är oberoende med avseeende på alla ordningar som data kan samlas in på. Undantaget är ifall vi vet hur datainsamlingen har gått till och om det finns någon tydlig tidsaspekt, till exempel i tidsseriedata, eller att samma enhet har uppmätts flera gånger som gör att vi vet att observationerna blir beroende. Vi vill att den modell som anpassas tar hänsyn till det beroende som finns i data så att de efterföljande residualerna endast uppvisar oberoende. 

Ett linjediagram över residualerna i observationsordning kan användas för att undersöka oberoende, men det är som sagt endast i specialfall som denna visualisering används. Linjediagrammet ska uppvisa "slump", det vill säga inga tydliga mönster i residualerna.

```{r}
#| fig-cap: Residualer i observationsordning.
#| fig-height: 3
#| fig-width: 5 


ggplot(residualData) + 
  aes(x = 1:nrow(residualData), y = residuals) + 
  geom_line(color = "steelblue") + 
  theme_bw() +
  labs(x = "Obs. index", y = "Residualer") + 
  geom_hline(
    aes(yintercept = 0),
    color = "black"
  )

```

Andra exempel på data som har ett beroende är: 

- Vi samlar in data från personer, men vissa personer kommer ifrån samma famlij, detta kan göra att det finns ett beroende mellan dessa personer.
- Vi samlar in spatiala (rumsliga) data, till exempel temperatur eller regnmängd på olika platser i Östergötland. Då är det vanligt att det finns en positiv korrelation mellan geografiskt närliggande observationer.

### Funktion med alla diagram (`residualPlots`)
Dessa diagram kommer vara återkommande i regressionsmodellering så vi kan skapa en funktion för att automatiskt generera alla fyra diagram samtidigt. Vi får genom paketet `cowplot` tillgång till en funktion (`plot_grid`) som kan kombinera flera diagram till en och samma. 

```{r}
#| fig-cap: Residualdiagrammen i en och samma bild
#| fig-height: 3
#| fig-width: 5 
#| label: fig-penguin-resid


# Funktionen kräver två argument, modellen som anpassats och bredden på staplarna i histogrammet.
residualPlots <- function(model) {
  
  residualData <- 
    data.frame(
      residuals = residuals(model),
      # Responsvariabeln finns som första kolumn i modellens model-objekt
      y = model$model[,1],
      yHat = fitted(model)
    )
  
  
  p1 <- ggplot(residualData) + 
    aes(x = residuals, y = after_stat(density)) +
    geom_histogram(bins = 20, fill = "steelblue", color = "black") + 
    theme_bw() + 
    labs(x = "Residualer", y = "Densitet")
  
  p2 <- ggplot(residualData) + 
    aes(x = yHat, y = residuals) + 
    geom_hline(aes(yintercept = 0)) + 
    geom_point(color = "steelblue") + 
    theme_bw() +
    labs(x = "Anpassade värden", y = "Residualer")
    
  
  p3 <- ggplot(residualData) + 
    # Använder standardiserade residualer
    aes(sample = scale(residuals)) + 
    geom_qq_line() + 
    geom_qq(color = "steelblue") +
    theme_bw() + 
    labs(x= "Teoretiska kvantiler", y = "Observerade kvantiler")
  
  cowplot::plot_grid(p1, p2, p3, nrow = 2)
  
}

residualPlots(simpleModel)

```

Sammanfattningsvis visar @fig-penguin-resid att residualerna uppfyller antagandet om normalfördelning med väntevärde 0 och lika varians. Det finns inga tydliga mönster i något diagram som indikerar på motsatsen eller att modellen missar att plocka upp något av sambandet. Några enstaka extremvärden har identifierats, specifikt två stycken stora positiva residualer som kommer undersökas mer i senare kapitel. Slutsatsen är att modellen är en lämplig förenkling av verkligheten.

## Övningsuppgifter {#sec-exercise-evaluate}
Använd återigen `marketing` från @sec-exercise-explore.

1. Skatta residualerna genom att beräkna skillnaden mellan de observerade och anpassade värdena på responsvariabeln.

2. Skapa ett histogram och ett kvantildiagram (QQ diagram) över residualerna och kontrollera antagandet om normalfördelning.

3. Skapa ett spridningsdiagram med residualerna på y-axeln och de anpassade värdena på x-axeln och kontroller antagandet om lika varians.

4. Sammanfatta dina slutatser och bedöm om modellen som anpassats i @sec-exercise-model-fit uppfyller modellantaganden.

