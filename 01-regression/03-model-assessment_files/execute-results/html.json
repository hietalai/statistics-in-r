{
  "hash": "38b3a5fc5568736fbcabf99b6bb6c62d",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Regressionsmodellen\"\neditor_options: \n  chunk_output_type: console\n\n---\n\n<!-- Setup -->\n\n\n\n\n\n<!-- New commands for matrices in regression -->\n\\newcommand{\\Xmatrix}{\\begin{bmatrix}1 & X_{11} & X_{12} & \\cdots & X_{1k}\\\\1 & X_{21} & X_{22} & \\cdots & X_{2k}\\\\\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\1 & X_{n1} & X_{n2} & \\cdots & X_{nk}\\end{bmatrix}\n}\n\n\\newcommand{\\Xonematrix}{\\begin{bmatrix}1 & X_{11}\\\\1 &X_{21}\\\\\\vdots\\\\1 & X_{n1}\\end{bmatrix}}\n\n\\newcommand{\\Ymatrix}{\\begin{bmatrix}Y_1\\\\Y_2\\\\\\vdots\\\\Y_n\\end{bmatrix}}\n\n\\newcommand{\\betamatrix}{\\begin{bmatrix}\\beta_0\\\\\\beta_1\\\\\\vdots\\\\\\beta_k\\end{bmatrix}}\n\n\\newcommand{\\betaonematrix}{\\begin{bmatrix}\\beta_0\\\\\\beta_1\\end{bmatrix}}\n\n\\newcommand{\\Ematrix}{\\begin{bmatrix}E_1\\\\E_2\\\\\\vdots\\\\E_n\\end{bmatrix}}\n\n <!-- Creates a shortcommand for sums -->\n\\newcommand{\\Sum}[1]{\\sum_{i=1}^#1}\n\n<!-- CONTENT -->\n\nEfter att ha sammanställt iaktaggelser från visualiseringar och beskrivande statistik, är nästa steg i processen att bygga modellen. Oavsett om modellen innehåller en eller flera förklarande variabler behöver vi alltid ha i åtanke de fem antaganden som presenterades i @sec-modellantaganden. Det enklaste är att börja med de kvantitativa variablerna som (vanligtvis) endast kräver en term vardera i modellen.\n\n$$\n\\text{näbblängd} = \\beta_0 + \\beta_1 \\cdot \\text{kroppsvikt} + \\beta_2 \\cdot \\text{fenlängd} + \\beta_3 \\cdot \\text{näbbredd} + \\cdots + E\n$$ {#eq-penguin-quant}\n\n## Indikatorvariabler\nEn regressionsmodell kan inte hantera kvalitativa variabler direkt, exempelvis $\\beta_4 \\cdot \\text{art}$, då variabelns värden beskriver kategorier inte värden från en numerisk skala. Detta gäller även om den kvalitativa variabeln är kodad numerisk. En lutningsparameter beskriver den konstanta förändring i responsvariabeln när den tillhörande förklarande variabeln ökar med en enhet, men en kvalitativ variabel har oftast ingen enhet och inte heller konstanta förändringar mellan intilliggande värden. Istället måste vi transformera den kvalitativa variabeln numerisk genom *indikatorvariabler* (även kallad dummyvariabler). \n\nSom namnet antyder används indikatorvariabler för att indikera vilken kategori en observation har uppmätt på den kvalitativa variabeln. Vi behöver då skapa en begränsad mängd indikatorvariabler som på ett tydligt sätt visar exakt en kategori per observation. \n\nAnta att en kvalitativ variabel har 3 kategorier:\n$$\n\\begin{bmatrix}A\\\\B\\\\C\\end{bmatrix}\n$$\nVi kan börja med att skapa en indikatorvariabel för kategori A som antar värdet 1 om observationen har uppmätt kategorin, 0 annars:\n\n$$\n\\begin{bmatrix}A\\\\B\\\\C\\end{bmatrix} = \\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}\n$$\nMed endast en indikatorvariabel kan vi inte tydligt identifiera om en observation har uppmätt kategori B eller C då de båda har värdet 0, så vi lägger till ytterligare en indikator som antar värdet 1 om observationen uppmätt kategori B, 0 annars:\n\n$$\n\\begin{bmatrix}A\\\\B\\\\C\\end{bmatrix} = \\begin{bmatrix}1 & 0\\\\0 & 1\\\\0 & 0\\end{bmatrix}\n$$\nNu skulle det vara lätt att fortsätta, att skapa en indikatorvariabel även för den sista kategorin, men det behövs inte. Om båda indikatorvariablerna är 0 har vi lyckats identifiera att observationen uppmätt kategori C och ytterligare en variabel är bara onödig information. \n\nDen sista kategorin blir också vår *referenskategori*, den kategori som de andra indikatorvariablernas effekter tolkas gentemot. När vi tolkar lutningsparametrar för indikatorvariabler, till exempel indikatorvariabeln för A, mäts förändringen i $Y$ när $X = A$ jämfört med när $X = C$.\n\n::: {.callout-important}\nRent matematiskt kommer tre indikatorvariabler modellera ett perfekt samband och skapa problem med singularitet i beräkningarna.\n:::\n\nGenerellt skapas $\\text{antal kategorier} - 1$ indikatorvariabler för varje kvalitativa variabel som ska inkluderas i en regressionsmodell. Valet av referenskategori för respektive är godtyckligt, men vanligtvis används den första eller sista kategorin för detta ändamål.\n\nFör att slutföra modelleringen av @eq-penguin-quant ska vi inkludera Art och Kön i modellen. Då behöver vi skapa två respektive en indikatorvariabel enligt:\n\n\\begin{align*}\n  Gentoo &= \\begin{cases}\n            1 \\qquad \\text{om art Gentoo}\\\\\n            0 \\qquad \\text{annars}\n        \\end{cases}\\\\\n  Chinstrap &= \\begin{cases}\n      1 \\qquad \\text{om art Chinstrap}\\\\\n      0 \\qquad \\text{annars}\n  \\end{cases}\n\\end{align*}\n\noch \n\n\\begin{align*}\n  hane &= \\begin{cases}\n            1 \\qquad \\text{om hane}\\\\\n            0 \\qquad \\text{annars}\n        \\end{cases}\n\\end{align*}\n\nför att till slut skapa följande modell:\n\n$$\n\\text{näbblängd} = \\beta_0 + \\beta_1 \\cdot \\text{kroppsvikt} + \\beta_2 \\cdot \\text{fenlängd} + \\beta_3 \\cdot \\text{näbbredd} + \\beta_4 \\cdot \\text{Gentoo} + \\beta_5 \\cdot \\text{Chinstrap} + \\beta_6 \\cdot \\text{hane} + E\n$$ {#eq-penguin-full-simple}\n\ndär Adelie och honor agerar referenskategori för respektive kvalitativ variabel. \n\n## Modellanpassning\n@eq-penguin-full-simple visar den sanna modell som utgår ifrån populationens alla observerade värden, men nästintill alla undersökningar utgår från någon form av urval. Även en totalundersökning under en viss period kan anses vara ett urval i tiden om modellen avses att användas efter undersökningsperioden är slutförd.\n\nVi kan beteckna den anpassade modellen med dess skattade parametrar enligt:\n\n$$\n\\hat{y}_i = b_0 + b_1 \\cdot x_{1i} + b_2 \\cdot x_{2i} + b_3 \\cdot x_{3i} + b_4 \\cdot x_{4i} + b_5 \\cdot x_{5i} + b_6 \\cdot x_{6i}\n$$ {#eq-penguin-est-simple}\ndär\n\\begin{align*}\n  \\hat{y}_i &= \\text{responsvariabelns skattade värde för observation i}\\\\\n  b_0 &= \\text{skattning av interceptet}\\\\\n  b_1 - b_6 &= \\text{skattning av lutningsparametrar}\n\\end{align*}\n\n::: {.callout-note}\nViss litteratur använder $\\hat{\\beta}$ som beteckning för skattade parametrar.\n:::\n\nModellen anpassas med hjälp av *minsta kvadratskattningen* (eng. **O**rdinary **L**east **S**quares, OLS), där syftet är att minimera modellens totala fel. Vi kan notera att @eq-penguin-est-simple saknar feltermen $E$ som inkluderas tidigare, vilket kommer från att den anpassade modellen endast består av regressionslinjen. Kom ihåg att en regressionsmodell ämnar att ge en förenkling av verkligheten. Men $E$ beskrev ju felet i modellen och om vi ska minimera det totala felet behöver vi på något sätt ta hänsyn till denna term i modellanpassningen.\n\nAnta att vi anpassar en modell enbart på kroppsvikt och näbblängd. Om vi skulle projicera den anpassade enkla linjära modellen i ett spridningsdiagram över de två variablerna (@fig-reg-errors) skulle linjen inte lyckas träffa alla punkter exakt, varje enskilda observation kommer ligga ett visst avstånd från regressionslinjen. Detta avstånd är observationens *residual* som betecknas med $e_i$.\n\n\n::: {.cell}\n::: {.cell-output-display}\n![Visualisering av regressionsmodellens residualer](03-model-assessment_files/figure-html/fig-reg-errors-1.png){#fig-reg-errors width=480}\n:::\n:::\n\n\nMatematiskt beräknar vi $e_i = Y_i - \\hat{Y}_i$, där $Y_i$ är det observerade värdet (punkten) och $\\hat{Y}_i$ är modellens anpassade värde (linjen). Minsta kvadratskattningen beräknar modellens alla parametrar så att det totala felet (**S**um of **S**quares of **E**rror, SSE) för alla residualer blir så litet som möjligt. \n\n$$\nSSE = \\sum_{i = 1}^n e_i^2 = \\sum_{i = 1}^n (Y_i - \\hat{Y}_i)^2\n$$ {#eq-sse}\n\nI en enkel linjär regression går det att härleda fram analytiska lösningar för de två parameterskattningarna, $b_0$ och $b_1$, som minimerar SSE men så fort vi inkluderar flera variabler blir detta betydligt svårare. Istället förlitar vi (och R) oss på matrisberäkningar som presenteras mer i @sec-matrices.\n\n::: {.callout-important}\nFormler för parameterskattningarna i en enkel linjär regression är:\n\\begin{align*}\n  b_1 &= \\frac{\\Sum{n}(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\Sum{n}(X_i - \\bar{X})^2} \\\\\n  b_0 &= \\bar{Y} - b_1 \\cdot \\bar{X}\n\\end{align*}\n:::\n\n### Modellanpassning i R\nFör att anpassa en linjär regressionsmodell i R används funktionen `lm()` med följande argument: \n\n- `formula`: modellens struktur som ett formelobjekt\n- `data`: datamaterialet som variablerna hittas\n\nEtt formelobjekt är ett speciellt format som R använder för att beskriva relationen mellan variabler. Generellt anges formatet som `y ~ x` där `x` består utav de olika förklarande variablerna, till exempel `bill_length_mm ~ body_mass_g + bill_depth_mm`. Det finns ett kortkommando (`~ .`) som används i exemplet nedan, där alla övriga variabler inkluderas i högerledet , men det kräver att vi först har ett datamaterial enbart bestående av de förklarande variablerna från @eq-penguin-full-simple. \n\nVi måste också se till att alla variabler i datamaterialet har rätt variabeltyp som vi förväntar oss. Vi identifierade i @sec-example-data att vi hade tre kvantitativa variabler och två kvalitativa variabler som i R motsvarar typerna `numeric` och `Factor`. Att använda sig av `Factor` underlättar transformationen till indikatorvariabler eftersom R vet att transformationen är nödvändig för att modellen ska fungera korrekt. Om de kvalitativa variablerna var av typen `character` eller kodad `numeric` är det inte säkert att R skapar indikatorvariabler och tolkningar av denna variabels effekt kan bli väldigt missvisande. Vi kan undersöka variabeltyperna för `penguins` med hjälp av `str()`.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code  code-fold=\"false\"}\n# Tar endast med de variabler som vi ansåg ha ett samband med responsvariabeln\nmodelData <- \n  penguins %>% \n  select(\n    bill_length_mm,\n    body_mass_g,\n    flipper_length_mm,\n    bill_depth_mm,\n    species,\n    sex\n  )\n\n# Anpassar angiven modell\nmodel <- lm(formula = bill_length_mm ~ ., data = modelData)\n```\n:::\n\n\nMed `summary()` får vi en detaljerad utskrift för modellen som inkluderar de anpassade *regressionskoefficienterna*. Vid presentation av en sådan utskrift kan vi använda `kable()` eller `xtable()` för att få en snyggare utskrift.\n\n::: {#fig-reg-summary-bad}\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n\nCall:\nlm(formula = bill_length_mm ~ ., data = modelData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.3939 -1.3424 -0.0421  1.2695 11.4274 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(>|t|)    \n(Intercept)       1.502e+01  4.374e+00   3.433 0.000674 ***\nbody_mass_g       1.084e-03  4.231e-04   2.562 0.010864 *  \nflipper_length_mm 6.856e-02  2.315e-02   2.961 0.003293 ** \nbill_depth_mm     3.130e-01  1.541e-01   2.032 0.043000 *  \nspeciesChinstrap  9.566e+00  3.497e-01  27.351  < 2e-16 ***\nspeciesGentoo     6.404e+00  1.030e+00   6.215 1.56e-09 ***\nsexmale           2.030e+00  3.892e-01   5.215 3.27e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.217 on 326 degrees of freedom\nMultiple R-squared:  0.8386,\tAdjusted R-squared:  0.8356 \nF-statistic: 282.3 on 6 and 326 DF,  p-value: < 2.2e-16\n```\n\n\n:::\n:::\n\nInte särskilt snygg utskrift\n:::\n\n\n\n::: {#tbl-reg-summary-good .cell .tbl-cap-location-top tbl-cap='En snygg utskrift av modellens anpassade parametrar'}\n\n```{.r .cell-code}\nsummary(model) %>% \n  coef() %>% \n  as_tibble(rownames = NA) %>% \n  rownames_to_column() %>% \n  rename(\n    ` ` = rowname,\n    Skattning = Estimate,\n    Medelfel = `Std. Error`,\n    `t-värde` = `t value`,\n    `p-värde` = `Pr(>|t|)`\n  ) %>% \n  kable(\n    digits = 4\n  ) %>% \n  kable_styling(\"striped\")\n```\n\n::: {.cell-output-display}\n`````{=html}\n<table class=\"table table-striped\" style=\"margin-left: auto; margin-right: auto;\">\n <thead>\n  <tr>\n   <th style=\"text-align:left;\">  </th>\n   <th style=\"text-align:right;\"> Skattning </th>\n   <th style=\"text-align:right;\"> Medelfel </th>\n   <th style=\"text-align:right;\"> t-värde </th>\n   <th style=\"text-align:right;\"> p-värde </th>\n  </tr>\n </thead>\n<tbody>\n  <tr>\n   <td style=\"text-align:left;\"> (Intercept) </td>\n   <td style=\"text-align:right;\"> 15.0166 </td>\n   <td style=\"text-align:right;\"> 4.3742 </td>\n   <td style=\"text-align:right;\"> 3.4330 </td>\n   <td style=\"text-align:right;\"> 0.0007 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> body_mass_g </td>\n   <td style=\"text-align:right;\"> 0.0011 </td>\n   <td style=\"text-align:right;\"> 0.0004 </td>\n   <td style=\"text-align:right;\"> 2.5617 </td>\n   <td style=\"text-align:right;\"> 0.0109 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> flipper_length_mm </td>\n   <td style=\"text-align:right;\"> 0.0686 </td>\n   <td style=\"text-align:right;\"> 0.0232 </td>\n   <td style=\"text-align:right;\"> 2.9608 </td>\n   <td style=\"text-align:right;\"> 0.0033 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> bill_depth_mm </td>\n   <td style=\"text-align:right;\"> 0.3130 </td>\n   <td style=\"text-align:right;\"> 0.1541 </td>\n   <td style=\"text-align:right;\"> 2.0316 </td>\n   <td style=\"text-align:right;\"> 0.0430 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> speciesChinstrap </td>\n   <td style=\"text-align:right;\"> 9.5655 </td>\n   <td style=\"text-align:right;\"> 0.3497 </td>\n   <td style=\"text-align:right;\"> 27.3508 </td>\n   <td style=\"text-align:right;\"> 0.0000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> speciesGentoo </td>\n   <td style=\"text-align:right;\"> 6.4044 </td>\n   <td style=\"text-align:right;\"> 1.0304 </td>\n   <td style=\"text-align:right;\"> 6.2154 </td>\n   <td style=\"text-align:right;\"> 0.0000 </td>\n  </tr>\n  <tr>\n   <td style=\"text-align:left;\"> sexmale </td>\n   <td style=\"text-align:right;\"> 2.0297 </td>\n   <td style=\"text-align:right;\"> 0.3892 </td>\n   <td style=\"text-align:right;\"> 5.2153 </td>\n   <td style=\"text-align:right;\"> 0.0000 </td>\n  </tr>\n</tbody>\n</table>\n\n`````\n:::\n:::\n\n\n::: {.callout-tip}\nFör att skapa denna snygga utskrift av koefficienterna behöver vi plocka ut en enskild del av `summary()` med hjälp av `coef()`. I dokumentationen för `lm()` finns mer information om vad som kan hämtas från det resulterande regressionsobjektet. \n\nR är ett objektorienterat programmeringsspråk, och funktionen lm() returnerar ett objekt av klassen ”lm”, vilket är en lista. Det är enkelt att plocka önskade delar från den listan vid behov. Det finns en mängd funktioner kopplade till objekt av klassen ”lm”: \n\n- `coef()`: Ger regressionskoefficienter\n- `residuals()`: Ger residualerna\n- `fitted()`: Ger de anpassade värdena ($\\hat{Y}$)\n- `summary()`: Ger en sammanfattande analys av regressionsmodellen. Funktionen returnerar ett objekt\nav klassen ”summary.lm”. Se `?summary.lm` i dokumentationen. coef() funkar även på dessa objekt som vi såg ovan.\n- `anova()`: Ger ANOVA-tabellen för modellen\n- `predict()`: gör prediktioner för (nya) x-värden, alltså beräknar $\\hat{Y}$ för givna x-värden. Kan även\nberäkna konfidensintervall och prediktionsintervall för $\\hat{Y}$. Se `?predict.lm()` för detaljer.\n- `plot()`: Ger olika diagnostiska plottar, se `?plot.lm` för detaljer.\n- `confint()`: Beräknar konfidensintervall för regressionskoefficienterna\n- `model.matrix()`: skapar olika typer av designmatriser som kan användas i `lm()`, se @sec-matrices.\n\nDet är också användbart att använda `str()` på lm-objekt. Kolla i `?lm()` under Value rubriken för att se vilka olika delar som finns i objektet.\n:::\n\n@tbl-reg-summary-good visar de skattade lutningsparametrarna (koefficienterna). Exempelvis kan vi se att för varje gram mer en pingvin väger ökar näbbens längd med ca 0.0011 mm i genomsnitt **givet att alla andra variabler hålls konstanta**. Den sista delen av denna tolkning är viktig att inkludera då en förändring av flera variabler skulle medföra en annan förändring av responsvariabeln i relation till respektive koefficient. \n\nIndikatorvariablerna tolkas inom sin grupp jämfört med referenskategorin, till exempel har Gentoo-pingviner i genomsnitt en 6.4 mm större näbblängd än referenskategorin Adelie-pingviner givet att alla andra variabler hålls konstanta.\n\nInterceptet är endast relevant att tolka om *värdemängden* är alla 0, det vill säga att data täcker det område där alla förklarande variabler antar värdet 0. I just detta exempel finns det inte data över dessa områden vilket medför att värdet på interceptet inte har någon rimlig tolkning. \n\n::: {.callout-important}\nÄven om tolkningen av interceptet inte blir rimlig **måste** interceptet inkluderas i modellanpassningen för att minsta kvadratskattningen ska minimera SSE. Om interceptet hade plockats bort motsvarar det en linje som tvingas att korsa y-axeln vid $y = 0$ vilket resulterar i att modellen inte beskriver de fenomen som vi vill att den ska beskriva.\n:::\n\nDet är inte bara koefficienttabellen som är relevant att titta på i en modellanpassning och vi kommer tillbaka till de andra objekten som finns inuti `lm` i senare kapitel.\n\n## Matrisberäkningar {#sec-matrices}\nAtt använda sig av matriser underlättar oerhört de tunga beräkningar som krävs för att anpassa en regressionsmodell med flera förklarande variabler. \n\nVi kan också formulera en regressionsmodell i matrisform:\n$$\n\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{E}\n$$\ndär, \n$$\n    \\mathbf{Y} = \\underset{n \\times 1}{\\Ymatrix} \\quad \\mathbf{X} = \\underset{n \\times p}{\\Xmatrix} \\quad \\boldsymbol{\\beta} = \\underset{p \\times 1}{\\betamatrix} \\quad \\mathbf{E} = \\underset{n \\times 1} {\\Ematrix}\n$$\n$\\mathbf{X}$ kallas för *designmatrisen* och innehåller alla $k$ förklarande variabler, en kolumn för varje, samt en första kolumn med 1:or som motsvarar interceptet. Indikatorvariabler adderar till antalet förklarande variabler trots att de utgår ifrån samma kvalitativa variabel, se @eq-penguin-full-simple där vi totalt har 6 förklarande variabler.\n\n$p$ beskriver antalet parametrar som motsvarar $k + 1$, antalet lutningsparametrar och interceptet.\n\n$n$ är antalet observationer.\n\n\n\n\n\n\n## Matriser i R\n\nAlla datorprogram, inklusive R, använder sig av matriser för att \n\n \n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel.matrix(bill_length_mm ~ ., data = penguins %>% select(!c(island, year))) %>% \nas_tibble() %>% \nslice_head(n = 5) %>% \nkable()\n```\n\n::: {.cell-output-display}\n\n\n| (Intercept)| speciesChinstrap| speciesGentoo| bill_depth_mm| flipper_length_mm| body_mass_g| sexmale|\n|-----------:|----------------:|-------------:|-------------:|-----------------:|-----------:|-------:|\n|           1|                0|             0|          18.7|               181|        3750|       1|\n|           1|                0|             0|          17.4|               186|        3800|       0|\n|           1|                0|             0|          18.0|               195|        3250|       0|\n|           1|                0|             0|          19.3|               193|        3450|       0|\n|           1|                0|             0|          20.6|               190|        3650|       1|\n\n\n:::\n:::\n",
    "supporting": [
      "03-model-assessment_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<script src=\"../site_libs/kePrint-0.0.1/kePrint.js\"></script>\n<link href=\"../site_libs/lightable-0.0.1/lightable.css\" rel=\"stylesheet\" />\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}