[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Statistisk teori och tillämpningar i R",
    "section": "",
    "text": "Inledning\nOm du har några kommentarer, synpunkter eller vill meddela något fel? Maila mig på isak.hietala@liu.se.",
    "crumbs": [
      "Programmering i R",
      "Inledning"
    ]
  },
  {
    "objectID": "00-programming/00-basics-R.html",
    "href": "00-programming/00-basics-R.html",
    "title": "Grunderna i R",
    "section": "",
    "text": "Introduktion\nR är ett så kallat open-source programmeringsspråk. Open-source betyder att programmet är gratis att ladda ner och använda, samt att vem som helst har möjlighet att skapa egna, skräddarsydda metoder eller analyser som enkelt kan delas med omvärlden. R har använts av statistiker och analytiker i mer än 20 års tid och många bidrag har byggt upp ett starkt och flexibelt verktyg som kan anpassas för många ändamål.\nR kännetecknas av sina paket med funktioner som vi kan använda för att genomföra olika operationer. Vi kan se på funktionerna som olika verktyg ämnade att lösa specifika problem, till exempel om vi vill slå in en spik i en bräda kan vi använda en hammare, och paketen som olika verktygslådor fokuserade på att genomföra en viss form utav arbete. När vi installerar R för första gången får vi tillgång till en stor mängd olika paket, men vi har möjligheten att utöka dessa väldigt enkelt. Vem som helst skapa funktioner och paket för allmänheten och ibland finns det ett behov av att ladda ner nya paket (motsv. köpa in nya verktygslådor) för att genomföra en viss sorts analys.\nDet finns flertalet gränssnitt som hjälper till att programmera med R, men vi rekommenderar att använda RStudio. Detta visuella gränssnitt medför att vi inte behöver programmera med en kommandotolk. För att installera R och RStudio kan du följa instruktionerna här. Detta underlag är skapad med R version 4.5.1 (2025-06-13 ucrt).",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Grunderna i R"
    ]
  },
  {
    "objectID": "00-programming/00-basics-R.html#introduktion",
    "href": "00-programming/00-basics-R.html#introduktion",
    "title": "Grunderna i R",
    "section": "",
    "text": "Viktigt\n\n\n\nNär vi programmerar i R, sparas objekt som vi skapar i datorns arbetsminne (RAM-minne). Arbetsminnet kan vi säga motsvarar ett korttidsminne, vilket innebär att vi har ett mindre utrymme att arbeta med än datorns hårddisk och information finns endast där temporärt. När vi startar upp R börjar vi en session som avslutas när vi stänger ner programmet. Vi kan spara objekt för att använda de senare i samma session, men dessa rensas när vi stänger ner programmet. Om vi vill använda objekt mellan sessioner kan vi spara ner information till datorns hårddisk, eller dess långtidsminne, på några olika sätt.\n\n\n\nStarta RStudio\nNär vi startar RStudio för första gången, delas programmet in i tre olika fönster. Det är starkt rekommenderat att alltid börja med att öppna eller skapa ett dokument där kod sparas (även kallad ett R Script eller skript) genom File -&gt; New file -&gt; R Script (eller kortkommandot Ctrl el. Command + Shift + N). När detta skript öppnas delas RStudio in i fyra olika fönster. Ett skript har ändelsen .R men är i grunden en textfil och kan öppnas i alla enkla texthanterare, t.ex. Notepad, om vi vill redigera koden utanför R eller RStudio.\n\nKort genomgång av RStudio\nNär ett skript skapats innehåller nu det övre vänstra fönstret denna fil. Här kan vi skriva kod som kan sparas ned och användas igen nästa gång vi öppnar programmet. Skriptet kan också skickas mellan datorer och är ett bra sätt att kunna dela med sig utav vad det är man jobbar med. Det rekommenderas starkt att alltid skriva kod i ett skript för att ha möjligheten att återanvända och redigera koden på ett lätt sätt.\nDet nedre vänstra fönstret innehåller en konsol. Här visas all kod som vi kör och tillhörande utskrifter och vi kan också skriva kod direkt i konsollen. Det som skiljer användandet av konsollen med ett skript är att all kod som vi skriver i konsollen inte sparas någonstans och kommer försvinna nästa gång vi startar upp programmet. Det är också svårt att redigera kod, till exempel om man gjort något stavfel eller måste revidera kod som man skrivit för länge sedan.\nI det nedre högra fönstret kan vi se olika flikar som visar filer från datorn, skapade visualiseringar, en översikt av de paket som vi har tillgängliga, samt få hjälp om olika funktioner i hjälpdokumentationen. Paket i R har inbyggda hjälpfiler som kan underlätta förståelsen av vad en funktion gör, hur den arbetar, vad den behöver för att köras med mera. Det rekommenderas att alltid börja med att titta i dokumentationen för en funktion om man är osäker på vad det är den gör.\nDet övre högra fönstret innehåller en översikt av alla objekt som vi skapar under en session och som R lagrar i korttidsminnet. Objekten som vi ser i RStudios Environment-flik kan vi klicka på för att antingen få mer detaljer om objektet, exempelvis hur stort ett visst objekt är eller om den innehåller fler delobjekt.\nVi kommer återkomma till dessa olika fönster senare i underlaget.\n\n\n\nR kod i underlaget\nI detta underlag kommer kodexempel (ljus bakgrund) visas som du kan kopiera till din egna dator. En knapp finns överst i det högra hörnet som kopierar allt innehåll i kodblocket. Från exemplena visas också utskrifter (mörk bakgrund) från koden som vi i RStudio ser i konsollen.\n\n\nVisa kod\n# Exempelkod som kan kopieras med en knapp i det övra högra hörnet.\n\n\n\n\nUtskrift från koder.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Grunderna i R"
    ]
  },
  {
    "objectID": "00-programming/00-basics-R.html#sec-basics-R",
    "href": "00-programming/00-basics-R.html#sec-basics-R",
    "title": "Grunderna i R",
    "section": "Grundläggande programmering i R",
    "text": "Grundläggande programmering i R\nR är ett kraftfullt språk som kan genomföra väldigt komplexa och avancerade beräkningar. Innan vi kommer dit måste vi första börja med grunderna i R och en utav de vanligaste användningsområdena för R är att använda språket som en vanlig miniräknare. R kommer läsa varje rad kod som en enskild operation och vi kan köra kod på flera olika sätt.\nVi kan antingen använda knappen uppe till höger av skriptet som heter Run eller använda kortkommandot Ctrl el. Command + Enter för att köra enstaka rader kod. R kan också köra flera rader kod samtidigt om vi markerar flera rader och klickar på Run eller använder kortkommandot.\n\nR som miniräknare\nTill att börja med kan vi använda matematiska operatorer såsom +, -, *, och /.\n\n\nVisa kod\n## Addition\n2 + 3\n\n\n[1] 5\n\n\nVisa kod\n## Subtraktion\n5 - 2\n\n\n[1] 3\n\n\nVisa kod\n## Multiplikation\n4 * 5\n\n\n[1] 20\n\n\nVisa kod\n## Division\n20 / 4\n\n\n[1] 5\n\n\nR kommer genomföra dessa operationer mellan siffrorna och skriva ut svaret i konsollen. De vanliga räknereglerna för matematiska operatorer gäller här vilket innebär att t.ex. kommer:\n\n\nVisa kod\n## Räkneregler\n1 + 2 * 3\n\n\n[1] 7\n\n\ngenerera ett annorlunda svar än:\n\n\nVisa kod\n## Räkneregler forts.\n(1 + 2) * 3\n\n\n[1] 9\n\n\n\nKommentarer i koden\nI ovanstående kodexempel ser vi också något speciellt. Om du kopierar all text från ett utav blocken och kör den på egen hand, kommer R endast skriva ut resultat från raden som inte innehåller #. En rad som börjar med # kommer R istället läsa som en kommentar. Detta medför att vi kan kommentera kod som vi skriver vilket har många fördelar.\nDels kan vi i anslutning till specifika bitar kod själva beskriva vad koden gör och vad för resultat som vi förväntar oss att få. Det är väldigt lätt att man i ett stort skript tappar bort sig själv, eller när man öppnar skriptet vid nästa session har glömt bort vad det är koden gör. Med kommentarer kan vi lättare komma ihåg vad de olika delarna gör, men framförallt om vi skickar koden till någon annan kan vi skicka med tillhörande instruktioner så att det blir lättare att följa vad det är som händer. Försök att få in en rutin att kommentera kod som du skriver redan från början!\n\n\n\nObjekt och dess typer\nI tidigare exempel kommer svaret på beräkningarna endast skrivas ut i konsollen, men om vi hade varit intresserade av att spara ner informationen och använda den senare behöver vi specifikt säga till R att göra det.\nVi kan spara resultat av en operation till ett objekt med hjälp av &lt;-. När vi vill ge ett objekt ett värde är det praxis att använda &lt;- och vi kan skriva detta som en kombination av symbolerna, &lt; och -. Vi kan läsa det som ’‘ett värde ges till objektet i pilens riktning’’.\nObjekt kan heta nästintill vadsomhelst men vi måste förhålla oss till ett par begränsningar:\n\nett objektnamn kan inte börja med en siffa, ex. 9tal &lt;- 9 är inte tillåtet.\nett objektnamn kan inte innehålla mellanslag, ex. ett tal &lt;- 2 är inte tillåtet. 1\n\nIstället kan vi använda siffror och andra symboler inuti namnet, ex. tal9. Istället för mellanslag för att separera ord kan vi använda ett system kallad camelCase. Detta sätt att namnge objekt medför att vi tar bort alla mellanslag, slår ihop orden, och använder stor bokstav för att urskilja enskilda delar, ex. ettTal.\nVi kan spara några matematiska operationer för att använda de senare.\n\n\nVisa kod\n## Summan av 2 + 3 tilldelas till ett objekt, döpt till a\na &lt;- 2 + 3\n\n## Vi kan använda en högerriktad pil, men detta är inte praxis\n2 + 3 -&gt; a\n\n\nVi kan nu använda a i senare delar av vår kod och R kommer veta att objektet innehåller summan av 2 + 3.\n\n\nVisa kod\n## a (5) + 3\na + 3\n\n\n[1] 8\n\n\nVisa kod\n## a (5) / 5\na / 5\n\n\n[1] 1\n\n\n\nTyper\nR kan utföra olika operationer beroende på vilken typ av objekt som vi har sparat. En fördel jämfört med andra programmeringsspråk är att vi, i majoriteten av fallen, inte behöver säga till R vilken typ ett objekt är, R kan läsa av kontexten relativt bra. Till exempel kommer objektet a vara numeriskt (mer specifikt typen numeric) och vi kan kontrollera detta genom funktionen class().\n\n\nVisa kod\nclass(a)\n\n\n[1] \"numeric\"\n\n\nUtöver numeriska typer finns även:\n\ntextsträng (character): ex. \"hej\", \"Anna\",\nlogisk (logical): ex. TRUE eller FALSE,\n\nsamt två specialfall av siffror:\n\nheltal (integer), ett specialfall av numeriskt när det bara förekommer heltal: 2L där L anger till R att objektet ska vara av typen integer,\nkomplex (complex) innehållande komplexa tal\n\nVanligtvis räcker det med att använda numeric, character och logical-typer. I praktiken använder sig R utav ytterligare ett specialfall för textsträngar, Factor. Ett Factor-objekt är en blandning av en siffra och text där R lagrar en siffra men har ett lexikon där varje siffra egentligen representerar en textsträng.\n\n\nVisa kod\n## Siffror anges bara som de är\nvalfrittNummer &lt;- 3\n\n## För att man ska ange text måste de omges av \" \" (citattecken) för att R ska läsa de som text\nvalfriText &lt;- \"Hello world!\"\n\n## Om något är sant \ntest &lt;- TRUE\n\n\nMed hjälp av dessa objekt kan vi använda dess värden senare.\n\n\nVisa kod\n# a är summan av 2 + 3, och valfrittNummer har värdet 3\na + valfrittNummer\n\n\n[1] 8\n\n\n\n\n\n\n\n\nViktigt\n\n\n\nLägg märke till att om vi genomför någon matematisk beräkning på ett sparat objekt, till exempel a + 3 så kommer objektet a fortfarande ha samma värde som när vi skapade det. Vi ser enbart resultatet av beräkningen i konsollen och måste tilldela värdet på nytt om vi vill spara det. R uppdaterar inte värdet på ett objekt såvida vi inte ‘’skriver över’’ det.\n\n\n\n\n\nFelsökning\nVad händer om vi försöker genomföra en matematisk operation på två objekt som inte båda är numeriska?\n\n\nVisa kod\n## Ett numeriskt objekt - text\nvalfrittNummer - valfriText\n\n\nError in valfrittNummer - valfriText: non-numeric argument to binary operator\n\n\nVi får nu inte ut något värde i konsollen utan får istället ett felmeddelande. Felmeddelanden och felsökning är en stor del av programmering och kommer vara mycket frustrerande till en början. R ger oss dock (ofta) en indikation på vad som har gått fel och efter ett tag kommer du börja känna igen vanligt förekommande fel och hur man ska lösa dem.\nI detta fall säger R att vi har en ’‘non-numeric argument to binary operator’’ vilket kanske inte är jättetydligt vad det egentligen betyder, men den första delen av meddelandet är viktigt. Vi har ett icke-numeriskt objekt i en operation som kräver numeriska värden. Detta vet vi ju eftersom valfriText är en textsträng och vi kan då lätt lösa felet genom att ange ett annat numeriskt objekt istället.\n\n\nDatastrukturer\nI de tidigare exemplen har ett objekt endast haft ett värde, men vi kan tillåta att ett objekt har en samling med värden istället. Detta kallar vi för datastrukturer då vi på olika sätt strukturerar data. Vanligen kräver en datastruktur att värdena är av samma typ, men vissa strukturer tillåter en blandning av typer.\n\nVektorer\nLåt oss säga att vi har en massa kläder som ligger kaotiskt utspritt i ett rum. För att strukturera dessa kan vi exempelvis ta alla sockar och lägga dem i en låda. Lådan innehåller därmed en grupp av liknande objekt, som i R motsvarar en vektor.\nEn vektor måste innehålla värden av samma typ, siffror, text, eller logiska värden. För att skapa en vektor använder vi funktionen c(), där varje delobjekt kallas för element. Vi separarar elementen i funktionen med ett kommatecken.\n\n\nVisa kod\n## En vektor med numeriska värden\nA &lt;- c(3, 5, 3, 7)\n\nB &lt;- c(1, 3, 2, 4)\n\n## En vektor med textstränger\nord &lt;- c(\"Apelsin\", \"Banan\", \"Citron\")\n\n## Skriver ut respektive vektor\nA\n\n\n[1] 3 5 3 7\n\n\nVisa kod\nB\n\n\n[1] 1 3 2 4\n\n\nVisa kod\nord\n\n\n[1] \"Apelsin\" \"Banan\"   \"Citron\" \n\n\nVektor A och B har fyra element och vektor ord har tre element, alla av samma typ. Om vi vill titta på ett element kan vi indexera vektorn. Indexering innebär att vi säger till R att plocka ut angivna element ur objektets dimensionser. En vektor har bara en dimension vilket innebär att indexfunktionen [] endast behöver ett värde.\n\n\n\n\n\n\nViktigt\n\n\n\nR börjar räkna från 1 när det kommer till index. Detta skiljer sig från andra programmeringsspråk som oftast börjar på 0.\n\n\n\n\nVisa kod\n# Plockar ut det fjärde elementet ur vektorn A\nA[4]\n\n\n[1] 7\n\n\nVisa kod\n# Plockar ut det andra elementet ur vektorn ord\nord[2]\n\n\n[1] \"Banan\"\n\n\nVi kan också plocka ut flera element genom att i indexeringen ange en vektor med numeriska index.\n\n\nVisa kod\n## Plockar ut det andra och fjärde elementet ur vektorn B\nB[c(2, 4)]\n\n\n[1] 3 4\n\n\n\n\nMatriser\nLåt oss anta att vi har två vektorer med lika många element. Vi kan slå ihop dessa till en matris genom funktionen matrix(). En matris måste, likt vektorer, innehålla värden av samma typ, vi kan alltså inte kombinera en numerisk vektor och en textvektor oavsett om de har lika många element.\n\n\nVisa kod\n## En matris med värdena från vektor A och B där vi anger att vi har 2 kolumner\nmatris &lt;- matrix(c(A,B), ncol = 2)\n\n## Skriver ut matrisen\nmatris\n\n\n     [,1] [,2]\n[1,]    3    1\n[2,]    5    3\n[3,]    3    2\n[4,]    7    4\n\n\nVi ser nu i marginalerna (raderna och kolumnerna) att R använder två dimensioner för att peka på ett element. Indexeringen behöver nu två värden [radindex, kolumnindex] för att plocka ut enskilda element. Ordningen av dessa värden spelar roll eftersom R först letar efter en specifik rad (före ,) och sedan en specifik kolumn (efter ,). Om inget värde anges som rad- eller kolumnindex förutsätter R att vi vill se alla index från den dimensionen.\n\n\nVisa kod\n## Plockar ut den andra kolumnen ur matris, vektor B\nmatris[,2]\n\n\n[1] 1 3 2 4\n\n\nVisa kod\n## Plockar ut elementet från den andra raden och första kolumnen, värdet 5\nmatris[2,1]\n\n\n[1] 5\n\n\nVisa kod\n## Plockar ut elementet från den första raden och andra kolumnen, värdet 1\nmatris[1,2]\n\n\n[1] 1\n\n\n\n\nListor och data frames\nDet är ibland begränsande att kräva samma typ av objekt i en vektor eller matris, men som tur är finns det en datastruktur som faktiskt tillåter oss att kombinera objekt av olika typ. Denna struktur kallas för en lista och vi kan se en lista lite som en byrålåda. I en byrålåda kan vi samla ihop lådor av olika storlek och form och detsamma kan vi göra i en lista. Vi kan kombinera vektorer av olika typer med matriser eller enskilda värden i en och samma lista, vi kan till och med lägga in en lista inuti en annan lista.\nFöljande exempel är en lista med fyra olika objekt.\n\n\nVisa kod\nlista &lt;- list(A, B, ord, matris)\n\nlista\n\n\n[[1]]\n[1] 3 5 3 7\n\n[[2]]\n[1] 1 3 2 4\n\n[[3]]\n[1] \"Apelsin\" \"Banan\"   \"Citron\" \n\n[[4]]\n     [,1] [,2]\n[1,]    3    1\n[2,]    5    3\n[3,]    3    2\n[4,]    7    4\n\n\nFör att plocka ut ett element från listan behöver vi använda ytterligare en form av indexering. Vi behöver först ta oss in i en utav lådorna för att indexera den som vanligt, och det gör vi genom [[element]].\n\n\nVisa kod\n## Plockar ut det fjärde elementet ur vektorn A, listans första element\nlista[[1]][4]\n\n\n[1] 7\n\n\nVisa kod\n## Plockar ut elementet från den andra raden och första kolumnen i listans fjärde element\nlista[[4]][2,1]\n\n\n[1] 5\n\n\nFlexibiliteten i en lista gör det däremot väldigt svårt att arbeta med den, mer specifikt att en lista kan innehålla objekt av olika storlekar. En mer strukturerad datastruktur som tillåter olika typer av objekt är en data frame. Likt en matris innehåller en data frame vektorer av samma längd och likt en lista tillåter en data frame att vektorerna är av olika typ, vi kombinerar alltså strukturen från en matris med flexibiliteten från en lista. Ytterligare en fördel med en data frame är att kolumnerna (vektorerna) kan ha namn för att lättare urskilja vad objektet innehåller.\n\n\n\nVisa kod\n## Skapar en data frame med hjälp av funktionen data.frame() och döper de två kolumnerna till Var1 och Var2\ndata.frame(Var1 = A, Var2 = B)\n\n\n  Var1 Var2\n1    3    1\n2    5    3\n3    3    2\n4    7    4\n\n\nNär vi samlar in data inom statistik brukar vi ställa upp informationen med samma struktur som en data frame, där varje rad är en observerad enhet och varje kolumn är en variabel som vi gör mätningar på. Varje enskilda cell blir då enhetens uppmätta värde på den angivna variabeln, till exempel halten kväveoxid i Vänern. Detta kallar vi ofta för rådata-format.\n\n\nVisa kod\n## Skapar data\nstudent &lt;- \n  data.frame(\n    namn = c(\"Anna\", \"Oscar\", \"Jakob\", \"Noor\"),\n    längd = c(158, 164, 180, 174),\n    utbildning = c(\"Biologi\", \"Biologi\", \"Matematik\", \"Statistik\")\n  )\n\n## Skriver ut data\nstudent\n\n\n   namn längd utbildning\n1  Anna   158    Biologi\n2 Oscar   164    Biologi\n3 Jakob   180  Matematik\n4  Noor   174  Statistik\n\n\nVi kan i objektet student till exempel läsa att den första studenten Anna är 158 cm lång och studerar Biologi. Om vi är intresserade av en specifik variabel ur denna data frame kan vi återigen indexera med hjälp av [] men det vanligaste är att istället använda $.\n\n\nVisa kod\n## Indexerar variabeln \"utbildning\" ur data frame \"student\"\nstudent$utbildning\n\n\n[1] \"Biologi\"   \"Biologi\"   \"Matematik\" \"Statistik\"\n\n\nVisa kod\n## Gör samma indexering med hjälp av [], där \"utbildning\" är den tredje kolumnen\nstudent[,3]\n\n\n[1] \"Biologi\"   \"Biologi\"   \"Matematik\" \"Statistik\"\n\n\nVisa kod\n## Gör återigen samma men använder namnet på variabeln\nstudent[, \"utbildning\"]\n\n\n[1] \"Biologi\"   \"Biologi\"   \"Matematik\" \"Statistik\"\n\n\nFör att plocka ut enskilda rader (observationer) eller celler kan vi indexera med [radindex, kolumnindex] likt en matris.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Grunderna i R"
    ]
  },
  {
    "objectID": "00-programming/00-basics-R.html#sammanfattning",
    "href": "00-programming/00-basics-R.html#sammanfattning",
    "title": "Grunderna i R",
    "section": "Sammanfattning",
    "text": "Sammanfattning\nNu har vi fått en genomgång av grunderna i R, hur man kodar enkla matematiska operationer, vilka typer av objekt som R kan arbeta med, och hur vi sparar information till arbetsminnet på olika sätt som kan användas senare i samma session. Vi kommer i nästkommande kapitel gå igenom olika hjälpmedel som R och RStudio erbjuder så att vi inte alltid behöver koda allting från grunden.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Grunderna i R"
    ]
  },
  {
    "objectID": "00-programming/00-basics-R.html#övningsuppgifter",
    "href": "00-programming/00-basics-R.html#övningsuppgifter",
    "title": "Grunderna i R",
    "section": "Övningsuppgifter",
    "text": "Övningsuppgifter\nMed hjälp av R på din egna dator försök att lösa följande uppgifter. Efter varje uppgift får du en utskrift som visar hur resultatet ska se ut från din kod.\n\nSpara en numerisk vektor med alla värden från 1 till och med 6 i ökande ordning.\n\n\n\n[1] 1 2 3 4 5 6\n\n\n\nSpara en textvektor med sex element där den första, tredje och fjärde elementet är Hund och resterande är Katt.\n\n\n\n[1] \"Hund\" \"Katt\" \"Hund\" \"Hund\" \"Katt\" \"Katt\"\n\n\n\nSkapa en data frame med två kolumner. Den första kolumnen ska heta “ID” och innehålla vektorn från a) och den andra kolumnen ska heta “Art” och innehålla vektorn från b).\n\n\n\n  ID  Art\n1  1 Hund\n2  2 Katt\n3  3 Hund\n4  4 Hund\n5  5 Katt\n6  6 Katt\n\n\n\nPlocka ut den fjärde observationen.\n\n\n\n  ID  Art\n4  4 Hund",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Grunderna i R"
    ]
  },
  {
    "objectID": "00-programming/00-basics-R.html#footnotes",
    "href": "00-programming/00-basics-R.html#footnotes",
    "title": "Grunderna i R",
    "section": "",
    "text": "Det finns ett sätt att tillåta detta som vi kommer till i kapitel ?sec-tidyverse.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Grunderna i R"
    ]
  },
  {
    "objectID": "00-programming/01-packages-and-functions.html",
    "href": "00-programming/01-packages-and-functions.html",
    "title": "Paket och funktioner",
    "section": "",
    "text": "Paket och funktioner\nDet kommer bli väldigt jobbigt om vi alltid måste skapa data för hand eller beräkna summor som a + b + c + .... Användandet av en programvara ska underlätta de statistiska beräkningarna och i den andan följer här några kapitel om hur R eller RStudio kan hjälpa till.\nInom programmering är det vanligt att man genomför samma komplexa operation flera gånger och ett enkelt sätt att underlätta kodningen är att skapa en funktion som förkortar flera rader kod till en. Flera liknande funktioner samlas i olika paket som antingen redan är installerade på datorn eller måste installeras en gång.\nInstallerade paket måste också laddas till arbetsminnet för att R ska kunna använda sig utav dem. Vi kan visualisera detta som att även fast vi har köpt in en verktygslåda, måste vi ställa upp den på arbetsbänken för att kunna använda verktygen däri. Om du inte har verktygslådan bredvid dig kommer det bli svårt att använda något av verktygen. Vi kan ladda upp ett paket till arbetsminnet med hjälp av library() eller require(), där namnet på paketet anges inuti parenteserna.\nVisa kod\n## Laddar paketet dplyr med dess tillhörande funktioner\nrequire(dplyr)\nOm du har en ny installation av R på datorn måste du ibland installera paket, det vill säga ladda ner paketets information från internet. Som tur är finns det en funktion för detta också, nämligen install.packages(). Skillnaden här är att namnet på paketet måste anges inom citationstecken, ex. \"PAKET\", istället för bara namnet som vi gjorde i require(). Om du en gång redan installerat paketet till din version av R behöver du inte installera paketetet för varje ny session utan kan direkt ladda det genom library() eller require().\nVisa kod\n## Om paketen inte finns på datorn måste de installeras. \n## KÖRS ENDAST EN GÅNG I SAMBAND MED EN NY INSTALLATION ELLER UPPDATERING AV R!\ninstall.packages(\"ggplot2\")\ninstall.packages(\"RColorBrewer\")\n\n## Laddar paketen innehållande de funktioner som vi vill använda\nrequire(ggplot2)\nrequire(RColorBrewer)\nTermen funktion har använts frekvent tidigare och kan behöva förtydligas. En funktion är en större operation, oftast flera rader kod, som sammanfattas med en rad. Vi kan använda redan inbyggda funktioner från olika paket (som vi gjort i tidigare kapitel) eller skapa en egen funktion, men vi kommer i detta underlag fokusera på att använda redan skapade funktioner. För att använda en funktion behöver vi veta namnet på funktionen och eventuella argument som funktionen behöver. Argument motsvarar inställningar eller information som behövs i operationerna som funktionen genomför. För att tilldela ett argument ett värde eller information används = till skillnad från &lt;- i “vanlig” kodning.\nVisa kod\nfunktion(argument1 = värde1, argument2 = värde2)\nAlla argument i en funktion omsluts av parenteser, ( och ), och detta betyder att man kan skriva funktioner på en eller flera rader. Fördelen med att skriva en funktion på flera rader är att göra det lättare att läsa av vad som egentligen händer. Notera att R dock måste ha någon form utav indikation att funktionen fortsätter, t.ex. ett , för att ange att flera argument tillkommer eller &lt;- som tilldelar ett värde till ett objekt.1\nVisa kod\n## Skapar en numerisk vektor \nvektor &lt;- \n  c(\n    2,\n    3,\n    4,\n    5,\n    6\n  )\nR fortsätter att läsa på nästa rad om programmet inte anser att raden avslutas, i detta fall med att funktionen avslutas med ). Mer specifikt kan vi läsa av raderna en och en likt:\nEn annan fördel med att skriva funktioner på flera rader är att vi kan kommentera varje enskilda argument som används. Detta kommer vi se exempel på senare.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Paket och funktioner"
    ]
  },
  {
    "objectID": "00-programming/01-packages-and-functions.html#paket-och-funktioner",
    "href": "00-programming/01-packages-and-functions.html#paket-och-funktioner",
    "title": "Paket och funktioner",
    "section": "",
    "text": "&lt;- behöver ett värde att tilldela till objektet vektor, men eftersom det inte anges något värde på samma rad fortsätter R läsa av nästa rad,\nFunktionen c får inget avslutande ) så R fortsätter läsa av nästa rad,\nVarje , separerar element i vektorn, men eftersom det inte anges något ytterligare värde fortsätter R läsa av nästa rad,\nDet är först när inget ytterligare element läggs till och funktionen stängs med ) som R är nöjd och inte läser vidare på efterföljande rader.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Paket och funktioner"
    ]
  },
  {
    "objectID": "00-programming/01-packages-and-functions.html#sec-readData",
    "href": "00-programming/01-packages-and-functions.html#sec-readData",
    "title": "Paket och funktioner",
    "section": "Ladda in datamaterial",
    "text": "Ladda in datamaterial\nVid datainsamling, eller vid inhämtning av material som någon annan har samlat in, är det vanligt att vi sammanställer informationen utanför R, till exempel skulle ett arbetsblad i Microsoft Excel ge oss ett lätt sätt att strukturera information. Istället för att behöva återskapa materialet från grunden i R kan vi läsa in information från andra typer av filer på datorn.\nDen enklaste formen av fil som R läser in är rena textfiler (med filändelser .txt, .csv, .dat) som på olika sätt sparat ner datans struktur på ett organiserat sätt. Vi kan läsa in informationen från dessa sorters filer till R med hjälp av specifika funktioner.\nInom statistik är det vanligt att använda kommaseparerade filer, .csv, som vi kan skapa från Excel genom menyn Spara som.... Med hjälp av funktionen read.csv och dess argument kan vi säga till R vilken struktur som filen har och få samma struktur i en data frame. Ett tips är att öppna datafilen i Notepad, Anteckningar eller annan enkel ordbehandlare för att se vilka symboler som används för att beskriva strukturen.\nExempelvis skulle en textfil kunna se ut så här:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1: Exempel på en fil öppnad i Notepad\n\n\n\nsom laddas in i R som följer:\n\n\nVisa kod\n## Laddar in datamaterialet från fil och sparar data frame i objektet ekar\nekar &lt;- \n  read.csv(\n    ## Sökvägen till filen på datorn\n    \"dataOmEkar.csv\", \n    ## Argument för vilken symbol som används för decimaler i filen\n    dec = \",\", \n    ## Argument för vilken symbol som används för att separera kolumner i filen\n    sep = \";\"\n  )",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Paket och funktioner"
    ]
  },
  {
    "objectID": "00-programming/01-packages-and-functions.html#arbetsmappar",
    "href": "00-programming/01-packages-and-functions.html#arbetsmappar",
    "title": "Paket och funktioner",
    "section": "Arbetsmappar",
    "text": "Arbetsmappar\nAtt importera datamaterial är endast ett sätt där vi interagerar med datorns hårddisk. Vi kan ibland vilja spara ner objekt eller visualiseringar mer permanent och då kommer vi återigen behöva ange en sökväg till någonstans på datorn. För att underlätta denna process kan vi använda oss utav arbetsmappar (eng. working directory).\nEn arbetsmapp är ett sätt för oss att snabbt och enkelt ge information till R att den ska leta i en specifik del av datorns hårddisk. Om vi arbetar med ett projekt, till exempel datorlaborationer i en specifik kurs, kan det vara lämpligt att skapa en mapp på datorn där all information som hör till kursen sparas ner. Då är det också lämpligt att i R säga att denna mapp är den arbetsmapp som vi ska importera från och exportera till under en session. Vi behöver dock först veta vilken sökväg som leder oss in till mappen.\nFör att hitta denna sökväg, kan du öppna upp mappen i ditt operativssystems filhanterare. Du kan följa lämplig instruktion för just ditt operativsystem via någon av följande länkar:\n\ninstruktioner för Windows\ninstruktioner för Mac\ninstruktioner för Linux\n\nNär du väl har hittat din sökväg ska du kopiera den i sin helhet och sedan använda funktionen setwd() för att R ska spara mappen i arbetsminnet. Notera att alla \\ måste bytas ut med antingen \\\\ eller / för att R ska kunna läsa av sökvägen korrekt. Exempelvis kan det se ut så här:\n\n\nVisa kod\n## Arbetsmappen anger en sökväg till en mapp på datorn med alla filer som ska användas \nsetwd(\"C:/Users/MIN ANVÄNDARE/MAPPENS NAMN\")\n\n\nVi måste lägga in sökvägen inom \"sökväg\" för att R ska kunna läsa av den som en textsträng och inte en massa objekt. Låt oss säga att vi har en fil i denna mapp som heter dataOmEkar.csv. Om vi inte har en arbetsmapp i sessionen behöver vi ange hela sökvägen till filen om vi ska importera den till R via read.csv(\"C:/Users/MIN ANVÄNDARE/MAPPENS NAMN/dataOmEkar.csv)\". Däremot efter att ha kört raden kod vet R att den ska leta efter filen i arbetsmappen och vi behöver därför bara använda filens namn likt read.csv(\"dataOmEkar.csv\"). I det långa loppet kommer arbetsmappar underlätta kodningen avsevärt om vi organiserar filer på datorn på ett strukturerat sätt. Om vi endast är intresserade av någon enstaka fil kanske vi kan klara oss att skriva den långa sökvägen en eller två gånger, men det blir lätt mycket text om fler filer behöver importeras.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Paket och funktioner"
    ]
  },
  {
    "objectID": "00-programming/01-packages-and-functions.html#help",
    "href": "00-programming/01-packages-and-functions.html#help",
    "title": "Paket och funktioner",
    "section": "Hjälpdokumentation",
    "text": "Hjälpdokumentation\nAtt alltid komma ihåg vad R kan göra, vilka funktioner som finns, vilka argument som de behöver, är omöjligt. Som tur är finns många resurser att hjälpa oss, inte minst den interna dokumentationen.\nGenom att använda ? och ett funktionsnamn letar R upp den tillhörande hjälpdokumentationen för funktionen. Den innehåller en detaljerad beskrivning av funktionens syfte, hur man använder den, vilka argument som finns och vad respektive styr, mer djupgående detaljer om funktionen och dess resultat, ytterligare referenser, och allra sist exempel när funktionen används som man kan ta inspiration från.\nLäs hjälpdokumentationen för funktionen att skapa en vektor och testa några av de exempel som visas allra sist i artikeln.\n\n\nVisa kod\n?c\n\n\nEftersom R är open-source finns det väldigt mycket material tillgänglig på internet, detta underlag kan ses som en sådan resurs. Genom att använda en sökmotor där man beskriver det problem som man stött på eller fråga hur en funktion fungerar kommer du hitta en stor samling av sidor som säkerligen beskriver exakt det du är ute efter.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Paket och funktioner"
    ]
  },
  {
    "objectID": "00-programming/01-packages-and-functions.html#chat-GPT",
    "href": "00-programming/01-packages-and-functions.html#chat-GPT",
    "title": "Paket och funktioner",
    "section": "ChatGPT eller annan AI",
    "text": "ChatGPT eller annan AI\nYtterligare en resurs som kan både hjälpa och stjälpa är ChatGPT och andra liknande AI-program. Genom att ställa frågor av olika slag till programmet kan man få resultat som dels ger kommenterad kod som (förhoppningsvis) löser det problem som man frågar efter och beskriver mer i detalj koden som den producerat.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 2: Exempel på en fråga och svar med ChatGPT\n\n\n\nI exemplet ovan producerar ChatGPT några rader kod som ser ut att fungera, vi måste ange sökvägen till filen i file_path och sedan används funktionen read.csv() för att läsa in datamaterialet till objektet data. ChatGPT är dock inte bra på att kontrollera sin kod och inte heller att följa viss praxis vid kodning, vilket innebär att vi aldrig får ta koden som produceras som hel sanning. Istället kan vi använda AI-program som ett sätt att inspireras eller på annat sätt läsa oss olika programmeringskoncept som vi sedan tillämpar på egen hand.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Paket och funktioner"
    ]
  },
  {
    "objectID": "00-programming/01-packages-and-functions.html#footnotes",
    "href": "00-programming/01-packages-and-functions.html#footnotes",
    "title": "Paket och funktioner",
    "section": "",
    "text": "Vi kommer senare se andra exempel på symboler som visar R att kodningen fortsätter på nästa rad.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "Paket och funktioner"
    ]
  },
  {
    "objectID": "00-programming/02-tidyverse.html",
    "href": "00-programming/02-tidyverse.html",
    "title": "tidyverse",
    "section": "",
    "text": "Läsa in filer med readr\nEn stor del utav statistisk analys omfattar bearbetning av datamaterial som samlats in till ett format som lämpar sig för olika statistiska analysmetoder. Ett datamaterial som man själv samlar in (primärdata) eller datamaterial som hämtas från någon annan källa (sekundärdata) är inte alltid strukturerat på det sätt som vi, eller metoderna, önskar. tidyverse är en samling paket i R som har en gemensam grund att programmera, både i dess syntax och grammatik.\nInom statistik önskas data ofta följa formatet: “en rad är en observation”, “en kolumn är en variabel” och “en cell är ett värde”, så att vi med lätthet kan hantera datamaterialet på ett flertal olika sätt. Detta kan vi kalla för rådata eller tidy data och Pingviner vid Antarktis visar data på just detta format. Varje rad är en uppmätt pingvin och varje kolumn är mätvärden för varje variabel. Exempel på en struktur som inte följer denna praxis är frekvenstabeller där varje rad visar flera observationer som har samma variabelvärde.\nVi kan installera de paketen som ingår i tidyverse genom att installera paketet med samma namn och ladda in det i arbetsminnet med require() eller library().\nI detta kapitel kommer vi gå igenom de olika paketen som behandlar datastrukturer och olika variablertyper medan senare kapitel kommer fortsätta med paket för visualisering (ggplot2) och mer avancerad kodning (purrr).\nR innehåller många inbyggda funktioner (se Ladda in datamaterial) för hur man kan läsa in filer av olika format från hårddisken. Vi har tidigare tittat på read.csv2() som är en grundfunktion i R, men readr har liknande funktioner utöver flera andra specialfall som utgår från vissa standardformat för filer.\n# Läser in en textfil där kolumner separeras med en (eller flera) mellanslag (.txt)\nread_table(file = \"sökväg\")\n\n# Läser in en textfil där kolumner separeras med tab (.tsv)\nread_tsv(file = \"sökväg\")\n\n# Läser in en textfil där kolumner separeras med , (read_csv) eller ; (read_csv2)\nread_csv(file = \"sökväg\")\nread_csv2(file = \"sökväg\")\nResultatet av dessa funktioner blir en formatterad tibble, vilket är tidyverse version av en data frame.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "tidyverse"
    ]
  },
  {
    "objectID": "00-programming/02-tidyverse.html#sec-readr",
    "href": "00-programming/02-tidyverse.html#sec-readr",
    "title": "tidyverse",
    "section": "",
    "text": "Tips\n\n\n\nDet är starkt rekommenderat att läsa in text-filer i R, inte Excelfiler då Excel kan innehålla specialformat som R inte kan läsa in korrekt. Vi kan från Excel spara om en .xlsx fil till en .txt-, .tsv- eller .csv-fil.\n\n\n\n\n\n\n\n\n\n\nViktigt\n\n\n\nSe till att datamaterialet som laddats in ser ut som vi förväntar att det ska göra, exempelvis är decimaler korrekt angivna, har vi lika många variabler i R som i originalfilen och liknande.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "tidyverse"
    ]
  },
  {
    "objectID": "00-programming/02-tidyverse.html#sec-tibble",
    "href": "00-programming/02-tidyverse.html#sec-tibble",
    "title": "tidyverse",
    "section": "Dataobjektet tibble",
    "text": "Dataobjektet tibble\nI Listor och data frames presenterades datastrukturen data frame som ett sätt för oss att i R spara information i ett strukturerat rådataformat. En tibble är en utbyggnad av denna datastruktur som rensat bort egenskaper av objektet som inte längre används och lägger till egenskaper som vi ofta vill använda när vi bearbetar data. Likt en data frame, innehåller en tibble en samling lika långa kolumner och dessa kolumner kan vara av olika objekttyper. Till exempel kan vi blanda listor och vektorer så länge de innehåller lika många element.\n\n\n\n\n\n\nViktigt\n\n\n\nEn tibble konverterar inte textvektorer till faktorer per automatik. Det vill säga om ett datamaterial som läses in via read_csv2() innehåller text, kommer denna variabel vara ett character-objekt, inte ett Factor-objekt.\n\n\nVi kan skapa en tibble från grunden genom att ange vilka objekt vi vill inkludera och vad de ska heta:\n\na &lt;- c(1, 2, 3)\nb &lt;- c(4, 5, 6)\nc &lt;- c(\"a\", \"b\", \"c\")\n\n# Skapar en tibble utifrån angivna vektorer\ndata &lt;- \n  tibble(\n    Var1 = a,\n    Var2 = b,\n    Var3 = c\n  )\n\n# Skriver ut tibble till konsollen\nprint(data)\n\n# A tibble: 3 × 3\n   Var1  Var2 Var3 \n  &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt;\n1     1     4 a    \n2     2     5 b    \n3     3     6 c    \n\n\nEn direkt utskrift av en tibble innehåller både dimensionerna av hela objektet och vad för typ respektive variabel är.\nOm vi har en matris eller något annat objekt som ser ut som en tibble men inte är det, kan vi konvertera den till en tibble med hjälp av as_tibble().\n\n\nVisa kod\n# Tar objektet a (en vektor) och gör om den till en tibble med en kolumn\nvectorToTibble &lt;- \n  a %&gt;% \n    as_tibble()\n\nprint(vectorToTibble)\n\n\n# A tibble: 3 × 1\n  value\n  &lt;dbl&gt;\n1     1\n2     2\n3     3",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "tidyverse"
    ]
  },
  {
    "objectID": "00-programming/02-tidyverse.html#sec-tidyr",
    "href": "00-programming/02-tidyverse.html#sec-tidyr",
    "title": "tidyverse",
    "section": "Omformatera data med tidyr",
    "text": "Omformatera data med tidyr\nEn utav de tyngsta delarna av statistisk analys är ofta att bearbeta data till det format som önskas. Paketet tidyr innehåller ett flertal funktioner som kan bearbeta data på många olika sätt\nOm data inte är på det format som vi önskar eller om någon statistisk metod behöver ett material som har ett annat format än tidy-data. Detta paket kommer vi inte titta på just nu i detalj men följande Cheat Sheets innehåller exempel på olika bearbetningar som vi kan vara intresserade av att genomföra med data.",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "tidyverse"
    ]
  },
  {
    "objectID": "00-programming/02-tidyverse.html#koppla-samman-funktioner-med-pipes",
    "href": "00-programming/02-tidyverse.html#koppla-samman-funktioner-med-pipes",
    "title": "tidyverse",
    "section": "Koppla samman funktioner med pipes",
    "text": "Koppla samman funktioner med pipes\nInom programmering, speciellt databearbetning, är det vanligt att vi vill skapa ett objekt, göra någon bearbetning på den, använda den i en statistisk analys och så vidare. Att nästla funktioner inuti varandra blir lätt väldigt krångligt att läsa och förstå vad som faktiskt händer eller vilka argument som hör till vilken funktion. Alternativet är att spara om objektet flera gånger men då skapas många onödiga objekt som vi måste hålla koll på och som egentligen bara tar upp plats i arbetsminnet.\n\n# Fyra nästlade funktioner som ska appliceras på ett objekt med olika argument\nfunktion4(funktion3(funktion2(funktion1(objekt), argument2 = X)), argument4 = Y)\n\n# Fyra funktioner som sparas vid varje steg\nA &lt;- funktion1(objekt)\n\nB &lt;- funktion2(A, argument2 = X)\n\nC &lt;- funktion3(B)\n\nD &lt;- funktion4(C, argument4 = Y)\n\nInom tidyverse används istället en annan process som kallas för programmeringspipes som kan skapa sekvenser av funktioner som är sammanlänkade i varandra.1 Från paketet dplyr används operatorn %&gt;% som kan skapas med kortkommandot Ctrl + Shift + M (CMD + Shift + M). Denna operator tar resultatet från funktionen innan %&gt;% och skickar vidare det som det första argumentet i funktionen efter %&gt;%.\n\n# Samma operation av fyra funktioner men med piping\nobjekt %&gt;% \n  funktion1() %&gt;% \n  funktion2(argument2 = X) %&gt;% \n  funktion3() %&gt;% \n  funktion4(argument4 = Y)\n\nFunktioner som inte behöver fler än ett argument skrivs bara ut som funktionen med tomma parenteser då resultatet används automatiskt som värdet på det argumentet. Funktioner som har ytterligare argument behöver bara ange de argument som inte använder sig av det tidigare resultatet.\n\n\n\n\n\n\nViktigt\n\n\n\nDet kan finnas funktioner som vill använda det tidigare resultatet i ett argument som inte är det första i funktionen. Som tur är kan vi lösa detta genom att använda . som symbolen för det tidigare resultatet och ange det vid argumentet som är aktuellt.\n\n# Objektet (.) läggs här in som värde för det andra argumentet i funktionen\nobjekt %&gt;% \n  funktion5(argument1 = X, argument2 = .)",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "tidyverse"
    ]
  },
  {
    "objectID": "00-programming/02-tidyverse.html#databearbetning-med-dplyr",
    "href": "00-programming/02-tidyverse.html#databearbetning-med-dplyr",
    "title": "tidyverse",
    "section": "Databearbetning med dplyr",
    "text": "Databearbetning med dplyr\nMed hjälp av de tidigare kapitlen och det “nya” sättet att skriva sekvenser av funktioner med pipes kan vi nu börja titta närmare på databearbetning av objekt till en tibble. Det är vanligt att vi i databearbetning behöver göra flera steg för att skapa det objekt vi sen vill analysera och då kommer %&gt;% mycket väl till pass.\ndplyr innehåller ett flertal olika “verb” som på ett sätt eller annat bearbetar data. Det första argumentet i alla dessa funktioner är ett dataobjekt men om vi använder pipes kommer det ske per automatik och vi behöver endast fokusera på de andra argumentet som beskriver hur “verbet” används.\n\nByta namn på variabler med rename()\nData som läses in till R kan ibland ha konstiga och långa namn som vid programmering kan bli svåra att hantera. Ett sätt att underlätta detta problem är att döpa om variablerna till ett enkelt ord som vi sedan kan använda i efterföljande steg.\nVi kan döpa om variabler med hjälp av rename() där vi anger det nya namnet givet det gamla namnet på variabeln eller variabelns kolumnindex.\n\n# Döper om variabler till svenska namn utifrån det gamla namnet\npenguins %&gt;% \n  rename(\n    art = species,\n    näbblängd = bill_length_mm\n  )\n\n# A tibble: 333 × 8\n   art    island    näbblängd bill_depth_mm flipper_length_mm body_mass_g sex   \n   &lt;fct&gt;  &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt; \n 1 Adelie Torgersen      39.1          18.7               181        3750 male  \n 2 Adelie Torgersen      39.5          17.4               186        3800 female\n 3 Adelie Torgersen      40.3          18                 195        3250 female\n 4 Adelie Torgersen      36.7          19.3               193        3450 female\n 5 Adelie Torgersen      39.3          20.6               190        3650 male  \n 6 Adelie Torgersen      38.9          17.8               181        3625 female\n 7 Adelie Torgersen      39.2          19.6               195        4675 male  \n 8 Adelie Torgersen      41.1          17.6               182        3200 female\n 9 Adelie Torgersen      38.6          21.2               191        3800 male  \n10 Adelie Torgersen      34.6          21.1               198        4400 male  \n# ℹ 323 more rows\n# ℹ 1 more variable: year &lt;int&gt;\n\n# Döper om variabler till svenska namn utifrån dess kolumnindex\npenguins %&gt;% \n  rename(\n    art = 1,\n    näbblängd = 3\n  )\n\n# A tibble: 333 × 8\n   art    island    näbblängd bill_depth_mm flipper_length_mm body_mass_g sex   \n   &lt;fct&gt;  &lt;fct&gt;         &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt; &lt;fct&gt; \n 1 Adelie Torgersen      39.1          18.7               181        3750 male  \n 2 Adelie Torgersen      39.5          17.4               186        3800 female\n 3 Adelie Torgersen      40.3          18                 195        3250 female\n 4 Adelie Torgersen      36.7          19.3               193        3450 female\n 5 Adelie Torgersen      39.3          20.6               190        3650 male  \n 6 Adelie Torgersen      38.9          17.8               181        3625 female\n 7 Adelie Torgersen      39.2          19.6               195        4675 male  \n 8 Adelie Torgersen      41.1          17.6               182        3200 female\n 9 Adelie Torgersen      38.6          21.2               191        3800 male  \n10 Adelie Torgersen      34.6          21.1               198        4400 male  \n# ℹ 323 more rows\n# ℹ 1 more variable: year &lt;int&gt;\n\n\n\n\nPlocka ut rader med filter()\nOm vi är intresserade av att plocka ut vissa rader ur ett objekt, till exempel om vi vill rensa bort saknade värden, kan vi använda filter() med någon logisk operator som säger vilka rader vi vill ha kvar.\n\n# Filtrerar bort observationer som saknar information ur variabeln \"sex\"\npenguinsNonMissing &lt;- \n  penguins %&gt;% \n    filter(!is.na(sex))\n\nprint(penguinsNonMissing)\n\n# A tibble: 333 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           39.2          19.6               195        4675\n 8 Adelie  Torgersen           41.1          17.6               182        3200\n 9 Adelie  Torgersen           38.6          21.2               191        3800\n10 Adelie  Torgersen           34.6          21.1               198        4400\n# ℹ 323 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\nVi kan också plocka ut rader som uppfyller ett visst kriterie, till exempel plocka ut alla Adelie pingviner.\n\npenguins %&gt;% \n  filter(species == \"Adelie\")\n\n# A tibble: 146 × 8\n   species island    bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie  Torgersen           39.1          18.7               181        3750\n 2 Adelie  Torgersen           39.5          17.4               186        3800\n 3 Adelie  Torgersen           40.3          18                 195        3250\n 4 Adelie  Torgersen           36.7          19.3               193        3450\n 5 Adelie  Torgersen           39.3          20.6               190        3650\n 6 Adelie  Torgersen           38.9          17.8               181        3625\n 7 Adelie  Torgersen           39.2          19.6               195        4675\n 8 Adelie  Torgersen           41.1          17.6               182        3200\n 9 Adelie  Torgersen           38.6          21.2               191        3800\n10 Adelie  Torgersen           34.6          21.1               198        4400\n# ℹ 136 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\nPlocka ut kolumner med select()\nAnta att vi bara är intresserade av vissa kolumner från ett stort datamaterial, till exempel art och fenlängd av pingvinerna kan vi plocka ut de med hjälp av select(). Vi kan antingen använda variablernas faktiska namn eller variablernas kolumnindex för att specificera vilka variabler som ska plockas ut.\n\n# Select med variabelnamn\npenguins %&gt;% \n  select(species, flipper_length_mm)\n\n# A tibble: 333 × 2\n   species flipper_length_mm\n   &lt;fct&gt;               &lt;int&gt;\n 1 Adelie                181\n 2 Adelie                186\n 3 Adelie                195\n 4 Adelie                193\n 5 Adelie                190\n 6 Adelie                181\n 7 Adelie                195\n 8 Adelie                182\n 9 Adelie                191\n10 Adelie                198\n# ℹ 323 more rows\n\n# Select med kolumnindex\npenguins %&gt;% \n  select(1, 5)\n\n# A tibble: 333 × 2\n   species flipper_length_mm\n   &lt;fct&gt;               &lt;int&gt;\n 1 Adelie                181\n 2 Adelie                186\n 3 Adelie                195\n 4 Adelie                193\n 5 Adelie                190\n 6 Adelie                181\n 7 Adelie                195\n 8 Adelie                182\n 9 Adelie                191\n10 Adelie                198\n# ℹ 323 more rows\n\n\nDet rekommenderas att använda variabelnamnen för att koden ska vara tydlig att läsa av och vi vet vilka variabler som faktiskt plockas ut och ev. skickas vidare till efterföljande funktioner.\nOm vi har flera variabler som följer efter varandra behöver vi inte skriva upp varje enskilda variabelnamn som argument utan kan använda Var1:Var5 för att säga åt funktionen att plocka ut alla variabler från och med Var1 till och med Var5.\n\npenguins %&gt;% \n  select(species, bill_length_mm:body_mass_g)\n\n# A tibble: 333 × 5\n   species bill_length_mm bill_depth_mm flipper_length_mm body_mass_g\n   &lt;fct&gt;            &lt;dbl&gt;         &lt;dbl&gt;             &lt;int&gt;       &lt;int&gt;\n 1 Adelie            39.1          18.7               181        3750\n 2 Adelie            39.5          17.4               186        3800\n 3 Adelie            40.3          18                 195        3250\n 4 Adelie            36.7          19.3               193        3450\n 5 Adelie            39.3          20.6               190        3650\n 6 Adelie            38.9          17.8               181        3625\n 7 Adelie            39.2          19.6               195        4675\n 8 Adelie            41.1          17.6               182        3200\n 9 Adelie            38.6          21.2               191        3800\n10 Adelie            34.6          21.1               198        4400\n# ℹ 323 more rows\n\n\n\n\nByta plats på variabler med relocate()\nIbland kan vi vilja byta ordning på variablerna i datamaterialet utan att välja dem. Med select() får vi en möjlighet att välja vilken ordning som variablerna plockas ut, den ordning som vi anger dem i funktionen, men om vi bara vill flytta på variabler utan att plocka ut vissa kan relocate() användas istället.\nFunktionen använder sig av tre argument, vilka variabler som ska flyttas och var de ska placeras. Som standard placeras de i början av datamaterialet.\n\n# Placerar fenlängd som första kolumnen\npenguins %&gt;% \n  relocate(flipper_length_mm)\n\n# A tibble: 333 × 8\n   flipper_length_mm species island    bill_length_mm bill_depth_mm body_mass_g\n               &lt;int&gt; &lt;fct&gt;   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt;       &lt;int&gt;\n 1               181 Adelie  Torgersen           39.1          18.7        3750\n 2               186 Adelie  Torgersen           39.5          17.4        3800\n 3               195 Adelie  Torgersen           40.3          18          3250\n 4               193 Adelie  Torgersen           36.7          19.3        3450\n 5               190 Adelie  Torgersen           39.3          20.6        3650\n 6               181 Adelie  Torgersen           38.9          17.8        3625\n 7               195 Adelie  Torgersen           39.2          19.6        4675\n 8               182 Adelie  Torgersen           41.1          17.6        3200\n 9               191 Adelie  Torgersen           38.6          21.2        3800\n10               198 Adelie  Torgersen           34.6          21.1        4400\n# ℹ 323 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n# Placerar art efter näbbreddens variabel\npenguins %&gt;% \n  relocate(species, .after = bill_depth_mm)\n\n# A tibble: 333 × 8\n   island    bill_length_mm bill_depth_mm species flipper_length_mm body_mass_g\n   &lt;fct&gt;              &lt;dbl&gt;         &lt;dbl&gt; &lt;fct&gt;               &lt;int&gt;       &lt;int&gt;\n 1 Torgersen           39.1          18.7 Adelie                181        3750\n 2 Torgersen           39.5          17.4 Adelie                186        3800\n 3 Torgersen           40.3          18   Adelie                195        3250\n 4 Torgersen           36.7          19.3 Adelie                193        3450\n 5 Torgersen           39.3          20.6 Adelie                190        3650\n 6 Torgersen           38.9          17.8 Adelie                181        3625\n 7 Torgersen           39.2          19.6 Adelie                195        4675\n 8 Torgersen           41.1          17.6 Adelie                182        3200\n 9 Torgersen           38.6          21.2 Adelie                191        3800\n10 Torgersen           34.6          21.1 Adelie                198        4400\n# ℹ 323 more rows\n# ℹ 2 more variables: sex &lt;fct&gt;, year &lt;int&gt;\n\n\n\n\nSortera data med arrange()\n\n\nSkapa nya variabler med mutate()\n\n\nGruppera beräkningar med group_by()\n\n\nSammanfatta data med summarize()",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "tidyverse"
    ]
  },
  {
    "objectID": "00-programming/02-tidyverse.html#footnotes",
    "href": "00-programming/02-tidyverse.html#footnotes",
    "title": "tidyverse",
    "section": "",
    "text": "Även basversionen av R/RStudio har anammat denna process och det finns nu två varianter av en pipe. Detta underlag kommer använda tidyverse varianten.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL I - Programmering i R**",
      "tidyverse"
    ]
  },
  {
    "objectID": "01-regression/index.html",
    "href": "01-regression/index.html",
    "title": "Förord",
    "section": "",
    "text": "Till denna del förutsätts att du har vissa förkunskaper för att ta till dig materialet på bästa sätt. Dessa är:\nProgrammering\nStatistik\nMatematik endast för statistiker\nKänner du att du saknar vissa av dessa kunskaper, titta tillbaka på tidigare material innan du går vidare.\nFör alla dessa kapitel förutsätts att du har laddat paketet tidyverse som innehåller flera paket såsom readr, dplyr, ggplot2 med flera. Andra paket kan behövas installeras och laddas för olika kapitel men detta bör anges specifikt.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "Förord"
    ]
  },
  {
    "objectID": "01-regression/index.html#footnotes",
    "href": "01-regression/index.html#footnotes",
    "title": "Förord",
    "section": "",
    "text": "Detta material använder sig av %&gt;% men |&gt; bör kunna användas istället i de allra flesta exemplen.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "Förord"
    ]
  },
  {
    "objectID": "01-regression/00-intro-regression.html",
    "href": "01-regression/00-intro-regression.html",
    "title": "1  Introduktion till regression",
    "section": "",
    "text": "1.1 Den linjära regressionsmodellen\nAtt undersöka samband mellan variabler är ett vanligt steg i att förstå relationer eller fenomen. Till exempel hur åldern på ett träd påverkar dess volym, hur olika doser av en medicin påverkar en individs blodtryck, eller hur en persons ålder och utbildningsnivå påverkar dens ingångslön.\nRegressionsanalys omfattar metoder som anpassar matematiska modeller vilka på bästa sätt kan ge en förenklad bild av verkligheten. Generellt är modeller någon form av konstruktion som skapas för att öka förståelsen av någonting verkligt. Till exempel är en flygplansmodell inte ett riktigt flygplan men kan användas för att förstå hur ett flygplan är uppbyggd och hur den kan hantera luftströmmar och andra fenomen. Ett klassiskt exempel är tavlan “Ceci n’est pas une pipe” av René Magritte (Figur 1.1) som visar en representation (en modell) av en pipa, inte en fungerande pipa.\nDet finns många olika sorters modeller inom regressionsanalys, men i det allra enklaste fallet anpassas en linjär modell där variablernas samband antas enkelriktat och konstant. \\[\nY = \\beta_0 + \\beta_1 \\cdot X + E\n\\tag{1.1}\\]\ndär:\nOm flera förklarande variabler antas påverka responsvariabeln utökas den linjära modellen med flera \\(\\beta_j\\), en för varje förklarande variabel \\(X_j\\). Senare kapitel kommer titta närmare på utökningar av denna linjära modell.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduktion till regression</span>"
    ]
  },
  {
    "objectID": "01-regression/00-intro-regression.html#den-linjära-regressionsmodellen",
    "href": "01-regression/00-intro-regression.html#den-linjära-regressionsmodellen",
    "title": "1  Introduktion till regression",
    "section": "",
    "text": "\\(Y\\) är den beroende/respons- variabeln som antas påverkas av \\(X\\).\n\\(X\\) är den oberoende/förklarande variabeln som antas påverka \\(Y\\).\n\\(\\beta_0\\) är modellens intercept där linjen skär y-axeln när \\(X = 0\\).\n\\(\\beta_1\\) är lutningen som beskriver det enkelriktade samband mellan \\(X\\) och \\(Y\\). Mer specifikt beskriver parametern förändringen i \\(Y\\) när \\(X\\) ökar med en enhet.\n\\(E\\) är modellens felterm, avståndet mellan det observerade värdet på \\(Y\\) och modellens skattade värde \\(\\hat{Y}\\).",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduktion till regression</span>"
    ]
  },
  {
    "objectID": "01-regression/00-intro-regression.html#sec-model-assumptions",
    "href": "01-regression/00-intro-regression.html#sec-model-assumptions",
    "title": "1  Introduktion till regression",
    "section": "1.2 Modellens antaganden",
    "text": "1.2 Modellens antaganden\nSyftet med en modell är att ge en lämplig förenkling av verkligheten. En linjär regressionsmodell kan vara en lämplig förenkling av ett samband om följande antaganden uppfylls:\n\natt det för varje \\(X\\) finns en slumpvariabel \\(Y\\) med ett ändligt medelvärde och varians,\nobservationerna är oberoende av varandra,\nmedelvärdet, \\(\\mu_{Y|X}\\), kan modelleras linjärt,\nvariansen för \\(Y\\) är lika för alla värden av \\(X\\), \\(\\sigma^2_{Y|X} \\equiv \\sigma^2\\),\nslumpvariabeln \\(Y\\) är normalfördelad för alla värden av \\(X\\).\n\nVi kan sammanfatta majoriteten av dessa antaganden med: \\[\n   Y|X \\overset{\\mathrm{iid}}{\\sim} N(\\mu_{Y|X}, \\sigma^2_{Y|X})\n\\] där \\(\\mathrm{iid}\\) betyder “independent and identically distributed” motsvarande antagande 2.\n\n\n\n\n\n\nViktigt\n\n\n\nDet finns inget antagande om att \\(Y \\sim N(\\mu_Y, \\sigma^2_Y)\\)! Alla antaganden för en linjär regressionsmodell fokuserar på att vi med hjälp av \\(X\\) har en normalfördelad slumpvariabel \\(Y\\).\n\n\nOm det tredje antagandet uppfylls kan vi modellera väntevärdet av \\(Y|X\\) med den linjära modellen: \\[\n  E[Y|X] = \\beta_0 + \\beta_1 \\cdot X\n\\tag{1.2}\\] så att: \\[\nY|X \\overset{\\mathrm{iid}}{\\sim} N(\\beta_0 + \\beta_1 \\cdot X, \\sigma^2_{Y|X})\n\\]\nTill skillnad från Ekvation 1.1 saknar Ekvation 1.2 modellens felterm på grund av att vi nu modellerar endast medelvärdet av slumpvariabelns fördelning, \\(\\mu_{Y|X}\\). Osäkerheten runtomkring medelvärdet är variansen av fördelningen.\nNär vi modellerar varje enskilda observation inkluderas \\(E\\) vilket innebär att vi kan flytta modellens antaganden från \\(Y|X\\) till \\(E\\). \\[\n  E \\overset{\\mathrm{iid}}{\\sim} N(0, \\sigma^2)\n\\tag{1.3}\\]\nDenna omskrivning ger oss en bra utgångspunkt att utvärdera lämpligheten av en anpassad modell.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1.2: Ej lämplig flygplansmodell, (”Create a model of a commercial airplane where some parts are taken from a car or a boat” 2024)\n\n\n\nOm en flygplansmodell ser endast till viss del ut som ett flygplan kommer modellen inte vara lämplig att använda för att förstå eller förenkla verkligheten. Detsamma gäller för regressionsmodeller; om modellen inte uppfyller dess antaganden riskerar slutsatser som dras inte stämma överens med verkligheten.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduktion till regression</span>"
    ]
  },
  {
    "objectID": "01-regression/00-intro-regression.html#studier-och-andra-variabler",
    "href": "01-regression/00-intro-regression.html#studier-och-andra-variabler",
    "title": "1  Introduktion till regression",
    "section": "1.3 Studier och andra variabler",
    "text": "1.3 Studier och andra variabler\nEn regressionsmodell behöver nödvändigtvis inte beskriva ett “orsak-och-verkan” samband, eller som vi brukar benämna det, ett kausalt samband. Samband kan ibland uppstå utav ren slump där det inte finns någon logisk koppling mellan variablerna. Denna typ av samband benämns som korrelationssamband. Trots att korrelationssamband rent matematiskt beskriver en relation mellan den ena variabeln och den andra, är det i vissa fall inte lämpligt eller relevant att använda eller tolka modellen i verkligheten.\n\n\n\n\n\n\n\n\nFigur 1.3: Sambandet mellan antalet filmer som Nicolas Cage medverkade i och antalet dödsfall av drunkning mellan 1999 och 2009 i USA (”CDC - NCHS - National Center for Health Statistics — cdc.gov”; ”Nicolas Cage | Actor, Producer, Director — imdb.com”)\n\n\n\n\n\nFigur 1.3 uppvisar ett exempel på korrelationssamband där de två variablerna inte har någon logisk koppling till varandra utan endast har observerats ha en positiv korrelation. Att beskriva detta samband skulle inte ge någon information om verkligheten så en viktig del av regressionsanalys är att bedöma lämpligheten och relevansen av utvalda variabler. Rent matematiskt kan inte heller en regressionsmodell urskilja mellan kausala eller korrelationssamband vilket innebär att vi som analytiker måste ta hänsyn till vilken sorts data och hur data har samlats in för att använda och tolka modellerna på rätt sätt.\nExemplet i figuren är insamlad som en observationsstudie där mätvärden (antal dödsfall och filmer) på enheterna (år) har observerats från olika registerdata. Vi har inte kunnat styra vilken relation dessa variabler har till varandra och studien i sig har inte tagit hänsyn till någon specifik orsak och verkan mellan de två. Vi kan därför endast dra slutsatser om korrelationssamband från en observationsstudie, vi kan säga att desto fler filmer Nicolas Cage medverkar i medför ett större antal dödsfall, vilket egentligen inte är relevant, men vi kan inte säga något om den kausala effekten.\nFör att kunna dra slutsatser om kausala samband behöver vi genomföra en experimentell studie där vi styr vilka mätvärden som enheter får eller har och responsvariablen antas vara en direkt effekt från de förklarande variablerna. Medicinska studier, till exempel studier om Covid-vaccinets effektivitet på att motverka en infektion, är typiska exempel på experimentella studier där en förklarande variabel (dos) ges till vissa grupper av enheter där andra påverkande effekter kontrolleras för att justera den förklarande variabelns verkliga påverkan.\n\n1.3.1 Kontrollvariabler\nI en observationsstudie kan vi ibland observera kontrollvariabler som kan justera den förklarande variabelns faktiska påverkan men det är främst i experimentella studier som dessa typer av variabler kan användas. Okända variabler kallas för confounding-effekter och antas påverka både den förklarande och responsvariabeln.\nI följande två figurer visas den huvudsakliga förklarande variabeln och den valda responsvariabeln med ovaler. De kända (heldragen) och okända (streckade) kontrollvariablerna visas som rektanglar.\n\n\n\n\n\n\n\n\n\n\nG\n\n\n\nOkänd\n\nOkänd\n\n\n\nFilmer\n\nFilmer\n\n\n\nOkänd-&gt;Filmer\n\n\n\n\n\nDödsfall\n\nDödsfall\n\n\n\nOkänd-&gt;Dödsfall\n\n\n\n\n\nFilmer-&gt;Dödsfall\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1.4: Exempel på relationen mellan variabler i en observationsstudie.\n\n\n\nEftersom sambandet mellan filmer och dödsfall förmodligen endast uppkommit av slumpen kan det finnas andra okända variabler som påverkar de båda.\n\n\n\n\n\n\n\n\n\n\nG\n\n\n\nÅlder\n\nÅlder\n\n\n\nBlodtryck\n\nBlodtryck\n\n\n\nÅlder-&gt;Blodtryck\n\n\n\n\n\nKön\n\nKön\n\n\n\nKön-&gt;Blodtryck\n\n\n\n\n\nMedicin\n\nMedicin\n\n\n\nMedicin-&gt;Blodtryck\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1.5: Exempel på relationen mellan variabler i en experimentell studie.\n\n\n\nEffekten av en medicin på blodtryck kan också påverkas av personens ålder och kön (Gu m.fl. 2008) vilka inkluderas i modellen för att isolera den förklarande variabelns effekt. I alla dessa exempel är det endast en effekt som är av intresse att undersöka, trots att modellen innehåller flera variabler och tillhörande lutningsparametrar.\n\n\n\n\n”CDC - NCHS - National Center for Health Statistics — cdc.gov”. https://www.cdc.gov/nchs/.\n\n\n”Create a model of a commercial airplane where some parts are taken from a car or a boat”. 2024. OpenAI. https://chat.openai.com/chat.\n\n\nGu, Qiuping, Vicki L. Burt, Ryne Paulose-Ram, och Charles F. Dillon. 2008. ”Gender Differences in Hypertension Treatment, Drug Utilization Patterns, and Blood Pressure Control Among US Adults With Hypertension: Data From the National Health and Nutrition Examination Survey 1999–2004”. American Journal of Hypertension 21 (7): 789–98. https://doi.org/10.1038/ajh.2008.185.\n\n\n”Nicolas Cage | Actor, Producer, Director — imdb.com”. https://www.imdb.com/name/nm0000115/.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduktion till regression</span>"
    ]
  },
  {
    "objectID": "01-regression/01-explorative-analysis.html",
    "href": "01-regression/01-explorative-analysis.html",
    "title": "2  Utforska samband",
    "section": "",
    "text": "2.1 Pingviner vid Antarktis\nDet första steget i en regressionsanalys är att utforska datamaterialet. Oavsett om vi genomfört en observations- eller experimentell studie har vi förmodligen innan insamlingen valt ut en responsvariabel som vi vill beskriva eller prediktera med hjälp av andra variabler. Målet med att utforska data är att få insikter som kan hjälpa oss på traven i senare steg, till exempel vilka variabler som är relevanta att inkludera i en modell, hur sambanden verkar se ut, finns det några problem med det insamlade data som behöver korrigeras.\nNågra punkter som vi behöver få svar på är:\nNär vi fått svar på alla dessa punkter är det mycket lättare att skapa en korrekt modellstruktur och även att utvärdera anpassade modeller. Vi kan undersöka dessa punkter genom enklare funktioner (ex. mean(), min(), summary(variabel)) men vi kan också få relevant information genom enskilda och parvisa visualiseringar av variablerna.\nÅterkommande i underlaget kommer ett insamlat datamaterial från ett forskarteam vid Antarktis användas. Teamet har mellan 2007 och 2009 samlat in information om 333 pingviner vid tre öar runtomkring Palmer Research Station. Datamaterialet kan hämtas via paketet palmerpenguins (Horst, Hill, och Gorman 2020) och läsas in i R via följande kod:\n# Glöm inte att installera paketet om du inte har gjort det förut\n# install.packages(\"palmerpenguins\")\n\n# Laddar paketet med datamaterialet\nrequire(palmerpenguins)\n\n# Filtrerar bort observationer med saknade värden\npenguins &lt;- \n  penguins %&gt;% \n  filter(!is.na(sex))\nVi kan titta närmare på ett urval av datamaterialet i Tabell 2.1.\nVisa kod\n# Generera en formaterad tabell med hjälp av kable() och formatera den med hjälp av kable_styling()\npenguins %&gt;% \n  slice_head(n = 5) %&gt;% \n  kable() %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 2.1: Urval av observationer från datamaterialet.\n\n\n\n\n \n  \n    species \n    island \n    bill_length_mm \n    bill_depth_mm \n    flipper_length_mm \n    body_mass_g \n    sex \n    year \n  \n \n\n  \n    Adelie \n    Torgersen \n    39.1 \n    18.7 \n    181 \n    3750 \n    male \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    39.5 \n    17.4 \n    186 \n    3800 \n    female \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    40.3 \n    18.0 \n    195 \n    3250 \n    female \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    36.7 \n    19.3 \n    193 \n    3450 \n    female \n    2007 \n  \n  \n    Adelie \n    Torgersen \n    39.3 \n    20.6 \n    190 \n    3650 \n    male \n    2007\nFrån tabellen kan vi utläsa följande variabler:\nVi kommer fokusera på näbblängden som vår responsvariabel i efterföljande exempel. I och med att datamaterialet är en observationsstudie kommer vi inte kunna dra slutsatser om kausala samband, utan kan endast undersöka korrelationssamband mellan pingvinernas olika egenskaper.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Utforska samband</span>"
    ]
  },
  {
    "objectID": "01-regression/01-explorative-analysis.html#sec-example-data",
    "href": "01-regression/01-explorative-analysis.html#sec-example-data",
    "title": "2  Utforska samband",
    "section": "",
    "text": "Notera\n\n\n\nSom en del av utforskningen kan vi identifiera saknade värden på vissa variabler och väljer att filtrera bort dessa variabler i just detta exempel. Hantering av saknade värden är ett stort fält inom statistiken och det finns flertalet metoder som kan imputera (skatta det saknade värdet) värden så att vi inte behöver ta bort hela observationer från undersökningen.\nEn enkel imputeringsmetod är medelvärdesimputering där vi byter ut det saknade värdet med medelvärdet av de övriga mätvärdena eller typvärdet ifall en kvalitativ variabel ska imputeras. I praktiken används mer avancerade metoder som kan tillämpas i många olika fall där vi också tar hänsyn till annan information om observationerna.\n\n\n\n\n\n\n\n\n\n\nNotera\n\n\n\nFunktionen kable() kommer från paketet knitr som måste (installeras och) laddas in innan vi kan använda den. Funktionen kable_styling() kommer från paketet kableExtra som på samma vis måste (installeras och) laddas in innan vi kan använda den.\n\n\n\n\nspecies: Pingvinens art mäts som en kvalitativ variabel och vi kan inte säga att en art är “bättre” eller “större” än någon annan. Vi kan alltså inte rangordna kategorierna och denna variabel följer då en nominalskala.\nisland: Vilken ö pingvinen har befunnit sig på vid mättidpunkten är också en kvalitativ variabel som inte går att rangordna. Därav följer även denna variabel en nominalskala.\nbill_length_mm: En kvantitativ variabel som mäter längden på näbben i millimeter (mm). Längd är en typisk variabel som följer en kvotskala eftersom det finns en tydlig nollpunkt.\nbill_depth_mm: Mäter näbbens djup i millimeter och följer samma resonemang som näbblängden.\nflipper_length_mm: Ytterligare en variabel som mäter en längd, nu längden av pingvinens fena. Samma resonemang som näbbens olika längder kan föras.\nbody_mass_g: Vikt av pingvinen mätt i gram. Även vikt har en tydlig nollpunkt och variabeln anses vara kvantitativ och följa en kvotskala.\nsex: Pingvinens biologiska kön vilket är en kvalitativ variabel som inte går att rangordna, nominalskala.\nyear: Denna variabel är lite svårare att bedöma då den mäter året då pingvinen är mätt som en numerisk variabel (heltal så R har sparat det som en int), men variabeln i sig behöver inte bedömas vara kvantitativ i denna kontext. Vi går inte in vidare på detta utan för enkelhetens skull kan vi säga att eftersom det går att beräkna differenser mellan åren, (det är 1 år mellan 2007 och 2008) men ingen tydlig nollpunkt finns på skalan, så kan vi anse denna variabel vara en kvantitativ variabel som följer en intervallskala.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Utforska samband</span>"
    ]
  },
  {
    "objectID": "01-regression/01-explorative-analysis.html#visualisera-responsvariabeln",
    "href": "01-regression/01-explorative-analysis.html#visualisera-responsvariabeln",
    "title": "2  Utforska samband",
    "section": "2.2 Visualisera responsvariabeln",
    "text": "2.2 Visualisera responsvariabeln\nSom ett första steg i den explorativa analysen kan vi visualisera fördelningen av responsvariabeln med ett histogram.\n\n\nVisa kod\nggplot(penguins) + aes(x = bill_length_mm) + \n  geom_histogram(bins = 30, fill = \"steelblue\", color = \"black\") +\n  theme_bw() +\n  labs(x = \"Näbblängd (mm)\", y = \"Antal\")\n\n\n\n\n\n\n\n\nFigur 2.1: Histogram över näbblängdens fördelning\n\n\n\n\n\nFigur 2.1 ger oss en bild av variabelns egenskaper och ifall materialet innehåller några extremvärden som kan vara svåra att plocka upp med en modell. Näbblängden verkar ha en bimodal struktur med två masscentrum vid 38-40 och 50 mm. Vi ser att majoriteten av observationerna ligger mellan ca 35-52 mm men det finns också enstaka observationer omkring 58-60 mm som verkar vara något avvikande stora näbbar.\nAtt fördelningen inte ser normalfördelad ut spelar ingen roll då vi måste titta på fördelningen av responsvariabeln med avseende på de förklarande variablerna för att kontrollera en regressionsmodells antaganden.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Utforska samband</span>"
    ]
  },
  {
    "objectID": "01-regression/01-explorative-analysis.html#sec-pairwise-visualization",
    "href": "01-regression/01-explorative-analysis.html#sec-pairwise-visualization",
    "title": "2  Utforska samband",
    "section": "2.3 Parvisa samband",
    "text": "2.3 Parvisa samband\nDatamaterialet innehåller ett flertal potentiella förklarande variabler som skulle kunna inkluderas i en modell. Beroende på hur en undersökning gått till kan variabler väljas bort om de inte anses ha ett logiskt samband med responsvariabeln, t.ex. id-variabler är inte relevanta att undersöka. I vårt exempel finns en variabel som beskriver årtal vilket vi i ett första skede kan anta inte har något logiskt samband med näbblängden. Då återstår sex andra variabler som skulle kunna inkluderas i modellanpassningen.\n\n2.3.1 Kvantitativa förklarande variabler\nFör kvantitativa förklarande variabler kan vi skapa ett spridningsdiagram där varje observation representeras med en punkt. Den förklarande variabeln placeras på x-axeln och responsvariabeln placeras på y-axeln. Med hjälp av punktsvärmen i spridningsdiagrammet kan vi få information om sambandet mellan de två variablerna. Det är fyra huvudsakliga punkter som vi fokuserar på:\n\nÄr sambandet linjärt?\nÄr sambandet positivt eller negativt?\nÄr sambandet starkt eller svagt?\nFörekommer det några extremvärden?\n\n\n\nVisa kod\nggplot(penguins) + aes(x = body_mass_g, y = bill_length_mm) +\n  geom_point(color = \"steelblue\") + \n  theme_bw() + \n  labs(x = \"Kroppsvikt (g)\", y = \"Näbblängd (mm)\")\n\n\n\n\n\n\n\n\nFigur 2.2: Spridningsdiagram som visar sambandet mellan kroppsvikt och näbblängd\n\n\n\n\n\nFigur 2.2 visar att sambandet ser till största del linjärt ut då en konstant förändring (ökning) av kroppsvikt leder till en konstant förändring (ökning) av näbblängden. Majoriteten av punkterna verkar följa denna trend, vilket tyder på ett relativt starkt samband, dock finns det ett flertal observationer (markerade i Figur 2.3) som avviker från detta. Dessa observationer har en lägre kroppsvikt men samma näbblängd som pingviner med en större kroppsvikt och påverkar styrkan av sambandet.\n\n\n\n\n\n\n\n\nFigur 2.3: Spridningsdiagram med markerat område i cirkeln\n\n\n\n\n\nVi kan beräkna Pearson’s korrelationskoefficient (\\(r\\)) för att inte behöva förlita oss på den subjektiva tolkningen av styrkan.1 Denna koefficient mäter styrkan på det linjära sambandet mellan två kvantitativa variabler och är ett lämpligt mått i just detta fall. Ett värde nära 0 tyder på inget eller ett svagt samband medan värden nära -1 eller +1 tyder på ett starkt negativt respektive positivt samband.\n\\[\nr = 0.589\n\\]\nDå korrelationskoefficienten är nära 0.6 tyder det på att sambandet är måttligt starkt.\n\n\n\n\n\n\nViktigt\n\n\n\nOm spridningsdiagrammet uppvisar ett icke-linjärt och icke-monotont (konstant) samband kommer koefficienten inte beskriva sambandets styrka på rätt sätt. Det är lätt hänt att korrelationskoefficienten används som den enda utforskande metoden då den är enkel att beräkna för flera olika par av variabler, men den kan ofta missa relevant information. Visualisering möjliggör identifieringen av komplexa samband som ofta medför att vi behöver hantera modellen på olika sätt.\n\n\nFigur 2.2 visar också vissa observationer som skulle kunna anses vara extremvärden. Till exempel skulle \\(\\{x = ~2700, y = ~47\\}\\) och \\(\\{x = ~3700, y = ~58\\}\\) vara observationer som avviker extremt från det tilltänkta sambandet och andra observationer. Detaljerad analys av extremvärden lämnar vi till senare kapitel, men i ett utforskande syfte noterar vi att vi kan ha observationer som kommer påverka modellanpassningen.\nSammanfattningsvis kan vi säga att sambandet mellan kroppsvikt och näbblängd är:\n\nlinjärt,\npositivt,\nmåttligt starkt,\nmed ev. några extremvärden.\n\nNär vi ska skapa vår första modell kommer det nog räcka med att inkludera en enkel \\(\\beta_1 \\cdot \\text{kroppsvikt}\\) term i modelleringen.\n\n2.3.1.1 Övriga kvantitativa variabler\nSamma utforskning bör genomföras för alla par av variabler, i detta fall också näbbredd och fenlängd:\n\n\n\n\n\n\n\n\nFigur 2.4: Spridningsdiagram som visar sambandet mellan näbbredd och näbblängd\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 2.5: Spridningsdiagram som visar sambandet mellan fenlängd och näbblängd\n\n\n\n\n\nBåda variablerna ser ut att ha linjärt samband med responsvariabeln. Figur 2.4 tyder på att sambandet mellan näbbredd och näbblängd är svagt negativt (\\(r = -0.229\\)) då punkterna är mycket utspridda medan Figur 2.5 tyder på ett lite starkare positivt samband (\\(r = 0.653\\)) i linje med Figur 2.2.\nEtt nytt fenomen som vi kan se i Figur 2.4 är att vi verkar ha flera punktsvärmar som var och en har ett positivt samband trots att vi tolkade det övergripande sambandet som svagt negativt. Om vi endast hade beräknat korrelationskoefficienten hade detta fenomen undgått vår analys. Figur 2.6 är ett exempel på Simpson’s Paradox som vi kommer undersöka närmare senare i detta underlag.\n\n\n\n\n\n\n\n\nFigur 2.6: Grupperingar av observationer\n\n\n\n\n\n\n\n\n2.3.2 Kvalitativa förklarande variabler\nVi kan inte använda spridningsdiagram för att visualisera sambandet mellan kvalitativa förklarande variabler och en kontinuerlig responsvariabel. Vi behöver istället använda visualiseringar som tar hänsyn till den kvalitativa skalan, vanligtvis ordinal eller nominalskala. Det finns flera olika sätt att visualisera fördelningen av responsvariabeln för de olika nivåerna av den förklarande, till exempel grupperade histogram eller lådagram, men en typ av visualisering som visar detaljerna i fördelningen är ett fioldiagram. Ett fioldiagram består utav en spegling av ett densitetsdiagram, där områden med många observationer har en större yta under kurvan.\nVia ggplot2 kan vi skapa ett sådant diagram genom geom_violin():\n\n\nVisa kod\nggplot(penguins) + \n  aes(x = species, y = bill_length_mm) +\n  geom_violin(fill = \"steelblue\") + \n  theme_bw() + \n  labs(x = \"Art\", y = \"Näbblängd (mm)\")\n\n\n\n\n\n\n\n\nFigur 2.7: Fördelningen av näbblängd uppdelat på art\n\n\n\n\n\nFigur 2.7 visar att Adelie-pingviner överlag har en kortare näbblängd jämfört med Chinstrap och Gentoo då fördelningens mittpunkt förhåller sig kring 38-40 mm. Chinstrap-pingviner har en något större andel pingviner med en längd större än 50 mm medan Gentoo har en större andel med en längd mindre än 50 mm.\n\n\n\n\n\n\n\n\nFigur 2.8: Fördelningen av näbblängd uppdelat på kön\n\n\n\n\n\nFigur 2.8 har en liten annorlunda form, med två stora massor för respektive kategori. Här har vi förmodligen en indikation på att kön inom de olika arterna har en påverkan och att hanar generellt har en större näbblängd än motsvarande honor av samma art.\n\n\n\n\n\n\n\n\nFigur 2.9: Fördelningen av näbblängd uppdelat på ö\n\n\n\n\n\nFigur 2.9 antyder att pingviner på ön Torgersen har en mindre näbblängd än vid övriga öar, men här behöver vi resonera huruvida denna variabel faktiskt beskriver sambandet eller om det finns något annat fenomen som kan förklara samma sak, till exempel om en ö endast har pingviner av en viss art. Mer om dessa sorters samband kommer senare i underlaget.\nSlutsatsen från dessa visualiseringar är att det verkar finnas ett samband mellan art och kön med näbblängd och de två variablerna bör inkluderas i modellen. Vi behöver nu fundera på hur vi på ett lämpligt sätt kan inkludera en kvalitativ variabel innehållande text i en matematisk modell som kräver siffror.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Utforska samband</span>"
    ]
  },
  {
    "objectID": "01-regression/01-explorative-analysis.html#sec-exercise-explore",
    "href": "01-regression/01-explorative-analysis.html#sec-exercise-explore",
    "title": "2  Utforska samband",
    "section": "2.4 Övningsuppgifter",
    "text": "2.4 Övningsuppgifter\nAnvänd datamaterialet marketing som går att hämta via:\n\ndevtools::install_github(\"kassambara/datarium\")\n\ndata(\"marketing\", package = \"datarium\")\n\nDatamaterialet innehåller tre variabler som beskriver reklambudget för YouTube, Facebook och nyhetstidningar (tusentals dollar) samt försäljningen (tusentals enheter). Vi vill modellera sambandet mellan försäljningen och de tre reklamkällorna.\n\nUndersöka variablernas typ och skala.\nSammanställ beskrivande statistik för respektive variabel.\nVisualisera fördelningen av respektive variabel.\nSkapa ett spridningsdiagram för varje förklarande variabel med responsvariabeln och tolka de utefter de fyra bitar information som ett spridningsdiagram visar.\nSammanfatta dina iakttagelser och motivera vilka förklarande variabler som bör inkluderas i en modell och hur de bör struktureras.\n\n\n\n\n\nHorst, Allison Marie, Alison Presmanes Hill, och Kristen B Gorman. 2020. palmerpenguins: Palmer Archipelago (Antarctica) penguin data. https://doi.org/10.5281/zenodo.3960218.\n\n\nKendall, Maurice G. 1955. Rank correlation methods, 2nd ed. Oxford, England: Hafner Publishing Co.\n\n\nSpearman, C. 1904. ”The Proof and Measurement of Association between Two Things”. The American Journal of Psychology 15 (1): 72–101. http://www.jstor.org/stable/1412159.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Utforska samband</span>"
    ]
  },
  {
    "objectID": "01-regression/01-explorative-analysis.html#footnotes",
    "href": "01-regression/01-explorative-analysis.html#footnotes",
    "title": "2  Utforska samband",
    "section": "",
    "text": "Eller andra mått för att beräkna styrkan på samband, t.ex. Kendall (Kendall 1955) eller Spearman (Spearman 1904).↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Utforska samband</span>"
    ]
  },
  {
    "objectID": "01-regression/02-model-structure.html",
    "href": "01-regression/02-model-structure.html",
    "title": "3  Modellanpassning",
    "section": "",
    "text": "3.1 Indikatorvariabler\nEfter att ha sammanställt iaktaggelser från visualiseringar och beskrivande statistik, är nästa steg i processen att bygga modellens struktur. Det enklaste är att börja med de kvantitativa variablerna som (vanligtvis) endast kräver en term vardera i modellen.\n\\[\n\\text{näbblängd} = \\beta_0 + \\beta_1 \\cdot \\text{kroppsvikt} + \\beta_2 \\cdot \\text{fenlängd} + \\beta_3 \\cdot \\text{näbbredd} + \\cdots + E\n\\tag{3.1}\\]\nOavsett om modellen innehåller en eller flera förklarande variabler behöver vi alltid ha i åtanke de fem antaganden som presenterades i Avsnitt 1.2 framförallt antagandet om linjäritet. Har vi upptäckt icke-linjära samband i de parvisa visualiseringarna räcker det oftast inte med att inkludera en term i modellen. Detta kommer vi återkomma till i Kapitel 7.\nEn regressionsmodell kan inte hantera kvalitativa variabler direkt, exempelvis \\(\\beta_4 \\cdot \\text{art}\\), då variabelns värden beskriver kategorier inte värden från en numerisk skala. Detta gäller även om den kvalitativa variabeln är kodad numerisk. En lutningsparameter beskriver den konstanta förändring i responsvariabeln när den tillhörande förklarande variabeln ökar med en enhet, men en kvalitativ variabel har oftast ingen enhet (ex. nominalskala) och inte heller konstanta förändringar mellan intilliggande värden (ex. ordinalskala). Istället måste vi transformera den kvalitativa variabeln numerisk genom indikatorvariabler (även kallad dummyvariabler).\nSom namnet antyder används indikatorvariabler för att indikera vilken kategori en observation har uppmätt på den kvalitativa variabeln. Vi behöver då skapa en begränsad mängd indikatorvariabler som på ett tydligt sätt visar exakt en kategori per observation.\nAnta att en kvalitativ variabel har 3 kategorier: \\[\n\\begin{bmatrix}A\\\\B\\\\C\\end{bmatrix}\n\\] Vi kan börja med att skapa en indikatorvariabel för kategori A som antar värdet 1 om observationen har uppmätt kategorin, 0 annars:\n\\[\n\\begin{bmatrix}A\\\\B\\\\C\\end{bmatrix} = \\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix}\n\\] Med endast en indikatorvariabel kan vi inte tydligt identifiera om en observation har uppmätt kategori B eller C då de båda har värdet 0, så vi lägger till ytterligare en indikator som antar värdet 1 om observationen uppmätt kategori B, 0 annars:\n\\[\n\\begin{bmatrix}A\\\\B\\\\C\\end{bmatrix} = \\begin{bmatrix}1 & 0\\\\0 & 1\\\\0 & 0\\end{bmatrix}\n\\] Nu skulle det vara lätt att fortsätta, att skapa en indikatorvariabel även för den sista kategorin, men det behövs inte. Om båda indikatorvariablerna är 0 har vi lyckats identifiera att observationen uppmätt kategori C och ytterligare en variabel är bara onödig information.\nDen sista kategorin blir också vår referenskategori, den kategori som de andra indikatorvariablernas effekter tolkas gentemot. När vi tolkar lutningsparametrar för indikatorvariabler, till exempel indikatorvariabeln för A, mäts förändringen i \\(Y\\) när \\(X = A\\) jämfört med när \\(X = C\\).\nGenerellt skapas \\(\\text{antal kategorier} - 1\\) indikatorvariabler för varje kvalitativa variabel som ska inkluderas i en regressionsmodell. Valet av referenskategori för respektive är godtyckligt, men vanligtvis används den första eller sista kategorin för detta ändamål.\nFör att slutföra modelleringen av Ekvation 3.1 ska vi inkludera Art och Kön i modellen. Då behöver vi skapa två respektive en indikatorvariabel enligt:\n\\[\\begin{align*}\n  Gentoo &= \\begin{cases}\n            1 \\qquad \\text{om art Gentoo}\\\\\n            0 \\qquad \\text{annars}\n        \\end{cases}\\\\\n  Chinstrap &= \\begin{cases}\n      1 \\qquad \\text{om art Chinstrap}\\\\\n      0 \\qquad \\text{annars}\n  \\end{cases}\n\\end{align*}\\]\noch\n\\[\\begin{align*}\n  hane &= \\begin{cases}\n            1 \\qquad \\text{om hane}\\\\\n            0 \\qquad \\text{annars}\n        \\end{cases}\n\\end{align*}\\]\nför att till slut skapa följande modell:\n\\[\n\\text{näbblängd} = \\beta_0 + \\beta_1 \\cdot \\text{kroppsvikt} + \\beta_2 \\cdot \\text{fenlängd} + \\beta_3 \\cdot \\text{näbbredd} + \\beta_4 \\cdot \\text{Gentoo} + \\beta_5 \\cdot \\text{Chinstrap} + \\beta_6 \\cdot \\text{hane} + E\n\\tag{3.2}\\]\ndär Adelie och honor agerar referenskategori för respektive kvalitativ variabel.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modellanpassning</span>"
    ]
  },
  {
    "objectID": "01-regression/02-model-structure.html#sec-indicator-variable",
    "href": "01-regression/02-model-structure.html#sec-indicator-variable",
    "title": "3  Modellanpassning",
    "section": "",
    "text": "Viktigt\n\n\n\nRent matematiskt kommer tre indikatorvariabler modellera ett perfekt samband och skapa problem med singularitet i beräkningarna.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modellanpassning</span>"
    ]
  },
  {
    "objectID": "01-regression/02-model-structure.html#modellanpassning",
    "href": "01-regression/02-model-structure.html#modellanpassning",
    "title": "3  Modellanpassning",
    "section": "3.2 Modellanpassning",
    "text": "3.2 Modellanpassning\nEkvation 3.2 visar den sanna modell som utgår ifrån populationens alla observerade värden, men nästintill alla undersökningar utgår från någon form av urval. Även en totalundersökning under en viss period kan anses vara ett urval i tiden om modellen avses att användas efter undersökningsperioden är slutförd.\nVi kan beteckna den anpassade modellen med dess skattade parametrar enligt:\n\\[\n\\hat{y}_i = b_0 + b_1 \\cdot x_{1i} + b_2 \\cdot x_{2i} + b_3 \\cdot x_{3i} + b_4 \\cdot x_{4i} + b_5 \\cdot x_{5i} + b_6 \\cdot x_{6i}\n\\tag{3.3}\\] där \\[\\begin{align*}\n  \\hat{y}_i &= \\text{responsvariabelns skattade värde för observation i}\\\\\n  b_0 &= \\text{skattning av interceptet}\\\\\n  b_1 - b_6 &= \\text{skattning av lutningsparametrar}\n\\end{align*}\\]\n\n\n\n\n\n\nNotera\n\n\n\nViss litteratur använder \\(\\hat{\\beta}\\) som beteckning för skattade parametrar.\n\n\nModellen anpassas med hjälp av minsta kvadratskattningen (eng. Ordinary Least Squares, OLS), där syftet är att minimera modellens totala fel. Vi kan notera att Ekvation 3.3 saknar feltermen \\(E\\) som inkluderas tidigare, vilket kommer från att den anpassade modellen endast består av regressionslinjen. Kom ihåg att en regressionsmodell ämnar att ge en förenkling av verkligheten. Men \\(E\\) beskrev ju felet i modellen och om vi ska minimera det totala felet behöver vi på något sätt ta hänsyn till denna term i modellanpassningen.\nAnta att vi anpassar en modell enbart på kroppsvikt och näbblängd. Om vi skulle projicera den anpassade enkla linjära modellen i ett spridningsdiagram över de två variablerna (Figur 3.1) skulle linjen inte lyckas träffa alla punkter exakt, varje enskilda observation kommer ligga ett visst avstånd från regressionslinjen. Detta avstånd är observationens residual som betecknas med \\(e_i\\).\n\n\n\n\n\n\n\n\nFigur 3.1: Visualisering av regressionsmodellens residualer\n\n\n\n\n\nMatematiskt beräknar vi \\(e_i = Y_i - \\hat{Y}_i\\), där \\(Y_i\\) är det observerade värdet (punkten) och \\(\\hat{Y}_i\\) är modellens anpassade värde (linjen). Minsta kvadratskattningen beräknar modellens alla parametrar så att det totala felet (Sum of Squares of Error, SSE) för alla residualer blir så litet som möjligt.\n\\[\nSSE = \\sum_{i = 1}^n e_i^2 = \\sum_{i = 1}^n (Y_i - \\hat{Y}_i)^2\n\\tag{3.4}\\]\nI en enkel linjär regression går det att härleda fram analytiska lösningar för de två parameterskattningarna, \\(b_0\\) och \\(b_1\\), som minimerar SSE men så fort vi inkluderar flera variabler blir detta betydligt svårare. Istället förlitar vi (och R) oss på matrisberäkningar som presenteras mer i Avsnitt 3.3.\n\n\n\n\n\n\nViktigt\n\n\n\nFormler för parameterskattningarna i en enkel linjär regression är: \\[\\begin{align*}\n  b_1 &= \\frac{\\sum_{i=1}^n(X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sum_{i=1}^n(X_i - \\bar{X})^2}\\\\\n  b_0 &= \\bar{Y} - b_1 \\cdot \\bar{X}\n\\end{align*}\\]\n\\(b_1\\) kan också omformuleras till beräkningsformeln: \\[\n\\begin{aligned}\n\\frac{\\sum_{i=1}^n(X_i \\cdot Y_i) - \\frac{\\sum_{i=1}^nX_i \\cdot \\sum_{i=1}^nY_i}{n}}{\\sum_{i=1}^nX_i^2 - \\frac{(\\sum_{i=1}^nX_i)^2}{n}}\n\\end{aligned}\n\\]\n\n\nVi kan också använda den anpassade modellen för att prediktera nya värden på responsvariabeln för nya observationer. Från den anpassade regressionslinjen byter vi ut respektive variabel med observationens faktiska värde och får till slut en enkel summa som beskriver responsvariabelns värde på linjen. Mer om hur prediktioner används i relation till populationen tas upp i Avsnitt 5.4.\n\n3.2.1 Modellanpassning i R\nFör att anpassa en linjär regressionsmodell i R används funktionen lm() med följande argument:\n\nformula: modellens struktur som ett formelobjekt\ndata: datamaterialet som variablerna hittas\n\nEtt formelobjekt är ett speciellt format som R använder för att beskriva relationen mellan variabler. Generellt anges formatet som y ~ x där x består utav de olika förklarande variablerna, till exempel bill_length_mm ~ body_mass_g + bill_depth_mm. Det finns ett kortkommando (~ .) som används i exemplet nedan, där alla övriga variabler inkluderas i högerledet , men det kräver att vi först har ett datamaterial enbart bestående av de förklarande variablerna från Ekvation 3.2.\nVi måste också se till att alla variabler i datamaterialet har rätt variabeltyp som vi förväntar oss. Vi identifierade i Avsnitt 2.1 att vi hade tre kvantitativa variabler och två kvalitativa variabler som i R motsvarar typerna numeric och Factor. Att använda sig av Factor underlättar transformationen till indikatorvariabler eftersom R vet att den måste göra så för att modellen ska fungera. Om de kvalitativa variablerna var av typen character eller kodad numeric är det inte säkert att R skapar indikatorvariabler. Vi kan undersöka variabeltyperna för penguins med hjälp av str().\n\n# Tar endast med de variabler som vi ansåg ha ett samband med responsvariabeln\nmodelData &lt;- \n  penguins %&gt;% \n  select(\n    bill_length_mm,\n    body_mass_g,\n    flipper_length_mm,\n    bill_depth_mm,\n    species,\n    sex\n  )\n\n# Anpassar angiven modell\nsimpleModel &lt;- lm(formula = bill_length_mm ~ ., data = modelData)\n\nMed summary() får vi en detaljerad utskrift för modellen som inkluderar de anpassade regressionskoefficienterna. Vid presentation av en sådan utskrift kan vi använda kable() eller xtable() för att få en snyggare utskrift.\n\nVisa kod\nsummary(simpleModel)\n\n\n\n\n\n\n\nCall:\nlm(formula = bill_length_mm ~ ., data = modelData)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-7.3939 -1.3424 -0.0421  1.2695 11.4274 \n\nCoefficients:\n                   Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       1.502e+01  4.374e+00   3.433 0.000674 ***\nbody_mass_g       1.084e-03  4.231e-04   2.562 0.010864 *  \nflipper_length_mm 6.856e-02  2.315e-02   2.961 0.003293 ** \nbill_depth_mm     3.130e-01  1.541e-01   2.032 0.043000 *  \nspeciesChinstrap  9.566e+00  3.497e-01  27.351  &lt; 2e-16 ***\nspeciesGentoo     6.404e+00  1.030e+00   6.215 1.56e-09 ***\nsexmale           2.030e+00  3.892e-01   5.215 3.27e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.217 on 326 degrees of freedom\nMultiple R-squared:  0.8386,    Adjusted R-squared:  0.8356 \nF-statistic: 282.3 on 6 and 326 DF,  p-value: &lt; 2.2e-16\n\n\n\n\nFigur 3.2: Inte särskilt snygg utskrift\n\n\n\n\n\nVisa kod\nsummary(simpleModel) %&gt;% \n  coef() %&gt;% \n  as_tibble(rownames = NA) %&gt;% \n  rownames_to_column() %&gt;% \n  rename(\n    ` ` = rowname,\n    Skattning = Estimate,\n    Medelfel = `Std. Error`,\n    `t-värde` = `t value`,\n    `p-värde` = `Pr(&gt;|t|)`\n  ) %&gt;% \n  kable(\n    digits = 4\n  ) %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 3.1: En snygg utskrift av modellens anpassade parametrar\n\n\n\n\n \n  \n     \n    Skattning \n    Medelfel \n    t-värde \n    p-värde \n  \n \n\n  \n    (Intercept) \n    15.0166 \n    4.3742 \n    3.4330 \n    0.0007 \n  \n  \n    body_mass_g \n    0.0011 \n    0.0004 \n    2.5617 \n    0.0109 \n  \n  \n    flipper_length_mm \n    0.0686 \n    0.0232 \n    2.9608 \n    0.0033 \n  \n  \n    bill_depth_mm \n    0.3130 \n    0.1541 \n    2.0316 \n    0.0430 \n  \n  \n    speciesChinstrap \n    9.5655 \n    0.3497 \n    27.3508 \n    0.0000 \n  \n  \n    speciesGentoo \n    6.4044 \n    1.0304 \n    6.2154 \n    0.0000 \n  \n  \n    sexmale \n    2.0297 \n    0.3892 \n    5.2153 \n    0.0000 \n  \n\n\n\n\n\n\n\n\n\n\n\n\n\nTips 3.1\n\n\n\nFör att skapa denna snygga utskrift av koefficienterna behöver vi plocka ut en enskild del av summary() med hjälp av coef(). I dokumentationen för lm() finns mer information om vad som kan hämtas från det resulterande regressionsobjektet.\nR är ett objektorienterat programmeringsspråk, och funktionen lm() returnerar ett objekt av klassen ”lm”, vilket är en lista. Det är enkelt att plocka önskade delar från den listan vid behov. Det finns en mängd funktioner kopplade till objekt av klassen ”lm”:\n\ncoef(): Ger regressionskoefficienter\nresiduals(): Ger residualerna\nfitted(): Ger de anpassade värdena (\\(\\hat{Y}\\))\nsummary(): Ger en sammanfattande analys av regressionsmodellen. Funktionen returnerar ett objekt av klassen ”summary.lm”. Se ?summary.lm i dokumentationen. coef() funkar även på dessa objekt som vi såg ovan.\nanova(): Ger ANOVA-tabellen för modellen\npredict(): gör prediktioner för (nya) x-värden, alltså beräknar \\(\\hat{Y}\\) för givna x-värden. Kan även beräkna konfidensintervall och prediktionsintervall för \\(\\hat{Y}\\). Se ?predict.lm() för detaljer.\nplot(): Ger olika diagnostiska plottar, se ?plot.lm för detaljer.\nconfint(): Beräknar konfidensintervall för regressionskoefficienterna\nmodel.matrix(): skapar olika typer av designmatriser som kan användas i lm(), se Avsnitt 3.3.\n\nDet är också användbart att använda str() på lm-objekt. Kolla i ?lm() under Value rubriken för att se vilka olika delar som finns i objektet.\n\n\nTabell 3.1 visar de skattade lutningsparametrarna (koefficienterna). Exempelvis kan vi se att för varje gram mer en pingvin väger ökar näbbens längd med ca 0.0011 mm i genomsnitt givet att alla andra variabler hålls konstanta. Den sista delen av denna tolkning är viktig att inkludera då en förändring av flera variabler skulle medföra en annan förändring av responsvariabeln i relation till respektive koefficient.\nIndikatorvariablerna tolkas inom sin grupp jämfört med referenskategorin, till exempel har Gentoo-pingviner i genomsnitt en 6.4 mm större näbblängd än referenskategorin Adelie-pingviner givet att alla andra variabler hålls konstanta.\nInterceptet är endast relevant att tolka om värdemängden är alla 0, det vill säga att data täcker det område där alla förklarande variabler antar värdet 0. I just detta exempel finns det inte data över dessa områden vilket medför att värdet på interceptet inte har någon rimlig tolkning.\n\n\n\n\n\n\nViktigt\n\n\n\nÄven om tolkningen av interceptet inte blir rimlig måste interceptet inkluderas i modellanpassningen för att minsta kvadratskattningen ska minimera SSE. Om interceptet hade plockats bort motsvarar det en linje som tvingas att korsa y-axeln vid \\(y = 0\\) vilket resulterar i att modellen inte beskriver de fenomen som vi vill att den ska beskriva.\n\n\nDet är inte bara koefficienttabellen som är relevant att titta på i en modellanpassning och vi kommer tillbaka till de andra objekten som finns inuti lm senare.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modellanpassning</span>"
    ]
  },
  {
    "objectID": "01-regression/02-model-structure.html#sec-matrices",
    "href": "01-regression/02-model-structure.html#sec-matrices",
    "title": "3  Modellanpassning",
    "section": "3.3 Matrisberäkningar",
    "text": "3.3 Matrisberäkningar\nMatriser underlättar de tunga beräkningar som krävs för att anpassa en regressionsmodell med flera förklarande variabler. Vi kan formulera en regressionsmodell i matrisform enligt: \\[\n\\mathbf{Y} = \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{E}\n\\tag{3.5}\\] där, \\[\n    \\mathbf{Y} = \\underset{n \\times 1}{\\begin{bmatrix}Y_1\\\\Y_2\\\\\\vdots\\\\Y_n\\end{bmatrix}} \\quad \\mathbf{X} = \\underset{n \\times p}{\\begin{bmatrix}1 & X_{11} & X_{12} & \\cdots & X_{1k}\\\\1 & X_{21} & X_{22} & \\cdots & X_{2k}\\\\\\vdots & \\vdots & \\vdots & \\ddots & \\vdots\\\\1 & X_{n1} & X_{n2} & \\cdots & X_{nk}\\end{bmatrix}\n} \\quad \\boldsymbol{\\beta} = \\underset{p \\times 1}{\\begin{bmatrix}\\beta_0\\\\\\beta_1\\\\\\vdots\\\\\\beta_k\\end{bmatrix}} \\quad \\mathbf{E} = \\underset{n \\times 1} {\\begin{bmatrix}E_1\\\\E_2\\\\\\vdots\\\\E_n\\end{bmatrix}}\n\\] \\(\\mathbf{X}\\) kallas för designmatrisen och innehåller alla \\(k\\) förklarande variabler, en kolumn för varje, samt en första kolumn med 1:or som motsvarar interceptet. Indikatorvariabler adderar till antalet förklarande variabler trots att de utgår ifrån samma kvalitativa variabel, se Ekvation 3.2 där vi totalt har 6 förklarande variabler. \\(p\\) beskriver antalet parametrar, motsvarande \\(k + 1\\) antalet lutningsparametrar + interceptet, och \\(n\\) är antalet observationer.\nSkattningen av \\(\\hat{\\boldsymbol{\\beta}}\\) minimerar fortfarande SSE där: \\[\nSSE = (\\mathbf{Y} - \\mathbf{X}\\boldsymbol{\\hat{\\beta}})'(\\mathbf{Y}-\\mathbf{X}\\boldsymbol{\\hat{\\beta}})\n\\tag{3.6}\\]\noch \\[\n\\boldsymbol{\\hat{\\beta}} = (\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\mathbf{Y}\n\\tag{3.7}\\]\n\n3.3.1 Matriser i R\nR använder sig av matriser i bakgrunden när vi använder lm() men vi kan också skapa våra egna utifrån datamaterialet och genomföra matrisberäkningen för \\(\\boldsymbol{\\hat{\\beta}}\\) eller SSE.\nDesignmatrisen är den mest komplexa att skapa, speciellt om vi har kvalitativa variabler med i data, men som tur är kan vi använda samma formelobjekt i funktionen model.matrix().\n\nX &lt;- \n  model.matrix(\n    bill_length_mm ~ ., \n    data = modelData\n  )\n\n# Visar de första fem raderna i matrisen\nX[1:5,]\n\n  (Intercept) body_mass_g flipper_length_mm bill_depth_mm speciesChinstrap\n1           1        3750               181          18.7                0\n2           1        3800               186          17.4                0\n3           1        3250               195          18.0                0\n4           1        3450               193          19.3                0\n5           1        3650               190          20.6                0\n  speciesGentoo sexmale\n1             0       1\n2             0       0\n3             0       0\n4             0       0\n5             0       1\n\nY &lt;- \n  modelData$bill_length_mm %&gt;% \n  as.matrix()\n\n# Visar de första fem raderna i vektorn\nY[1:5,]\n\n[1] 39.1 39.5 40.3 36.7 39.3\n\n\nDe fem första raderna i respektive matris är transformerade värden från Tabell 2.1 och designmatrisen innehåller indikatorvariabler enligt Ekvation 3.2.\n\n3.3.1.1 Skattning av \\(\\boldsymbol{\\hat{\\beta}}\\)\nNu kan vi med hjälp av matrisberäkningsformler i R beräkna koefficienterna:\n\nbetaHat &lt;- solve(t(X) %*% X) %*% t(X) %*% Y\n\n\n\n\n\nTabell 3.2: Skattade koefficienter från matrisberäkning avrundat till fyra decimaler\n\n\n\n\n \n  \n     \n    Koefficient \n  \n \n\n  \n    (Intercept) \n    15.0166 \n  \n  \n    body_mass_g \n    0.0011 \n  \n  \n    flipper_length_mm \n    0.0686 \n  \n  \n    bill_depth_mm \n    0.3130 \n  \n  \n    speciesChinstrap \n    9.5655 \n  \n  \n    speciesGentoo \n    6.4044 \n  \n  \n    sexmale \n    2.0297 \n  \n\n\n\n\n\n\n\nTabell 3.2 visar samma parameterskattningar som Tabell 3.1, eftersom det är samma beräkningar som genomförts. Vi ser dock fler värden i den tidigare tabellen vilket uppkommer från att lm() omfattar fler beräkningar som sedan sammanställs i ett och samma objekt.\nTill exempel beräknas även prediktioner och residualer, vilket vi också kan göra med matrisberäkningar enligt:\n\nYhat &lt;- X %*% betaHat\n\ne &lt;- Y - Yhat\n\n\n\n3.3.1.2 Kovariansmatris för \\(\\boldsymbol{\\hat{\\beta}}\\)\nVariansen för respektive parameter kan också beräknas med matriser, där medelfelet är roten ur diagonalelementen från kovariansmatrisen. \\[\ns^2_{\\boldsymbol{\\hat{\\beta}}} = (\\mathbf{X}'\\mathbf{X})^{-1}MSE\n\\] där MSE är \\(\\frac{SSE}{n - (k + 1)}\\).\nDå beräkningen av SSE och MSE utgår från matriser kommer även deras objekt vara en \\(1 \\times 1\\) matris, men i beräkningen av kovariansmatrisen är MSE endast en skalär. Vi behöver därför explicit ange att MSE inte längre är en matris för att undvika problem med matrisdimensioner.\n\n# Beräknar SSE\nSSE &lt;- t(Y - Yhat) %*% (Y - Yhat)\n\n# Beräknas MSE\nMSE &lt;- SSE / (nrow(X) - ncol(X))\n\n# Beräknar kovariansmatrisen för Beta\ns2Beta &lt;- solve(t(X) %*% X) * as.numeric(MSE)\n\n\n\n\n\nTabell 3.3: Skattade medelfel från matrisberäkning avrundat till fyra decimaler\n\n\n\n\n \n  \n     \n    Medelfel \n  \n \n\n  \n    (Intercept) \n    4.3742 \n  \n  \n    body_mass_g \n    0.0004 \n  \n  \n    flipper_length_mm \n    0.0232 \n  \n  \n    bill_depth_mm \n    0.1541 \n  \n  \n    speciesChinstrap \n    0.3497 \n  \n  \n    speciesGentoo \n    1.0304 \n  \n  \n    sexmale \n    0.3892 \n  \n\n\n\n\n\n\n\nVi ser även i Tabell 3.3 samma värden som Tabell 3.1.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modellanpassning</span>"
    ]
  },
  {
    "objectID": "01-regression/02-model-structure.html#sec-exercise-model-fit",
    "href": "01-regression/02-model-structure.html#sec-exercise-model-fit",
    "title": "3  Modellanpassning",
    "section": "3.4 Övningsuppgifter",
    "text": "3.4 Övningsuppgifter\nVi kommer återigen använda datamaterialet marketing.\n\nAnpassa en linjär regressionsmodell med lm() som inkluderar de variabler som du valt ut i Avsnitt 2.4.\nSammanställ en tabell över de skattade koefficienterna och tolka respektive.\nSkapa designmatrisen och en matris för responsvariabeln och skatta lutningsparametrarna med hjälp av dessa. Kontrollera att du får samma värden som i tabellen från lm().\nAnvänd matrisberäkningar för att beräkna medelfelet för respektive parameter.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Modellanpassning</span>"
    ]
  },
  {
    "objectID": "01-regression/03-model-assessment.html",
    "href": "01-regression/03-model-assessment.html",
    "title": "4  Modellutvärdering",
    "section": "",
    "text": "4.1 Residualanalys\nEfter att vi har anpassat en modell baserat på iakttagelser från visualiseringar och beskrivande statistik har vi möjlighet att tolka det skattade sambandet mellan de förklarande variablerna och responsvariabeln, vilket vi också gjorde i Avsnitt 3.2.1. Det finns dock två aspekter som vi ännu inte funderat på;\nFör att kunna bedöma lämpligheten av modellen måste vi undersöka huruvida modellen uppfyller de antaganden som presenterades i Avsnitt 1.2 genom residualanalys och slutsatser om populationen kan göras med hjälp av statistisk inferens. Vi börjar alltid med att undersöka modellens lämplighet eftersom inferensmetodernas beräkningar också förutsätter att dessa antaganden är uppfyllda.\nResidualanalys innebär att beräkna och visuellt utforska residualerna från en modell gentemot modellantaganden \\(E\\overset{iid}{\\sim}N(0, \\sigma^2)\\), det vill säga att residualerna är oberoende, normalfördelade med väntevärde 0 och lika varians. Residualerna kan också användas för att undersöka ifall den linjära modell som anpassats är lämplig. Vi kommer titta närmare på mer detaljerad residualanalys i ett senare kapitel.\nFör enkelhetens skull kan vi plocka ut residualerna samt de observerade och skattade värdena på responsvariabeln från den skattade modellen (se Tip 3.1).\n# Skapa ett datamaterial för visualiseringar\n\nresidualData &lt;- \n  tibble(\n    residuals = residuals(simpleModel),\n    y = modelData$bill_length_mm,\n    yHat = fitted(simpleModel)\n  )\nVi kommer visualisera dessa variabler i olika former med hjälp av ggplot2 vilket kräver att vi har en data.frame eller tibble med data.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modellutvärdering</span>"
    ]
  },
  {
    "objectID": "01-regression/03-model-assessment.html#sec-residual-simple",
    "href": "01-regression/03-model-assessment.html#sec-residual-simple",
    "title": "4  Modellutvärdering",
    "section": "",
    "text": "4.1.1 Normalfördelning\nVi kan undersöka antagandet om normalfördelade residualer genom ett histogram och ett QQ-diagram (quantile-quantile diagram).\n\n\nVisa kod\nggplot(residualData) + \n  aes(x = residuals, y = after_stat(density)) +\n  geom_histogram(binwidth = 1, fill = \"steelblue\", color = \"black\") + \n  theme_bw() + \n  labs(x = \"Residualer\", y = \"Densitet\")\n\n\n\n\n\nResidualernas fördelning\n\n\n\n\n\n\nVisa kod\nggplot(residualData) + \n  # Använder standardiserade residualer\n  aes(sample = scale(residuals)) + \n  geom_qq_line() +\n  geom_qq(color = \"steelblue\") +\n  theme_bw() + \n  labs(x = \"Teoretiska kvantiler\", y = \"Observerade kvantiler\")\n\n\n\n\n\nResidualernas observerade kvantiler jämfört med teoretiska normalfördelade kvantiler.\n\n\n\n\nI histogrammet vill vi se normalfördelningens symmetriska och klockliknande form centrerad kring 0 vilket ibland kan vara svårt att utläsa speciellt om datamaterialet är litet. QQ-diagrammet visar de observerade och de teoretiska kvantilerna där vi vill att punkterna ska följa den inritade linjen för en “perfekt” normalfördelning.\nFör denna modell ser vi inga tydliga avvikelser från det mönster vi vill se, men vi kan utläsa ett fåtal avvikande observationer som skulle kunna betraktas som extremvärden. Två stora positiva residualer kan identifieras i diagrammen men det finns även enstaka negativa som ligger långt från de övriga.\n\n\n\n\n\n\nViktigt\n\n\n\nVi kan betrakta antagandet om normalfördelning som inte uppfyllt om dessa diagram visar på starka avvikelser från det vi vill se. Även när vi vet att ett urval är draget från en normalfördelning är det inte alltid som histogrammet visar den form som vi söker.\n\n\nVisa kod\nset.seed(1234)\n\ntibble(\n  x = rnorm(30)\n) %&gt;% \n ggplot() + \n  aes(x = x, y = after_stat(density)) +\n  geom_histogram(bins = 10, fill = \"steelblue\", color = \"black\") + \n  theme_bw() + \n  labs(x = \"x\", y = \"Densitet\")\n\n\n\n\n\nFördelning av ett urval från den faktiska normalfördelningen\n\n\n\n\nStarka avvikelser från normalfördelningen innebär exempelvis att vi ser flera områden med hög densitet:\n\n\nVisa kod\nset.seed(1234)\n\ntibble(\n  x = runif(30)\n) %&gt;% \n ggplot() + \n  aes(x = x, y = after_stat(density)) +\n  geom_histogram(bins = 10, fill = \"steelblue\", color = \"black\") + \n  theme_bw() + \n  labs(x = \"x\", y = \"Densitet\")\n\n\n\n\n\nFördelning av ett urval från andra fördelningar\n\n\n\n\neller en väldigt skev fördelning:\n\n\nVisa kod\nset.seed(1234)\n\ntibble(\n  x = rchisq(30, df = 2)\n) %&gt;% \n ggplot() + \n  aes(x = x, y = after_stat(density)) +\n  geom_histogram(bins = 10, fill = \"steelblue\", color = \"black\") + \n  theme_bw() + \n  labs(x = \"x\", y = \"Densitet\")\n\n\n\n\n\nFördelning av ett urval från andra fördelningar\n\n\n\n\nDessa diagram indikerar att modellen saknar en förklarande variabel eller måste transformeras på något sätt för att uppfylla antagandet.\nOm QQ-diagrammet uppvisar tydliga mönster, till exempel om punkterna är krökta runt linjen, betyder det att modellen inte uppfyller antagandet om linjärt samband.\n\n\n\n\n\nExempel på mönster i QQ-diagram\n\n\n\n\n\n\n\n\n4.1.2 Lika varians\nVi kan kontrollera antagandet om residualernas lika varians genom ett spridningsdiagram med residualerna på y-axeln och någon av anpassade värden eller observerade värden på förklarande eller responsvariabeln. Vanligtvis används de anpassade värdena för att x-axeln ska beskriva hela modellen, men andra variabler kan vara användbara att visualisera för att identifiera potentiella orsaker till ett brustet antagande.\n\n\nVisa kod\nggplot(residualData) + \n  aes(x = yHat, y = residuals) + \n  geom_point(color = \"steelblue\") + \n  theme_bw() +\n  labs(x = \"Anpassade värden\", y = \"Residualer\") + \n  geom_hline(\n    aes(yintercept = 0)\n  ) + \n  # Imaginära gränser\n  geom_hline(\n    aes(yintercept = -5),\n    color = \"#d9230f\",\n    linetype = 2\n  ) + \n  geom_hline(\n    aes(yintercept = 5),\n    color = \"#d9230f\",\n    linetype = 2\n  )\n\n\n\n\n\n\n\n\nFigur 4.1: Residualernas spridning mot anpassade värden.\n\n\n\n\n\nFör att uppfylla antagandet om lika varians, ska punkterna i varje tvärsnitt av värden på x-axeln vara jämnt och lika utspridda. Tänk som att vi vill placera två stycken parallella linjer längs med maximum och minimum-värden för residualerna (de två rödstreckade linjerna i Figur 4.1) och en stor majoritet av punkterna bör ligga utspridda emellan dessa. Vi ser i Figur 4.1 att några enstaka observationer faktiskt hamnar utanför och ökar variationen i vissa tvärsnitt, men då det inte är tydliga avvikelser kan vi anse att residualerna har uppfyllt antagandet om lika varians.\n\n\n\n\n\n\nViktigt\n\n\n\nOm linjerna som täcker maximum och minimum-värden för residualerna inte är parallella uppfyller inte modellen kravet om lika varians.\n\n\n\n\n\nExempel på icke-konstant varians i residualerna\n\n\n\n\n\n\n\nExempel på icke-konstant varians i residualerna\n\n\n\n\nDessa fenomen betyder oftast att hela eller delar av modellen behöver transformeras för att uppfylla antagandet om lika varians.\nVi kan också identifiera problem med linjäritet i detta spridningsdiagram. Figuren nedan uppvisar någorlunda konstant varians i avseende på variationen i varje tvärsnitt av x-axeln, men det finns ett tydligt mönster i residualerna. Detta betyder att modellen inte lyckats modellera sambandet på rätt sätt. I detta läge vore det lämpligt att visualisera residualerna mot respektive förklarande variabel för att identifiera vilken/vilka utav de som verkar bidra med det icke-linjära sambandet.\n\n\n\n\n\nMönster i residualerna som tyder på ett icke-linjärt samband\n\n\n\n\n\n\n\n\n4.1.3 Oberoende\nOfta är det svårt eller omöjligt att undersöka om observationerna är oberoende med avseeende på alla ordningar som data kan samlas in på. Undantaget är ifall vi vet hur datainsamlingen har gått till och om det finns någon tydlig tidsaspekt, till exempel i tidsseriedata, eller att samma enhet har uppmätts flera gånger som gör att vi vet att observationerna blir beroende. Vi vill att den modell som anpassas tar hänsyn till det beroende som finns i data så att de efterföljande residualerna endast uppvisar oberoende.\nEtt linjediagram över residualerna i observationsordning kan användas för att undersöka oberoende, men det är som sagt endast i specialfall som denna visualisering används. Linjediagrammet ska uppvisa “slump”, det vill säga inga tydliga mönster i residualerna.\n\n\nVisa kod\nggplot(residualData) + \n  aes(x = seq_len(nrow(residualData)), y = residuals) + \n  geom_line(color = \"steelblue\") + \n  theme_bw() +\n  labs(x = \"Obs. index\", y = \"Residualer\") + \n  geom_hline(\n    aes(yintercept = 0),\n    color = \"black\"\n  )\n\n\n\n\n\nResidualer i observationsordning.\n\n\n\n\nAndra exempel på data som har ett beroende är:\n\nVi samlar in data från personer, men vissa personer kommer ifrån samma famlij, detta kan göra att det finns ett beroende mellan dessa personer.\nVi samlar in spatiala (rumsliga) data, till exempel temperatur eller regnmängd på olika platser i Östergötland. Då är det vanligt att det finns en positiv korrelation mellan geografiskt närliggande observationer.\n\n\n\n4.1.4 Funktion med alla diagram (diagnosticPlots)\nDessa diagram kommer vara återkommande i regressionsmodellering så vi kan skapa en funktion för att automatiskt generera alla fyra diagram samtidigt. Vi får genom paketet cowplot tillgång till en funktion (plot_grid) som kan kombinera flera diagram till en och samma.\n\n#' Funktionen diagnosticPlots genererar enkla residualdiagram från en given modell\n#' @param model En anpassad regressionsobjekt av klass \"lm\"\n#' @param primaryColor Den huvudsakliga färgen i diagrammen\n#' @param secondaryColor Den alternativa färgen i diagrammen\n#' @param bins  Anger antalet staplar i histogrammet\n#' @param independence Logisk operator om diagram för oberoende ska inkluderas\n#' @param scaleLocation Logisk operator om diagram med standardiserade residualer ska inkluderas\ndiagnosticPlots &lt;- \n  function(\n    model, \n    primaryColor = \"steelblue\",\n    secondaryColor = \"firebrick\",\n    bins = 10, \n    independence = FALSE,\n    scaleLocation = FALSE\n  ) {\n    if (model |&gt; class() != \"lm\") {\n      stop(\"model must be an lm object\")\n    }\n    if (bins &lt;= 0 | (bins %% 1) &gt; 0) {\n      stop(\"bins must be a positive integer\")\n    }\n    if (!(independence %in% c(TRUE, FALSE))) {\n      stop(\"independence must be a boolean operator\")\n    }\n    if (!(scaleLocation %in% c(TRUE, FALSE))) {\n      stop(\"independence must be a boolean operator\")\n    }\n    \n    residualData &lt;- \n      dplyr::tibble(\n        residuals = residuals(model),\n        # Responsvariabeln finns som första kolumn i modellens model-objekt\n        y = model$model[,1],\n        yHat = fitted(model)\n      )\n  \n    ## Histogram för kontroll av normalfördelning\n    p1 &lt;- \n      ggplot2::ggplot(residualData) + \n      ggplot2::aes(x = residuals, y = ggplot2::after_stat(density)) +\n      ggplot2::geom_histogram(bins = bins, fill = primaryColor, color = \"black\") + \n      ggplot2::theme_bw() + \n      ggplot2::labs(x = \"Residualer\", y = \"Densitet\")\n    \n    ## Spridningsdiagram för kontroll av homoskedasticitet\n    p2 &lt;- \n      ggplot2::ggplot(residualData) + \n      ggplot2::aes(x = yHat, y = residuals) + \n      ggplot2::geom_hline(ggplot2::aes(yintercept = 0), color = \"black\") + \n      ggplot2::geom_point(color = primaryColor) + \n      ggplot2::theme_bw() +\n      ggplot2::labs(x = \"Anpassade värden\", y = \"Residualer\")\n      \n    \n    ## Kvantildiagram för kontroll av normalfördelning\n    p3 &lt;- \n      ggplot2::ggplot(residualData) + \n      ## Använd standardiserade residualer\n      ggplot2::aes(sample = scale(residuals)) + \n      ggplot2::geom_qq_line() + \n      ggplot2::geom_qq(color = primaryColor) +\n      ggplot2::theme_bw() + \n      ggplot2::labs(x= \"Teoretiska kvantiler\", y = \"Observerade kvantiler\")\n    \n    plotList &lt;- list(p1, p2, p3)\n    \n    if (independence) {\n      p4 &lt;- \n        ggplot2::ggplot(residualData) + \n        ggplot2::aes(x = seq_len(nrow(residualData)), y = scale(residuals)) + \n        ggplot2::geom_hline(ggplot2::aes(yintercept = 0), color = \"black\") + \n        ggplot2::geom_line(color = primaryColor, linewidth = 1) + \n        ggplot2::theme_bw() + \n        ggplot2::labs(x= \"Obs. ordning\", y = \"Residualer\")\n      \n      plotList &lt;- append(plotList, p4)\n    }\n    \n    if (scaleLocation) {\n      p5 &lt;- \n        ggplot2::ggplot(residualData) + \n        ggplot2::aes(x = yHat, y = sqrt(abs(residuals))) + \n        ggplot2::geom_point(color = primaryColor) + \n        ggplot2::theme_bw() +\n        ggplot2::labs(x = \"Anpassade värden\", y = expression(sqrt(\"|Residualer|\")))\n      \n      plotList &lt;- append(plotList, p5)\n    }\n    \n    cowplot::plot_grid(\n      plotlist = plotList,\n      nrow = 2\n    )\n  \n}\n\ndiagnosticPlots(simpleModel)\n\n\n\n\n\n\n\nFigur 4.2: Residualdiagrammen i en och samma bild\n\n\n\n\n\nSammanfattningsvis visar Figur 4.2 att residualerna uppfyller antagandet om normalfördelning med väntevärde 0 och lika varians. Det finns inga tydliga mönster i något diagram som indikerar på motsatsen eller att modellen missar att plocka upp något av sambandet. Några enstaka extremvärden har identifierats, specifikt två stycken stora positiva residualer som kommer undersökas mer i senare kapitel. Slutsatsen är att modellen är en lämplig förenkling av verkligheten.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modellutvärdering</span>"
    ]
  },
  {
    "objectID": "01-regression/03-model-assessment.html#sec-exercise-evaluate",
    "href": "01-regression/03-model-assessment.html#sec-exercise-evaluate",
    "title": "4  Modellutvärdering",
    "section": "4.2 Övningsuppgifter",
    "text": "4.2 Övningsuppgifter\nAnvänd återigen marketing från Avsnitt 2.4.\n\nSkatta residualerna genom att beräkna skillnaden mellan de observerade och anpassade värdena på responsvariabeln.\nSkapa ett histogram och ett kvantildiagram (QQ diagram) över residualerna och kontrollera antagandet om normalfördelning.\nSkapa ett spridningsdiagram med residualerna på y-axeln och de anpassade värdena på x-axeln och kontroller antagandet om lika varians.\nSammanfatta dina slutatser och bedöm om modellen som anpassats i Avsnitt 3.4 uppfyller modellantaganden.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Modellutvärdering</span>"
    ]
  },
  {
    "objectID": "01-regression/04-statistical-inference.html",
    "href": "01-regression/04-statistical-inference.html",
    "title": "5  Statistisk inferens",
    "section": "",
    "text": "5.1 ANOVA\nNär vi anser oss ha hittat en lämplig modell kan vi fokusera på att tolka modellens resultat avseende populationen. Inom regressionsmodellering kan vi genomföra flera olika typer av statistisk inferens; på hela modellen, på grupper av parametrar, eller på enskilda parametrar.\nVi kan börja med ett F-test för hela modellen för att se ifall minst en parameter är signifikant, att modellen är värd att undersöka vidare, för att sedan genomföra enskilda t-test för respektive parameter och bedöma vilka förklarande variabler har en signifikant påverkan på responsvariabeln. Då kvalitativa variabler ofta består utav flera parametrar behöver dessa slås samman för att undersöka variabelns samband vilket vi kan göra med ett partiellt F-test.\nInnan vi går in på de olika testerna behöver vi presentera ANOVA-tabellen som används för att dela upp responsvariabelns variation i modellens olika komponenter; modellens förklarande variabler och feltermen.\nAnalysis of Variance är en samling metoder som beräknar variationen av olika modellkomponenter. Målet med en modell är att förklara den totala variationen i responsvariabeln på bästa sätt. Allting som de förklarande variablerna hjälper till att beskriva kallas för den förklarade variationen och det som modellen inte lyckas förklara (felet) är den oförklarade variationen.\n\\[\n\\underbrace{\\mathbf{Y}}_\\text{total variation} = \\underbrace{\\mathbf{X} \\boldsymbol{\\beta}}_\\text{förklarad variation} + \\underbrace{\\mathbf{E}}_\\text{oförklarad variation}\n\\tag{5.1}\\]\nEkvation 5.1 visar att den totala variationen är en summa av den förklarade och oförklarade variationen vilket också ses i formlerna för dessa. Respektive komponent beräknas enligt:\n\\[\n  \\text{total variation} = SST = \\mathbf{Y}'\\mathbf{Y} - \\left(\\frac{1}{n}\\right)\\mathbf{Y}'\\mathbf{J}\\mathbf{Y}\n\\] där \\(\\mathbf{J}\\) är enhetsmatrisen, en \\(n \\times n\\) matris endast innehållande 1:or.\nDet kanske inte är så lätt att se vad dessa matrisberäkningar faktiskt beskriver men beräkningen motsvarar \\(\\sum_{i=1}^n(Y_i - \\bar{Y})^2\\), alltså täljaren i en variansberäkning för \\(Y\\). Den vänstra termen (\\(\\mathbf{Y}'\\mathbf{Y}\\)) motsvarar \\(Y_i\\) och den högra termen (\\(\\left(\\frac{1}{n}\\right)\\mathbf{Y}'\\mathbf{J}\\mathbf{Y}\\)) motsvarar \\(\\bar{Y}\\), responsvariabelns medelvärde. Den totala variationen beskriver hur mycket variation som uppkommer ifall vi skulle använda medelvärdet av \\(Y\\) som modell.\n\\[\n  \\text{oförklarad variation} = SSE = \\mathbf{Y}'\\mathbf{Y} - \\boldsymbol{\\hat{\\beta}}'\\mathbf{X}'\\mathbf{Y}\n\\] SSE har vi tidigare använt som ett mått på felet i modellen, se Ekvation 3.4, vilket betyder att \\(\\boldsymbol{\\hat{\\beta}}'\\mathbf{X}'\\mathbf{Y}\\) motsvarar \\(\\hat{Y}_i\\).\n\\[\n  \\text{förklarad variation} = SSR = \\boldsymbol{\\hat{\\beta}}'\\mathbf{X}'\\mathbf{Y} - \\left(\\frac{1}{n}\\right)\\mathbf{Y}'\\mathbf{J}\\mathbf{Y}\n\\]\nSSR beskriver variationen mellan modellens anpassade värde och medelvärdet av \\(Y\\). Det kan i sin tur kan tolkas som hur mycket mer variation som modellen bidrar med jämfört med medelvärdet, eller kort sagt hur mycket bättre modellen är på att förklara variationen i \\(Y\\).\nVi har tidigare använt en annan matrisformel för SSE men med hjälp av omformuleringen kan vi tydligt se hur SST = SSR + SSE: \\[\n\\mathbf{Y}'\\mathbf{Y} - \\left(\\frac{1}{n}\\right)\\mathbf{Y}'\\mathbf{J}\\mathbf{Y} = \\mathbf{Y}'\\mathbf{Y} \\underbrace{-  \\boldsymbol{\\hat{\\beta}}'\\mathbf{X}'\\mathbf{Y} + \\boldsymbol{\\hat{\\beta}}'\\mathbf{X}'\\mathbf{Y}}_\\text{summerar till 0} - \\left(\\frac{1}{n}\\right)\\mathbf{Y}'\\mathbf{J}\\mathbf{Y}\n\\] Vi kan också visualisera denna relation i ett stackat stapeldiagram. Den totala höjden av stapeln är SST medan de olika delarna beskriver hur stor del av den totala variationen som är förklarad eller oförklarad i en viss modell.\nVisualisering av de olika källor av variation",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistisk inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/04-statistical-inference.html#sec-regression-anova",
    "href": "01-regression/04-statistical-inference.html#sec-regression-anova",
    "title": "5  Statistisk inferens",
    "section": "",
    "text": "5.1.1 ANOVA-tabellen\nEn ANOVA-tabell är ett sätt att effektivt få en översikt av dessa olika komponenter samt visa ytterligare information, såsom frihetsgraderna (\\(df\\)) för respektive komponent och medelkvadratsummor.\nFrihetsgrader beskriver hur många lutningsparametrar som skattas för respektive del1 och medelkvadratsummor visar den genomsnittliga variationen per frihetsgrad, \\(\\frac{SS}{df}\\).\n\n\n\n\nTabell 5.1: Enkel ANOVA-tabell\n\n\n\n\n\n\n\n\n\n\n\n\nSource\nDF\nSum of Squares\nMean Square\n\n\n\n\nModel (Regression)\n\\(df_R = k\\)\n\\(SSR = \\boldsymbol{\\hat{\\beta}}' \\mathbf{X}' \\mathbf{Y} - \\frac{1}{n} \\mathbf{Y}' \\mathbf{J} \\mathbf{Y}\\)\n\\(MSR = \\frac{SSR}{df_R}\\)\n\n\nError\n\\(df_E = n - (k + 1)\\)\n\\(SSE = \\mathbf{Y}' \\mathbf{Y} - \\boldsymbol{\\hat{\\beta}}' \\mathbf{X}' \\mathbf{Y}\\)\n\\(MSE = \\frac{SSE}{df_E}\\)\n\n\nTotal\n\\(df_T = n - 1\\)\n\\(SSY = \\mathbf{Y}' \\mathbf{Y} - \\frac{1}{n} \\mathbf{Y}' \\mathbf{J} \\mathbf{Y}\\)\n\n\n\n\n\n\n\n\n\nEn enkel ANOVA-tabell som Tabell 5.1 visar endast de tre huvudsakliga komponenterna, men olika programvaror kan ibland visa andra uppdelningar som standard. I en multipel linjär regressionsmodell är det vanligt att dela upp den förklarade variationen ytterligare, exempelvis i sekventiella kvadratsummor.\n\n\n5.1.2 Sekventiella kvadratsummor\nBeräkningarna för en ANOVA-tabell sker automatiskt i R när vi använder lm() och vi kan plocka ut tabellen från modellobjektet med hjälp av anova(), (se Tip 3.1).\n\n\nVisa kod\nanova(simpleModel) %&gt;% \n  round(4) %&gt;% \n  kable() %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 5.2: ANOVA-tabell från R\n\n\n\n\n \n  \n     \n    Df \n    Sum Sq \n    Mean Sq \n    F value \n    Pr(&gt;F) \n  \n \n\n  \n    species \n    2 \n    7015.3857 \n    3507.6929 \n    713.4929 \n    0 \n  \n  \n    bill_depth_mm \n    1 \n    818.5050 \n    818.5050 \n    166.4905 \n    0 \n  \n  \n    flipper_length_mm \n    1 \n    198.2269 \n    198.2269 \n    40.3210 \n    0 \n  \n  \n    body_mass_g \n    1 \n    160.3760 \n    160.3760 \n    32.6218 \n    0 \n  \n  \n    sex \n    1 \n    133.7191 \n    133.7191 \n    27.1995 \n    0 \n  \n  \n    Residuals \n    326 \n    1602.6899 \n    4.9162 \n     \n     \n  \n\n\n\n\n\n\n\nSom standard, delar R upp modellens kvadratsumma (SSR) i de enskilda förklarande variablerna med hjälp av sekventiella (även kallad betingade) kvadratsummor. En sekventiell kvadratsumma beskriver hur mycket variation en förklarande variabel bidrar med givet att modellen redan innehåller andra förklarande variabler.\nOrdningen som presenteras i Tabell 5.2 är ordningen som variablerna läggs till i modellen, till exempel visar andra raden \\(SS(\\text{bill\\_depth\\_mm} | \\text{species})\\), att näbbredden bidrar med 818.505 ytterligare unik förklarad variation av responsvariabeln som art inte redan har förklarat. Den tredje raden visar \\(SS(\\text{flipper\\_length\\_mm} | \\text{species}, \\text{bill\\_depth\\_mm})\\), det vill säga hur mycket ytterligare unik variation som fenlängden förklarar i en modell som inkluderar näbbredd och art.\nRent matematiskt beräknas den sekventiella kvadratsumman som en summa av antingen SSE eller SSR mellan två olika modeller, en utan den tillagda variabeln och en med variabeln inkluderad. Anta att vi vill lägga till variabel \\(X^*\\) till en modell som har \\(k\\) andra variabler, då ser beräkningen ut som följer:\n\\[\n\\begin{aligned}\nSS(X^*|X_1, \\ldots, X_k) &= SSE_{X_1, \\ldots, X_k} - SSE_{X_1, \\ldots, X_k, X^*} = \\\\\n&= SSR_{X_1, \\ldots, X_k, X^*} - SSR_{X_1, \\ldots, X_k}\n\\end{aligned}\n\\tag{5.2}\\]\nNotera att SSR ökar för varje ytterligare variabel som läggs till i modellen, medan SSE alltid minskar. En variation måste alltid vara positiv, därav beräknas \\(SSE_{reducerad} - SSE_{komplett}\\) eller \\(SSR_{komplett} - SSR_{reducerad}\\).\nSekventiella kvadratsummor påverkas av ordningen variablerna läggs till i modellen. Låt oss byta ordning på de förklarande variablerna när vi anpassar modellen:\n\n\nVisa kod\nmodel &lt;- lm(formula = bill_length_mm ~ sex + ., data = modelData)\n\nanova(model) %&gt;% \n  round(4) %&gt;% \n  kable() %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 5.3: Annan ordning på modellernas variabler\n\n\n\n\n \n  \n     \n    Df \n    Sum Sq \n    Mean Sq \n    F value \n    Pr(&gt;F) \n  \n \n\n  \n    sex \n    1 \n    1175.4780 \n    1175.4780 \n    239.1017 \n    0.0000 \n  \n  \n    species \n    2 \n    6975.5916 \n    3487.7958 \n    709.4457 \n    0.0000 \n  \n  \n    bill_depth_mm \n    1 \n    64.4987 \n    64.4987 \n    13.1196 \n    0.0003 \n  \n  \n    flipper_length_mm \n    1 \n    78.3815 \n    78.3815 \n    15.9434 \n    0.0001 \n  \n  \n    body_mass_g \n    1 \n    32.2629 \n    32.2629 \n    6.5625 \n    0.0109 \n  \n  \n    Residuals \n    326 \n    1602.6899 \n    4.9162 \n     \n     \n  \n\n\n\n\n\n\n\nI Tabell 5.3 ser vi att \\(SS(\\text{sex}) = 1175.478\\) vilket är betydligt högre än \\(SS(\\text{sex}|\\text{species}, \\text{bill\\_depth\\_mm}, \\text{flipper\\_length\\_mm}, \\text{body\\_mass\\_g}) = 133.7191\\) från Tabell 5.2. Variabeln kön bidrar med mycket variation när den är ensam i en modell, men när den läggs till i en modell som redan har andra variabler bidrar den inte med lika mycket unik information. Detta betyder att den förklarade variationen som variabeln bidrar med verkar finnas i övriga variabler också. Denna iakttagelse kommer vi komma tillbaka till i ett senare kapitel.\nNågonting som är lika i de två tabellerna är SSE. Vi har i båda modellerna inkluderad samma variabler vilket innebör att SST, SSR, och SSE överlag är densamma. Summan av alla sekventiella kvadratsummor ska fortfarande bli SSR oavsett ordningen på variablerna och på grund av den additiva egenskapen hos variationen har SST och SSE inte heller förändrats.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistisk inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/04-statistical-inference.html#sec-stat-inference",
    "href": "01-regression/04-statistical-inference.html#sec-stat-inference",
    "title": "5  Statistisk inferens",
    "section": "5.2 Statistisk inferens",
    "text": "5.2 Statistisk inferens\nMed hjälp av de olika källorna av variation kan vi beräkna tester för hela eller delar av modellen i olika F-test, medan de enskilda parameterskattningarna och dess tillhörande medelfel kan användas i tester för enskilda lutningsparametrar.\n\n5.2.1 F-test för modellen\nI en multipel linjär regression är ett F-test för hela modellen bra att börja med för att se ifall minst en lutningsparameter är signifikant. Vi undersöker hypoteserna:\n\\[\\begin{align*}\nH_0&: \\beta_1 = \\beta_2 = \\beta_3 = \\cdots = \\beta_k = 0\\\\\nH_a&: \\text{Minst en av } \\beta_j \\text{ i } H_0 \\text{ är skild från } 0\n\\end{align*}\\]\nOm minst en lutningsparameter är signifikant betyder det att det finns åtminstone en variabel som bidrar med förklarad variation, att modellen är bättre än att använda enbart \\(\\bar{Y}\\). Testvariabeln undersöker relationen mellan den förklarande och oförklarande variationen genom dess medelkvadratsummor.\n\\[\nF_{test} = \\frac{SSR / k}{SSE / (n - (k+1))} = \\frac{MSR}{MSE}\n\\]\nTestvariabeln följer en F-fördelning som styrs av två frihetsgrader; \\(df1\\) från täljaren och \\(df2\\) från nämnaren i beräkningen, det vill säga modellens och felets frihetsgrader. Om \\(H_0\\) är sann kommer testvariabeln bli 0, medan om \\(H_a\\) är sann kommer testvariabeln bli ett stort positivt tal. Eftersom båda medelkvadratsummorna är positiva tal innebär det att kvoten alltid kommer vara positiv och vi kan förkasta \\(H_0\\) om testvariabeln befinner sig nog långt från 0.\n\n\nVisa kod\n# Skapar en funktion för att generera olika F-fördelningar\ngenerateFdistribution &lt;- function(df1, df2, n = 1000) {\n  x &lt;- seq(0, 5, length.out = n)  \n  y &lt;- df(x, df1, df2)  \n  tibble(x = x, y = y, df1 = df1, df2 = df2)  \n}\n\n# Skapar en lista med olika frihetsgrader\ndfs &lt;- list(c(5, 30), c(10, 100), c(20, 50), c(30, 300))\n\n# Genererar data\nFdistributions &lt;- dfs %&gt;%\n  purrr::map_df(~generateFdistribution(.x[1], .x[2]), .id = \"Distribution\") %&gt;%\n  mutate(Distribution = paste0(\"df1 = \", df1, \", df2 = \", df2))\n\n# Plot the F-distributions using ggplot2\nggplot(Fdistributions) + \n  aes(x = x, y = y, color = Distribution) +\n  geom_line(linewidth = 1) +\n  labs(\n    x = \"F-värde\",\n    y = \"Densitet\",\n    color = \"Frihetsgrader\"\n  ) +\n  theme_minimal() +\n  theme(\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),\n    legend.position = \"right\",\n    legend.title = element_text(face = \"bold\")\n  ) +\n  scale_color_manual(values = c(\"steelblue\", \"#d9230f\", \"black\", \"grey50\"))\n\n\n\n\n\nOlika F-fördelningar och deras frihetsgrader\n\n\n\n\nFör att få fram SSR från en ANOVA-tabell i R behöver vi summera de sekventiella kvadratsummorna. Vi kan sedan bearbeta tabellen för att få fram testvariabeln och använda frihetsgraderna för respektive källa i pf(lower.tail = FALSE) för att få fram p-värdet för testet.\n\n\nVisa kod\nanovaTable &lt;- anova(simpleModel)\n\n# Beräknar raden för SSR utifrån alla rader förutom SSE\nSSR &lt;- anovaTable[-nrow(anovaTable),] %&gt;% \n  summarize(across(Df:`Sum Sq`, ~sum(.x))) %&gt;% \n  mutate(`Mean Sq` = `Sum Sq` / Df,\n         `F value` = NA,\n         `Pr(&gt;F)` = NA)\n\n# Kombinerar SSR med SSE från ursprungliga tabellen\nsimpleAnova &lt;- SSR %&gt;% \n  add_row(anovaTable[nrow(anovaTable),]) %&gt;% \n  mutate(\n    `F value` = \n      ifelse(row_number() == 1,\n            `Mean Sq`[1] / `Mean Sq`[2], \n            NA),\n    `Pr(&gt;F)` = \n        ifelse(row_number() == 1, \n              pf(q = `F value`[1], df1 = Df[1], df2 = Df[2], lower.tail = FALSE), \n              NA)\n    )\n\nrownames(simpleAnova) &lt;- c(\"Model\", \"Residuals\")\n\nkable(simpleAnova, digits = 4) %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 5.4: Bearbetad och förenklad ANOVA tabell\n\n\n\n\n \n  \n     \n    Df \n    Sum Sq \n    Mean Sq \n    F value \n    Pr(&gt;F) \n  \n \n\n  \n    Model \n    6 \n    8326.213 \n    1387.7021 \n    282.2698 \n    0 \n  \n  \n    Residuals \n    326 \n    1602.690 \n    4.9162 \n     \n     \n  \n\n\n\n\n\n\n\nEftersom p-värdet är mindre än 5 procent, kan \\(H_0\\) förkastas och minst en av variablerna har ett samband med responsvariabeln.2\n\n\n5.2.2 Partiella F-test för grupper av parametrar\nIbland är vi intresserade att undersöka delar av modellen, en grupp med lutningsparametrar. Ett sådant fall är om vi vill undersöka en kvalitativ variabels påverkan eftersom den kan ha transformerats till flera indikatorvariabler alla med en tillhörande lutningsparameter. Ett annat tillfälle är om vi vill undersöka om flera variabler tillsammans bidrar med förklarad variation till modellen.\nIstället för att undersöka alla lutningsparametrar undersöks nu ett urval: \\[\\begin{align*}\nH_0&: \\beta_1 = \\beta_2 = \\beta_3 = \\cdots = \\beta_s = 0\\\\\nH_a&: \\text{Minst en av } \\beta_j \\text{ i } H_0 \\text{ är skild från } 0\n\\end{align*}\\] där \\(s\\) är antalet parametrar som undersöks.\nTestvariabeln för ett partiellt F-test kräver en komplett (betecknad \\(_F\\)) och en reducerad modell (betecknad \\(_R\\)). Den kompletta modellen består av alla variabler medan den reducerade modellen utgår från att \\(H_0\\) är sann och variablerna som undersöks har plockats bort från anpassningen. Vi kan välja att antingen använda SSR eller SSE för att beräkna hur mycket förklarad variation som försvinner mellan de två modellerna enligt samma princip som Ekvation 5.2.\n\\[\nF_{test} = \\frac{(SSR_F - SSR_R) / s}{SSE_F / (n - (k+1))} = \\frac{(SSE_R - SSE_F) / s}{SSE_F / (n - (k+1))}\n\\tag{5.3}\\]\nTestvariabeln är fortfarande F-fördelat med \\(s\\) respektive \\(n - (k+1)\\) frihetsgrader.\n\n5.2.2.1 Räkneknep för partiella F-test\nMed hjälp av Ekvation 5.2 kan Ekvation 5.3 formuleras på ett tredje sätt som underlättar vår analysprocess. Vi kan skriva om skillnaden i förklarad variation mellan den kompletta och reducerade modellen som en sekventiell kvadratsumma. Exempelvis kan vi vilja undersöka om variabeln art har ett samband med responsvariabeln. Eftersom den variabeln transformeras till två indikatorvariabler omfattar hypoteserna två lutningsparametrar.\n\\[\\begin{align*}\nH_0&: \\beta_{Chinstrap} = \\beta_{Gentoo} = 0\\\\\nH_a&: \\text{Minst en av } \\beta_j \\text{ i } H_0 \\text{ är skild från } 0\n\\end{align*}\\]\nDen reducerade modellen skapas utifrån att \\(H_0\\) är sann, det vill säga \\(\\beta_{Chinstrap} = \\beta_{Gentoo} = 0\\) och de två modellernas förklarade variation skulle betecknas som: \\[\n\\begin{aligned}\n  SSR_{R} &= SSR_{bill\\_depth\\_mm, flipper\\_length\\_mm, body\\_mass\\_g, sex} \\\\\n  SSR_{F} &= SSR_{bill\\_depth\\_mm, flipper\\_length\\_mm, body\\_mass\\_g, sex, species}\n\\end{aligned}\n\\]\nVi kan omformulera täljaren i Ekvation 5.3 till: \\[\nSS(species|bill\\_depth\\_mm, flipper\\_length\\_mm, body\\_mass\\_g, sex)\n\\] I de ANOVA-tabeller som presenterats tidigare kan vi få fram denna kvadratsumma direkt om art läggs till som den sista variabeln i modellen.\n\n\nVisa kod\nmodel &lt;- lm(bill_length_mm ~ bill_depth_mm + flipper_length_mm + body_mass_g + sex + species, data = modelData)\n\nanova(model) %&gt;% \n  round(4) %&gt;% \n  kable() %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 5.5: ANOVA-tabell från en modell där art läggs till sist\n\n\n\n\n \n  \n     \n    Df \n    Sum Sq \n    Mean Sq \n    F value \n    Pr(&gt;F) \n  \n \n\n  \n    bill_depth_mm \n    1 \n    518.9806 \n    518.9806 \n    105.5648 \n    0.0000 \n  \n  \n    flipper_length_mm \n    1 \n    4045.7248 \n    4045.7248 \n    822.9329 \n    0.0000 \n  \n  \n    body_mass_g \n    1 \n    6.1329 \n    6.1329 \n    1.2475 \n    0.2649 \n  \n  \n    sex \n    1 \n    68.4245 \n    68.4245 \n    13.9181 \n    0.0002 \n  \n  \n    species \n    2 \n    3686.9500 \n    1843.4750 \n    374.9776 \n    0.0000 \n  \n  \n    Residuals \n    326 \n    1602.6899 \n    4.9162 \n     \n     \n  \n\n\n\n\n\n\n\nEn ANOVA-tabell med sekventiella kvadratsummor beräknar ett partiellt F-test för respektive variabel (och dess parameter/parametrar) som undersöker huruvida variabeln bidrar med en signifikant ökning av den förklarade variationen till en modell som redan inkluderar variablerna ovanför. Tabell 5.5 beräknar nu det partiella F-test för art (\\(F_{test} = 374.9776\\)) som vi var intresserade av och vi kan direkt tolka p-värdet för testet (\\(p-värde &lt; 0.001\\)) som att minst en av lutningsparametrarna är signifikant skild från 0.\nOm vi genomför ett partiellt F-test för flera variabler kan vi inte använda p-värden som anges i tabellen då hypoteserna omfattar fler lutningsparametrar/variabler än vad de sekventiella kvadratsummorna visar. Anta att vi vill undersöka om art och kön tillsammans bidrar något till modellen. Hypotesprövningen skulle då omfatta:\n\\[\n\\begin{aligned}\nH_0&: \\beta_{sexMale} = \\beta_{Chinstrap} = \\beta_{Gentoo} = 0\\\\\nH_a&: \\text{Minst en av } \\beta_j \\text{ i } H_0 \\text{ är skild från } 0\n\\end{aligned}\n\\]\nDen sekventiella kvadratsumman som vi vill använda anges som \\(SS(species, sex|bill\\_depth\\_mm, flipper\\_length\\_mm, body\\_mass\\_g)\\) och vi kan beräkna fram detta värde genom att summera de två variablernas SS från Tabell 5.5.\n\\[\n\\begin{aligned}\nSS(species, sex|bill\\_depth\\_mm, flipper\\_length\\_mm, body\\_mass\\_g) = \\\\\nSS(species|bill\\_depth\\_mm, flipper\\_length\\_mm, body\\_mass\\_g, sex) + \\\\\nSS(sex|bill\\_depth\\_mm, flipper\\_length\\_mm, body\\_mass\\_g)\n\\end{aligned}\n\\] Alternativet är att anpassa två modeller i R, den kompletta och reducerade och läsa av SSE eller summera SSR från respektive ANOVA-tabell.\n\n\n5.2.2.2 Partiellt F-test för specifika värden\nVi kan ställa upp en generell modell som: \\[\\begin{align*}\n  Y = \\beta_0 + \\beta_1 \\cdot X_1 + \\beta_2 \\cdot X_2 + \\beta_3 \\cdot X_3 +\\beta_4 \\cdot X_4 +\\beta_5 \\cdot X_5+ E\n\\end{align*}\\]\nOm vi ska undersöka specifika parametrars värden (som inte är 0) kan vi genomföra följande härledning. Anta \\(H_0:\\) \\(\\beta_2=4\\) och \\(\\beta_5 = -2\\) som ska undersökas med ett test.\n\\[\\begin{align*}\nY &= \\beta_0 + \\beta_1 \\cdot X_1 + 4 \\cdot X_2 + \\beta_3 \\cdot X_3 +\\beta_4 \\cdot X_4 - 2 \\cdot X_5+ E\\\\\nY - 4 \\cdot X_2 + 2 \\cdot X_5 &= \\beta_0 + \\beta_1 \\cdot X_1  + \\beta_3 \\cdot X_3 +\\beta_4 \\cdot X_4 + E \\\\\nY^* &= \\beta_0 + \\beta_1 \\cdot X_1  + \\beta_3 \\cdot X_3 +\\beta_4 \\cdot X_4 + E\n\\end{align*}\\]\n\\(Y^*\\) kan anses vara en reducerad modell för ett F-test. I R kan detta inte lösas genom anova() utan måste beräknas ‘’för hand’’ genom att anpassa två modeller, den kompletta och den reducerade.\n\n\n\n5.2.3 t-test för enskilda parametrar\nAtt använda ANOVA-tabellen för att undersöka enskilda parametrar är inte lämpligt då det kräver att variabeln anges sist i modelleringen för att det partiella F-testet undersöker just den enskilda variabeln i relation till övriga modellen. Istället bör vi använda t-test för respektive parameter.\nFormellt undersöks hypoteserna: \\[\n\\begin{aligned}\n  H_0&: \\beta_j = 0\\\\\n  H_a&: \\beta_j \\ne 0\n\\end{aligned}\n\\] där \\(j\\) är någon av lutningsparametrarna i en anpassad modell.\nTestvariabeln beräknas utifrån den skattade lutningsparametern och dess medelfel: \\[\n\\begin{aligned}\nt_{test} = \\frac{b_j - 0}{s_{b_j}}\n\\end{aligned}\n\\]\nTestvariabeln är t-fördelad givet \\(H_0\\) med \\(n-(k+1)\\) frihetsgrader.\nI R används t-test i koefficienttabellen som vi kan plocka ut ur summary()-objektet genom coef().\n\n\nVisa kod\nsummary(simpleModel) %&gt;% \n  coef() %&gt;% \n  round(4) %&gt;% \n  kable(format = \"markdown\",\n        col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\"), \n        parse = TRUE) %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 5.6: Koefficienttabell för en modell med tillhörande t-test för enskilda parametrar\n\n\n\n\n \n  \n    Variabel \n    Skattning \n    Medelfel \n    t-värde \n    p-värde \n  \n \n\n  \n    (Intercept) \n    15.0166 \n    4.3742 \n    3.4330 \n    0.0007 \n  \n  \n    speciesChinstrap \n    9.5655 \n    0.3497 \n    27.3508 \n    0.0000 \n  \n  \n    speciesGentoo \n    6.4044 \n    1.0304 \n    6.2154 \n    0.0000 \n  \n  \n    bill_depth_mm \n    0.3130 \n    0.1541 \n    2.0316 \n    0.0430 \n  \n  \n    flipper_length_mm \n    0.0686 \n    0.0232 \n    2.9608 \n    0.0033 \n  \n  \n    body_mass_g \n    0.0011 \n    0.0004 \n    2.5617 \n    0.0109 \n  \n  \n    sexmale \n    2.0297 \n    0.3892 \n    5.2153 \n    0.0000 \n  \n\n\n\n\n\n\n\nI Tabell 5.6 ser vi att p-värdet för alla t-testen är väldigt låga (nära 0). För varje enskilda hypotesprövning kan vi på fem procents signifikans förkasta \\(H_0\\) vilket betyder att variabeln har en signifikant påverkan på responsvariabeln.\n\n\n\n\n\n\nViktigt\n\n\n\nOm en parameter inte anses signifikant är det en motivering till att variabeln kan plockas bort, vi anpassar en reducerad modell och en ny analys påbörjas. Om en variabel plockas bort kommer de övriga parameterskattningarna förändras och tolkningar samt inferens behöver uppdateras.\n\n\n\n\n5.2.4 Konfidensintervall för \\(\\beta\\)\nSlutsatsen vi kan dra från dessa hypotesprövningar är att modellen innehåller variabler som alla har ett signifikant samband med responsvariabeln. Om vi vill tolka magnituden av effekten gentemot populationen, inte bara om sambandet är signifikant, behöver vi beräkna intervallskattningar.\n\\[\n\\begin{aligned}\nb_j \\pm t_{n - (k+1); 1- \\alpha/2} \\cdot s_{b_j}\n\\end{aligned}\n\\]",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistisk inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/04-statistical-inference.html#sec-r-square",
    "href": "01-regression/04-statistical-inference.html#sec-r-square",
    "title": "5  Statistisk inferens",
    "section": "5.3 Enkla utvärderingsmått",
    "text": "5.3 Enkla utvärderingsmått\nBara för att en modell är lämplig, uppfyller modellantaganden och innehåller signifikanta parametrar, betyder det inte att modellen är den bästa som kan skapas eller överhuvudtaget bra. Med hjälp av olika utvärderingsmått kan vi få en överblick på hur bra modellen är.\nFörklaringsgraden (\\(R^2\\)) beskriver hur stor andel av den totala variationen som förklaras av modellens förklarande variabler. Med denna beskrivning kan vi beräkna \\(R^2\\) som: \\[\n\\begin{aligned}\n  R^2 = \\frac{SSR}{SST} = 1 - \\frac{SSE}{SST}\n\\end{aligned}\n\\] På grund av att SSR alltid blir större ju fler variabler som en modell innehåller, behöver vi justera måttet för att kunna jämföra modeller av olika storlekar. Istället bör vi titta på den justerade förklaringsgraden (\\(R^2_{a}\\)) för att se vilken modell som är bäst. En förbättrad \\(R^2_{a}\\) betyder att modellen har tagit bort onödig komplexitet.\n\\[\n\\begin{aligned}\n  R^2_a = 1 - \\frac{SSE / (n - (k+1))}{SST / (n - 1)}\n\\end{aligned}\n\\]",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistisk inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/04-statistical-inference.html#sec-predictions",
    "href": "01-regression/04-statistical-inference.html#sec-predictions",
    "title": "5  Statistisk inferens",
    "section": "5.4 Prediktioner",
    "text": "5.4 Prediktioner\nPrediktioner innebär att vi skattar värdet på Y givet observerade värden på X med hjälp av den anpassade regressionslinjen. Dessa prediktioner kommer falla längsmed linjen vilket ytterligare motiverar att modellen behöver vara lämplig och bra. Vi vill inte att en prediktion i ett område är mer träffsäker än en prediktion i en annan eller att regressionslinjen generellt är en dålig representation av responsvariabeln.\nModellen utgår från en specifik definitionsmängd, de observerade värdena på \\(\\mathbf{X}\\), och det är även inom denna mängd som prediktioner bör göras. Det finns vissa tillfällen, till exempel inom tidsserieanalys, där prediktioner görs utanför definitionsmängden men där finns ett beroende i tiden som möjliggör dessa extrapoleringar. Inom “vanlig” regression bör vi undvika att extrapolera regressionslinjen utanför definitionsmängden.\n\n5.4.1 Medelvärdet av Y för givna \\(\\mathbf{X}\\)\nOm vi är intresserad av det genomsnittliga värdet på responsvariabeln för alla nya observationer med givna värden på \\(\\mathbf{X}\\) kan vi skatta \\(\\mu_{Y|{\\mathbf{X}_0}}\\) där \\(\\mathbf{X}_0\\) innehåller värden för den nya observationen.\n\\[\n\\mathbf{X}_0 = \\begin{bmatrix}\n    1 \\\\\n    X_{1,0}\\\\\n    \\vdots\\\\\n    X_{k,0}\n    \\end{bmatrix}\n\\] Vi utgår från den anpassade regressionsmodellen och beräknar en punktprediktion av responsvariabeln enligt: \\[\n\\hat{Y}_{\\mathbf{X}_0} = \\mathbf{X}_0'\\boldsymbol{\\hat{\\beta}}\n\\]\nMedelfelet för skattningen tar hänsyn till:\n\\[\ns^2_{\\hat{Y}_{\\mathbf{X}_0}} = \\mathbf{X}_0'\\mathbf{s}^2_{\\boldsymbol{\\hat{\\beta}}}\\mathbf{X}_0\n\\]\nIntervallskattningen för ett genomsnitt blir ett konfidensintervall.\n\n\n5.4.2 Enskild prediktion av Y för givna \\(\\mathbf{X}\\)\nOm vi istället är intresserad av ett enskilt värde på Y med givna värden på \\(\\mathbf{X}\\), kan vi skatta \\(Y_{\\mathbf{X}_0}\\).\n\\[\ns^2_{pred} = MSE + s^2_{\\hat{Y}_{\\mathbf{X}_0}}\n\\] Intervallskattningen för ett värde av Y blir ett prediktionsintervall.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistisk inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/04-statistical-inference.html#footnotes",
    "href": "01-regression/04-statistical-inference.html#footnotes",
    "title": "5  Statistisk inferens",
    "section": "",
    "text": "Frihetsgrader beskriver egentligen hur många bitar oberoende information som finns för en beräkning. Tänk tillbaka på beräkningen av en stickprovsstandardavvikelse vars frihetsgrader är \\(n - 1\\), antalet observationer - 1, för att vi skattar medelvärdet när vi beräknar standardavvikelsen.↩︎\nOm vi hade tagit ett annat beslut (att inte förkasta nollhypotesen) hade det inte varit relevant att fortsätta med analysen, eller åtminstone att fokusera resterande analys på att undersöka varför en multipel linjär regressionsmodell som vi förväntar har ett samband utifrån parvisa spridningsdiagram inte visar på det tillsammans.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Statistisk inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/05-simultaneous-inference.html",
    "href": "01-regression/05-simultaneous-inference.html",
    "title": "6  Simultan inferens",
    "section": "",
    "text": "6.1 Simultan inferens\nNär en modell har undersökts med hjälp av residualanalys och statistisk inferens och vi kommit fram till att den är en lämplig och bra förenkling av verkligheten, kan vi börja använda den för att dra lärdomar om sambandet och prediktera nya observationer. Vi har i Avsnitt 5.2 redan fått några lärdomar om hur sambandet mellan vissa variabler ser ut men om vi vill tolka flera parametrar från modellen samtidigt bör vi tillämpa någon form av simultan inferens. En utav regressionsmodellers huvudsakliga användningsområden är att prediktera nya observationer. Till exempel kan responsvariabeln vara väldigt kostsam att mäta jämfört med de förklarande variablerna. Då kan en lämplig och bra regressionsmodellen minska kostnaderna genom att intervallskatta värdet på responsvariabeln utifrån givna värden på de förklarande variablerna. Prediktioner kan också användas för beslutsunderlag, till exempel kan en regressionsmodell ge information om förväntade inkomster givet en viss reklambudget.\nNär en modell innehåller flera förklarande variabler, alla med minst en tillhörande lutningsparameter, kommer vi genomföra flera inferensberäkningar om vi vill dra slutsatser om flera parametrar eller intervallskatta prediktioner för flera nya observationer. Varje hypotesprövning eller intervallskattning som beräknas utgår från att vi alltid har en risk att fatta fel beslut, vilket innebär att denna risk inflateras ju fler parametrar eller värden som undersöks med enskilda beräkningar. Typ I felet (signifikansnivån) beskriver risken att förkasta en sann \\(H_0\\).\nDen satiriska vetenskapliga serietecknaren xkcd har publicerat en serie som berör signifikansen av hypotesprövningar.\nEn grupp forskare, som hellre vill spela Minecraft, har fått i uppdrag att undersöka effekten av Jelly Beans på förekomsten av acne. Forskarna undersöker 20 olika färger av Jelly Beans med en signifikansnivå på fem procent. En utav färgerna visade sig ha en signifikant påverkan på förekomsten av acne och som vi ser i nyhetsartikeln allra sist i serien blir denna upptäckt innehållet på första sidan.\nVad är det som faktiskt har hänt här och är det korrekt att annonsera ut detta för världen? Vi kan skapa ett liknande simulerat exempel genom att genomföra 20 stycken urval från en population där vi vet det sanna medelvärdet.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simultan inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/05-simultaneous-inference.html#simultan-inferens",
    "href": "01-regression/05-simultaneous-inference.html#simultan-inferens",
    "title": "6  Simultan inferens",
    "section": "",
    "text": "Figur 6.1: xkcd, CC BY-NC 2.5\n\n\n\n\n\n\n6.1.1 Simulering\n\n\nVisa kod\n## Anger ett seed\nset.seed(12345)\n\n## Simulerar ett datamaterial från en given population med sanna värden\ndata &lt;- \n  replicate(\n    n = 20,\n    expr = rnorm(n = 30, mean = 0, sd = 1)\n  )\n\n\nObjektet data innehåller nu 20 stycken kolumner med 30 observationer i varje och varje kolumn är ett nytt urval (motsvarande en undersökning av en färg Jelly Bean). Alla dessa urval kommer från en population där \\(\\mu = 0\\) och det skulle vi kunna undersöka genom ett enkelt t-test för ett medelvärde. Formellt undersöks hypoteserna:\n\\[\n\\begin{aligned}\n  H_0 &: \\mu = 0\\\\\n  H_A &: \\mu \\ne 0\n\\end{aligned}\n\\]\ndär testvariabeln är \\[\nt_{test} = \\frac{\\bar{x} - 0}{ \\frac{s}{\\sqrt{n}}}\n\\]\n\n\nVisa kod\n## Testvariabeln för första urvalet\ntTest &lt;- (mean(data[,1]) - 0) / (sd(data[,1]) / sqrt(nrow(data))) \n\n\np-värdet för testet kan beräknas utifrån t-fördelningen med \\(n - 1\\) frihetsgrader. Vi måste dock ta hänsyn till att vi undersöker en dubbelsidig mothypotes vilket innebär att p-värdet är både större än den positiva testvariabeln och mindre än den negativa testvariabeln. Med hjälp av symmetrin i t-fördelningen kan vi räkna ut detta genom att beräkna absolutbeloppet av testvariabeln och multiplicera ytan större än detta värde med \\(2\\).\n\n\nVisa kod\n## Beräkning av p-värdet\npValue &lt;- 2 * pt(q = abs(tTest), df = nrow(data) - 1, lower.tail = FALSE) \n\n\nVi kan också använda inbyggda funktionen t.test() för att få fram samma resultat, där standardargumentet är att vi undersöker om populationsmedelvärdet är skilt från 0.\n\n\nVisa kod\nt.test(data[,1])\n\n\n\n    One Sample t-test\n\ndata:  data[, 1]\nt = 0.46006, df = 29, p-value = 0.6489\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -0.2715323  0.4291463\nsample estimates:\n mean of x \n0.07880701 \n\n\nVi kan replikera detta test och spara p-värdet för alla 20 olika utval med hjälp av apply(). Funktionen genomför en angiven funktion för varje element i ett objekt, i detta fall anger vi att den ska genomföra beräkningen för varje kolumn (MARGIN = 2) i objektet data.\n\n\nVisa kod\n## Kör samma funktion (t.test) för varje kolumn (MARGIN = 2) av datamaterialet\npValues &lt;- \n  apply(\n    X = data,\n    MARGIN = 2,\n    FUN = function(x){\n      t.test(x)$p.value\n    }\n  )\n\n\n\n\n\n\nTabell 6.1: p-värden för t-testet i respektive urval\n\n\n\n\n \n  \n    p-värde \n  \n \n\n  \n    0.649 \n  \n  \n    0.195 \n  \n  \n    0.036 \n  \n  \n    0.895 \n  \n  \n    0.806 \n  \n  \n    0.978 \n  \n  \n    0.341 \n  \n  \n    0.765 \n  \n  \n    0.981 \n  \n  \n    0.269 \n  \n  \n    0.092 \n  \n  \n    0.497 \n  \n  \n    0.228 \n  \n  \n    0.467 \n  \n  \n    0.114 \n  \n  \n    0.333 \n  \n  \n    0.268 \n  \n  \n    0.790 \n  \n  \n    0.290 \n  \n  \n    0.896 \n  \n\n\n\n\n\n\n\nI Tabell 6.1 är det endast ett test vars tillhörande p-värde är mindre än \\(\\alpha = 0.05\\) (urval 3), motsvarande den gröna Jelly Bean. Eftersom vi skapat dessa urval från en sann fördelning, vet vi att populationen har medelvärde 0 vilket innebär att vi gör ett fel av typ I, förkastar en sann \\(H_0\\). Med en signifikansnivå på 5 procent räknar vi att i 1 av 20 fall (5%) så fattar vi fel beslut utav ren slump. Desto fler tester som genomförs desto större risk att minst en av dessa tester kommer generera ett typ I-fel och att tolka ett enskilt test med 5 procents signifikans är missvisande.\nUnder antagandet att de olika urvalen är oberoende av varandra kan vi räkna ut den slutgiltiga risken för typ-I fel i minst en av testerna med hjälp av multiplikationssatsen för oberoende händelser:\n\\[\n\\begin{aligned}\n1 - (0.95 \\cdot 0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 &\\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95 \\cdot  0.95)\\\\\n&1 - (0.95^{20})\\\\\n&0.6415141\n\\end{aligned}\n\\] Risken att minst en utav 20 tester har förkastat en sann \\(H_0\\) är istället ca 64% istället för 5%.\n\n\n6.1.2 Familjekonfidens\nNär vi genomför flera tester kan vi istället justera konfidensgraden för varje individuella test så att vi får en sammanfattande konfidensnivå som vi också använder i tolkningen. Den enklaste varianten är att beräkna Bonferronis familjekonfidens där konfidensgraden beräknas enligt: \\[\n\\begin{aligned}\n  1 - \\alpha/2 \\Rightarrow 1 - \\alpha/(2 \\cdot g)\n\\end{aligned}\n\\] där \\(g\\) är antalet tester som genomförs.\n\n\nVisa kod\n# Plockar ur testvariabeln\nstatistic &lt;- \n  apply(\n    X = data,\n    MARGIN = 2,\n    FUN = function(x){\n      t.test(x)$statistic\n    }\n  )\n\ntibble(`Testvariabel` = statistic) %&gt;% \n  kable(digits = 3) %&gt;% \n  kable_styling(\"striped\", full_width = FALSE) \n\n\n\n\nTabell 6.2: Beräknad testvariabel för respektive urval\n\n\n\n\n \n  \n    Testvariabel \n  \n \n\n  \n    0.460 \n  \n  \n    1.328 \n  \n  \n    2.196 \n  \n  \n    0.134 \n  \n  \n    -0.248 \n  \n  \n    0.028 \n  \n  \n    0.969 \n  \n  \n    0.302 \n  \n  \n    0.024 \n  \n  \n    -1.127 \n  \n  \n    1.744 \n  \n  \n    0.689 \n  \n  \n    1.231 \n  \n  \n    -0.737 \n  \n  \n    1.629 \n  \n  \n    -0.984 \n  \n  \n    -1.129 \n  \n  \n    0.268 \n  \n  \n    1.077 \n  \n  \n    0.132 \n  \n\n\n\n\n\n\n\nDet justerade kritiska tabellvärdet är \\(\\pm t_{30 - 1, 1 - 0.05 / (2 \\cdot 20)} = \\pm\\) 3.31 istället för \\(\\pm t_{30 - 1, 1 - 0.05 / (2)} = \\pm\\) 2.045 vilket innebär att ingen testvariabel i Tabell 6.2 ligger extremare än det justerade. Med en simultan signifikansnivå på fem procent förkastas ingen av testernas nollhypoteser.\n\n\n6.1.3 Familjekonfidens för lutningsparametrar\nMed hjälp av Bonferroni:s familjekonfidens kan vi justera formlerna för intervallskattning av lutningsparametrarna. En generell formel för en intervallskattning kan skrivas såsom: \\[\n\\text{punktskattning} \\pm \\text{tabellvärde} \\cdot \\text{medelfel}\n\\tag{6.1}\\]\nI fallet för \\(\\beta_1\\) blir formeln: \\[\n    b_1 \\pm t_{n - (k+1); 1- \\alpha/2} \\cdot s_{b_1}\n\\] Bonferroni:s familjekonfidens leder till att formeln justeras enligt: \\[\n    b_1 \\pm t_{n - (k+1); 1- \\alpha/(2\\cdot g)} \\cdot s_{b_1}\n\\] , där \\(g\\) är antalet lutningsparametrar som ska undersökas samtidigt.\n\\(t_{n-(k+1); 1 - \\alpha/(2\\cdot g)}\\) brukar också anges som \\(B\\). När \\(g\\) är stort, kommer värden från \\(t\\)-fördelningen också vara stora vilket i slutändan kan leda till intervall som inte ger någon vettig information. Därför följer att Bonferronis metod är lämpligast att användas när antalet intervall eller tester är få.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simultan inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/05-simultaneous-inference.html#intervallskattning-av-flera-prediktioner",
    "href": "01-regression/05-simultaneous-inference.html#intervallskattning-av-flera-prediktioner",
    "title": "6  Simultan inferens",
    "section": "6.2 Intervallskattning av flera prediktioner",
    "text": "6.2 Intervallskattning av flera prediktioner\nOm vi är intresserade av att prediktera flera nya observationer kommer vi behöva använda simultan inferens för att samtidigt dra slutsatser om de alla.\n\n6.2.1 Skattning av flera konfidensintervall\nOm vi vill beräkna konfidensband för hela regressionslinjen, i.e. \\(\\mu_Y\\) för alla punkter av \\(\\mathbf{X}\\), kan Working-Hotelling:s metod skapa denna region. Strukturen från formel Ekvation 6.1 ger då följande formel:\n\\[\n\\begin{aligned}\n  \\hat{Y}_{\\mathbf{X}_0} \\pm W \\cdot s_{\\hat{Y}_{\\mathbf{X}_0}}\n\\end{aligned}\n\\tag{6.2}\\]\ndär \\(W^2 = 2\\cdot F_{k+1; n-(k+1); 1-\\alpha}\\).\nDenna beräkning tar redan hänsyn till alla möjliga punkter av \\(\\mathbf{X}\\) som regressionslinjen täcker, vilket innebär att samma formler kan användas för enstaka nya observationer, \\(\\mathbf{X}_{\\mathbf{X}_0}\\).\nÄven för prediktioner av responsvariabeln kan Bonferroni användas enligt: \\[\n  \\hat{Y}_{\\mathbf{X}_0} \\pm B \\cdot s_{\\hat{Y}_{\\mathbf{X}_0}}\n\\tag{6.3}\\] där \\(B = t_{n-(k+1); 1 - \\alpha/(2\\cdot g)}\\)\nEkvation 6.2 ger generellt smalare intervall än Ekvation 6.3 då \\(W\\) är samma värde oavsett hur många intervall som skattas medan \\(B\\) ökar med antalet \\(g\\).\n\n\n6.2.2 Skattning av flera prediktionsintervall\nFör enstaka nya observationer beräknas istället prediktionsintervall vilket innebär att skattningens medelfel förändras. Metoder för att beräkna \\(g\\) prediktionsintervall är Scheffé och Bonferronis metoder.\nScheffés metod: \\[\\begin{align}\n   \\hat{Y}_{\\mathbf{X}_0} \\pm S \\cdot s_{pred}\n\\end{align}\\] där \\[\\begin{align*}\n    S &= g \\cdot F_{g; n-k+1; 1 - \\alpha}\\\\\n    s_{pred} &= \\sqrt{MSE + s^2_{\\hat{Y}_{\\mathbf{X}_0}}}\n\\end{align*}\\]\nBonferronis metod: \\[\\begin{align}\n    \\hat{Y}_{\\mathbf{X}_0} \\pm B \\cdot s_{pred}\n\\end{align}\\] där \\[\\begin{align*}\n    B = t_{n-k+1; 1 - \\alpha/(2\\cdot g)}\n\\end{align*}\\]\nBåda dessa metoder kommer skapa bredare intervall i relation till antalet intervall som skattas eftersom \\(g\\) inkluderas i båda beräkningarna. Detta skiljer sig från Ekvation 6.2 där \\(W\\) inte blir större desto fler intervall.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Simultan inferens</span>"
    ]
  },
  {
    "objectID": "01-regression/06-complex-predictors.html",
    "href": "01-regression/06-complex-predictors.html",
    "title": "7  Komplexa samband",
    "section": "",
    "text": "7.1 Interaktioner\nI det utforskande steget av en undersökning kan vi ibland identifiera mer komplexa typer av samband mellan en förklarande variabel och responsvariabeln. Exempelvis identifierade vi i Figur 2.6 grupper av punkter som visade ett positivt samband medan punktsvärmen överlag visade på ett negativt samband. Den linjära regressionsmodellen kan också med hjälp av vissa transformeringar modellera icke-linjära samband.\nIbland kan en kombination av flera variabler förändra effekten som variablerna har enskilt med en responsvariabel. Till exempel kan temperaturens effekt på elkonsumtionen (länk till datamaterialet ) i en bostad påverkas av förekomsten av bergvärme.\nLäs in materialet och filtera bort saknade värden med:\npower &lt;- read.csv2(file = \"electricityconsumption.csv\", dec = \".\") %&gt;% \n  dplyr::mutate(Bergsvärme = Bergsvärme %&gt;% as_factor()) %&gt;% \n  dplyr::filter(!(Bergsvärme %&gt;% is.na() | Dygnsmedel %&gt;% is.na()))\nVisa kod\nggplot(power) + \n  aes(x = Dygnsmedel, y = Energi_KWh, color = Bergsvärme) + \n  geom_point() + \n  theme_bw() + \n  scale_color_manual(values = c(\"steelblue\", \"#d9230f\"), \n                     labels = c(\"Ej installerad\", \"Installerad\")) +\n  labs(x = \"Temperatur\", y = \"Elkonsumtion (kWh)\", caption = \"Källa: Insamlad data från en bostad i Norrbotten.\")\n\n\n\n\n\n\n\n\nFigur 7.1: Sambandet mellan temperatur och elkonsumtion uppdelat på förekomsten av bergsvärme\nFigur 7.1 visar två olika samband mellan temperatur och elkonsumtion beroende på om observationen (tidpunkten) mätte sambandet när bergsvärme var installerad i bostaden eller ej. När bergsvärme finns verkar påverkan av temperatur vara mindre (\\(\\beta = -1.432\\)) än när bergsvärme saknas (\\(\\beta = -3.626\\)), förändringen i elkonsumtion för varje ökad grad av temperatur har förändrats.\nFör att modellen ska plocka upp variablernas synergi med varandra skapas en interaktion som en produkt av, i det enklaste fallet, de två variablerna och läggs till i modellen med en ytterligare tillhörande lutningsparameter.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Komplexa samband</span>"
    ]
  },
  {
    "objectID": "01-regression/06-complex-predictors.html#sec-interaction",
    "href": "01-regression/06-complex-predictors.html#sec-interaction",
    "title": "7  Komplexa samband",
    "section": "",
    "text": "7.1.1 Interaktion mellan en kvalitativ och en kvantitativ variabel\nEn utav de enklare formerna av en interaktion är mellan en kvalitativ och en kvantitativ variabel, som vi såg ett exempel på i Figur 7.1. Om vi ser ett sådant fenomen i ett spridningsdiagram tyder det på att de två variablerna interagerar med varandra för att skapa olika lutningsparametrar.\n\\[\n\\begin{aligned}\n  Y_i = \\beta_0 + \\beta_1 \\cdot \\text{temperatur}_i + \\beta_2 \\cdot \\text{bergsvärme}_i + \\beta_3 \\cdot \\text{temperatur}_i \\cdot \\text{bergsvärme}_i + E_i\n\\end{aligned}\n\\] där \\(\\text{bergsvärme}_i\\) är en indikatorvariabel som indikerar 1 om bergsvärme förekommer och 0 annars.\nKodningen av indikatorvariabeln betyder att vi egentligen får två olika möjliga utfall av modellen, en när \\(\\text{bergsvärme}_i = 1\\) och en när \\(\\text{bergsvärme}_i = 0\\).\n\\[\n\\begin{aligned}\n  Y_{i|\\text{bergsvärme} = 1} &= \\beta_0 + \\beta_1 \\cdot \\text{temperatur}_i + \\beta_2 \\cdot 1 + \\beta_3 \\cdot \\text{temperatur}_i \\cdot 1 + E_i \\\\\n  &= \\beta_0 + \\beta_1 \\cdot \\text{temperatur}_i + \\beta_2 + \\beta_3 \\cdot \\text{temperatur}_i + E_i\\\\\n  &= \\underbrace{( \\beta_0 + \\beta_2 )}_{\\beta_0^*} + \\underbrace{(\\beta_1 + \\beta_3)}_{\\beta_1^*} \\cdot \\text{temperatur}_i + E_i\\\\\n  \\\\\n  Y_{i|\\text{bergsvärme} = 0} &= \\beta_0 + \\beta_1 \\cdot \\text{temperatur}_i + \\beta_2 \\cdot 0 + \\beta_3 \\cdot \\text{temperatur}_i \\cdot 0 + E_i\\\\\n  &= \\beta_0 + \\beta_1 \\cdot \\text{temperatur}_i + E_i\n\\end{aligned}\n\\] När \\(\\text{bergsvärme}_i = 1\\) skapas en enkel linjär modell med ett ‘nytt’ intercept \\(\\beta_0^*\\) och en ny lutningsparameter \\(\\beta_1^*\\). \\(\\beta_2\\) och \\(\\beta_3\\) är alltså den kategoriska variabelns påverkan på regressionslinjens intercept respektive lutning. Vi kan generellt säga att med flera kategorier (indikatorvariabler) skapas flera varianter av modellen med en referenslinje när alla indikatorer är 0, och en linje för varje indikator som blir 1 där interceptet och lutningen förändras jämfört med referenslinjen.\nFör att skapa en interaktion i modellen med hjälp av R kan symbolen * användas:\n\nmodel &lt;- lm(Energi_KWh ~ Dygnsmedel * Bergsvärme, data = power)\n\nsummary(model) %&gt;% \n  coef() %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\")) %&gt;% \n  kable_styling(\"striped\")\n\nKoefficienttabell från en modell med en interaktion\n \n  \n    Variabel \n    Skattning \n    Medelfel \n    t-värde \n    p-värde \n  \n \n\n  \n    (Intercept) \n    80.115 \n    0.328 \n    244.008 \n    0 \n  \n  \n    Dygnsmedel \n    -3.626 \n    0.030 \n    -119.777 \n    0 \n  \n  \n    Bergsvärme1 \n    -45.664 \n    0.375 \n    -121.610 \n    0 \n  \n  \n    Dygnsmedel:Bergsvärme1 \n    2.194 \n    0.035 \n    62.308 \n    0 \n  \n\n\n\n\nEftersom bergsvärme anges som en faktorvariabel hanterar R detta korrekt (se Avsnitt 3.1) och hade även gjort det om det fanns flera kategorier. I detta fall skapas endast en ny variabel mellan indikatorvariabeln och den numeriska då det endast fanns två kategorier (en indikatorvariabel). Om fler indikatorvariabler hade skapats från den kvalitativa variabeln, hade fler interaktioner skapats, en för varje kombination av indikatorvariabel och kontinuerlig variabel.\nVi kan tolka dessa skattningar som att om bostaden har bergsvärme installerad, sänks förbrukningen vid 0 grader med ca 45 kWh och temperaturens påverkan på konsumtionen förändras med ca 2.2 kWh mindre per ökad grad1 jämfört med en bostad utan bergsvärme. Vi får alltså två modeller:\n\\[\n\\begin{aligned}\n  \\hat{Y}_{i|\\text{bergsvärme} = 1} &= ( 80.115 + -45.664 ) + (-3.626 + 2.194) \\cdot \\text{temperatur}_i \\\\\n  \\\\\n  \\hat{Y}_{i|\\text{bergsvärme} = 0} &= 80.115 + -3.626 \\cdot \\text{temperatur}_i\n\\end{aligned}\n\\] som vi kan visualisera i det tidigare diagrammet med:\n\n\nVisa kod\nggplot(power) + \n  aes(x = Dygnsmedel, y = Energi_KWh, color = Bergsvärme) + \n  geom_point() + \n  theme_bw() + \n  scale_color_manual(values = c(\"steelblue\", \"#d9230f\"), \n                     labels = c(\"Ej installerad\", \"Installerad\")) +\n  labs(x = \"Temperatur\", y = \"Elkonsumtion (kWh)\", caption = \"Källa: Insamlad data från en bostad i Norrbotten.\") +\n  ## Lägga till regressionslinjer\n  #  Ej installerad (Referenslinjen)\n  geom_abline(\n    intercept = coef(model)[1],\n    slope = coef(model)[2],\n    color = \"black\",\n    linewidth = 1,\n    linetype = 2\n  ) + \n  #  Installerad\n  geom_abline(\n    intercept = coef(model)[1] + coef(model)[3],\n    slope = coef(model)[2] + coef(model)[4],\n    color = \"black\",\n    linewidth = 1\n  )\n\n\n\n\n\nSpridningsdiagram med gruppvisa regressionslinjer\n\n\n\n\n\n7.1.1.1 Simpson’s paradox\n\n\n\n7.1.2 Interaktion mellan två kvantitativa variabler\nEn interaktion mellan två kvantitativa variabler är svårare att visualisera och identifiera. Anta att vi har ett datamaterial som består av två förklarande variabler och en responsvariabel där det sanna sambandet inkluderar en interaktion mellan de förklarande variablerna.\n\n\nVisa kod\n# Antal observationer\nn &lt;- 200\n\nset.seed(64)\n\n## Skapa ett datamaterial\ndata &lt;- \n  tibble(\n    x1 = runif(n = n, min = 0, max = 5),\n    x2 = rnorm(n = n, mean = 0, sd = 3),\n    y = 10 + 1.5*x1 - 1.5*x2 - 3*x1*x2 + rnorm(n = n)\n  )\n\n## Utforskning av materialet\np1 &lt;- ggplot(data) + aes(x = x1, y = y) + geom_point(color = \"steelblue\") + theme_bw()\n\np2 &lt;- ggplot(data) + aes(x = x2, y = y) + geom_point(color = \"steelblue\") + theme_bw()\n\np3 &lt;- ggplot(data) + aes(x = x1, y = x2) + geom_point(color = \"steelblue\") + theme_bw()\n\ncowplot::plot_grid(p1, p2, p3)\n\n\n\n\n\nSpridningsdiagram över de olika variablerna i materialet.\n\n\n\n\nMed detta enkla exempel med endast två variabler och deras interaktion kan vi visualisera materialet med ett fåtal diagram och utläsa att modellen uppvisar någon form av komplext samband som inte de enskilda förklarande variablerna kan modellera. Desto fler förklarande variabler som finns minskar effektiviteten att identifiera interaktioner från enskilda parvisa diagram, vilket innebär att vi oftast identifierar behov av interaktioner utifrån modellanpassningar och residualanalys.\n\n\nVisa kod\ndåligModell &lt;- lm(y ~ x1 + x2, data = data)\n\ndiagnosticPlots(dåligModell)\n\n\n\n\n\nResidualer från den felaktigt formulerade modellen.\n\n\n\n\nLikt när vi tittar på en potentiell interaktion mellan en kvalitativ och kvantitativ variabel visas det tydligt i residualerna mot de anpassade värdena att det saknas något samband i modellen då residualerna inte uppvisar konstant varians. Även normalfördelningsdiagrammen identifierar långa svansar med många värden i extremerna.\n\n\nVisa kod\nbraModell &lt;- lm(y ~ x1 * x2, data = data)\n\ndiagnosticPlots(braModell)\n\n\n\n\n\nResidualerna från en lämplig modell\n\n\n\n\nNu ser residualerna bättre ut och det verkar som att modellen är en korrekt representation av sambandet.\nTill skillnad från Avsnitt 7.1.1 kommer tolkningar av interaktioner mellan två kvantitativa variabler bli betydligt svårare. Modellen kan inte på ett enkelt sätt ‘förenklas’ likt i det kvalitativa fallet men på ett ungefär kan vi säga att lutningsparametern för interaktionen påverkar lutningsparametern för respektive grundvariabel.\n\\[\n\\begin{aligned}\n  Y_i &= \\beta_0 + \\beta_1 \\cdot X_{i1} + \\beta_2 \\cdot X_{i2} + \\beta_3 \\cdot X_{i1} \\cdot X_{i2} + E_i \\\\\n  &\\qquad \\qquad \\qquad \\text{alternativt}  \\\\\n  Y_i &= \\beta_0 + \\beta_1 \\cdot X_{i1} + (\\beta_2 + \\beta_3 \\cdot X_{i1}) \\cdot X_{i2} + E_i\\\\\n  \\\\\n  Y_i &= \\beta_0 + (\\beta_1 + \\beta_3 \\cdot X_{i2}) \\cdot X_{i1} + \\beta_2 \\cdot X_{i2} + E_i\n\\end{aligned}\n\\] Eftersom vi i en multipel linjär regression tolkar parameterskattningar som att den förklarande variabeln förändrar responsvariabeln givet att alla andra variabler är fixa kommer en tolkning av en förändring i en förklarande variabel innebära att Y förändras på två platser. I den första alternativa formuleringen ser vi hur en förändring av \\(X_{i1}\\) leder till att Y förändras både via \\(\\beta_1\\) och hur \\(X_{i2}\\)s samband med Y (\\(\\beta_2\\)) förändras med anledning av \\(\\beta_3\\).\nDet vi kan göra för att tolka en variabels effekt på responsvariabeln är att kombinera alla termer som omfattar variabeln och visualisera dens sammanfattande effekt givet att alla andra variabler är konstanta. För en interaktion mellan två kontinuerliga variabler kan vi fixera olika värden på den ena variabeln och modellera den andra variabelns effekt mot responsvariabeln. Ett vanligt sätt att göra detta är att fixera med hjälp av medelvärdet och en standardavvikelse åt båda hållen.\n\n\nVisa kod\nsummary(braModell) %&gt;% \n  coef() %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\")) %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 7.1: Koefficienttabell från en modell med en interaktion\n\n\n\n\n \n  \n    Variabel \n    Skattning \n    Medelfel \n    t-värde \n    p-värde \n  \n \n\n  \n    (Intercept) \n    9.960 \n    0.155 \n    64.063 \n    0 \n  \n  \n    x1 \n    1.466 \n    0.052 \n    28.279 \n    0 \n  \n  \n    x2 \n    -1.538 \n    0.053 \n    -29.287 \n    0 \n  \n  \n    x1:x2 \n    -2.981 \n    0.017 \n    -176.049 \n    0 \n  \n\n\n\n\n\n\n\n\n\nVisa kod\n# Tar ut skattade koefficienter från modellen med interaktion\nb &lt;- coef(braModell)\nmeanX2 &lt;- mean(data$x2)\nsdX2 &lt;- sd(data$x2)\n\nintData &lt;- \n  tibble(\n    # Skapa olika värden av x1 givet värdemängden\n    x1 = seq(min(data$x1), max(data$x1), by = 0.01),\n    y1 = b[1] + (b[2] + b[4]*(meanX2 - sdX2))*x1 + b[3] * (meanX2 - sdX2),\n    y2 = b[1] + (b[2] + b[4]*(meanX2))*x1 + b[3] * (meanX2),\n    y3 = b[1] + (b[2] + b[4]*(meanX2 + sdX2))*x1 + b[3] * (meanX2 + sdX2)\n  ) %&gt;% \n  pivot_longer(\n    !x1\n  )\n\nggplot(intData) + aes(x = x1, y = value, color = name) + geom_line(linewidth = 1) + \n  scale_color_manual(expression(X[2]), values = c(\"steelblue\", \"#d9230f\", \"black\"), labels = expression(mu - sigma, mu, mu + sigma)) + \n  theme_bw() + labs(x = expression(X[1]), y = \"Y\")\n\n\n\n\n\n\n\n\nFigur 7.2: \\(X_1\\):s effekt på responsvariabeln för ett givet värde på \\(X_2\\)\n\n\n\n\n\n\n\n\n\n\n\nVarning\n\n\n\nOm fördelningen av \\(X_2\\) inte är symmetrisk kan valet av ovanstående fixa värden vara missvisande. Om vi vill visualisera olika värden bör vi fundera över vilka som faktiskt är lämpliga att använda.\n\n\nDet vi kan utläsa från Figur 7.2 är att effekten av \\(X_1\\) är positiv för låga värden av \\(X_2\\) och vänder till negativ för höga värden av \\(X_2\\). I ett enkelt fall som denna går det att visa och till viss del tolka interaktionens effekt på ett någorlunda tydligt sätt, men i en mer komplex modell blir det direkt rörigt. Vi bör istället titta på residualanalyser och annan utvärdering av modellen för att bedöma om interkationen gör att modellen blir bättre. Avvägningen mellan modellens komplexitet och dess träffsäkerhet är än mer viktig att diskutera för att modellen ska uppnå sitt syfte.\n\n\n7.1.3 Identifiera interaktion\nVanligtvis kan vi få ledtrådar om interaktioner i de parvisa sambanden, speciellt om det är en interaktion beskriven i Avsnitt 7.1.1, men ibland är det svårt att direkt se ifall en interaktion behövs. Det är också svårt att utläsa mellan exakt vilka variabler som interaktionen finns. Med hjälp av grupperade spridningsdiagram likt Figur 7.1 (kvalitativa och kvantitativa) eller 3D-diagram (kvantitativa och kvantitativa) kan sambandet mellan par av förklarande variabler och responsvariabeln undersökas. Vi kan också skapa potentiella interaktioner och modellera dessa mot responsvariabeln i ett spridningsdiagram.\n\n\nVisa kod\nggplot(data) + aes(x = x1*x2, y = y) + geom_point(color = \"steelblue\") + \ntheme_bw() + labs(x = \"Interaktion\", y = \"Y\")\n\n\n\n\n\nInteraktionen mellan \\(X_1\\) och \\(X_2\\) och dess samband med Y\n\n\n\n\nDiagrammet visar ett starkt negativt linjärt samband mellan interaktionen och responsvariabeln, vilket antyder att interaktionen har en betydande roll i modelleringen. Med flera variabler kommer antalet interaktioner som skulle kunna skapas öka exponentiellt\nDet går också att utläsa från residualanalysen ifall modellen inte plockar upp något samband med responsvariabeln men även med hjälp av dessa diagram kan det vara svårt att utläsa exakt vad för samband som saknas och vilka variabler som behöver justeras. Det är i detta läge som spridningsdiagram över residualerna uppdelat på de olika förklarande variablerna kan ge en indikation på vad som behöver justeras.\nLåt oss anpassa en felaktig modell utan interaktion och titta på residualerna:\n\n\nVisa kod\ndiagnosticPlots(model = lm(Energi_KWh ~ Dygnsmedel + Bergsvärme, data = power))\n\n\n\n\n\n\n\n\n\nDet är framförallt i diagrammet överst till höger som det syns att modellen saknar att modellera någon form av samband mellan variablerna.\n\n\nVisa kod\nmodelNoInt &lt;- lm(Energi_KWh ~ Dygnsmedel + Bergsvärme, data = power)\n\nvisData &lt;- \n  tibble(\n    Residualer = resid(modelNoInt),\n    X1 = power$Dygnsmedel,\n    X2 = power$Bergsvärme\n  ) \n\nggplot(visData) + aes(x = X1, y = Residualer) + \n  geom_point(color = \"steelblue\") +\n  theme_bw() + labs(x = \"Temperatur\")\n\n\n\n\n\nResidualer mot förklarande variabler\n\n\n\n\nVisa kod\nggplot(visData) + aes(x = X2, y = Residualer) + \n  geom_violin(fill = \"steelblue\") +\n  theme_bw() + labs(x = \"Bergsvärme\")\n\n\n\n\n\nResidualer mot förklarande variabler\n\n\n\n\nOm vi sedan visualiserar residualerna uppdelat på de två förklarande variablerna kan vi utläsa ett korsliknande mönster i den kvantitativa variabeln vilket antyder att vi har gruppvisa samband.\n\n\nVisa kod\ndiagnosticPlots(model = model) \n\n\n\n\n\n\n\n\n\nNär interaktionen lagts till ser residualerna mycket bättre ut, dock inte helt perfekta för just denna modell.\n\n\nVisa kod\nmodelInt &lt;- lm(Energi_KWh ~ Dygnsmedel * Bergsvärme, data = power)\n\nvisData &lt;- \n  tibble(\n    Residualer = resid(modelInt),\n    X1 = power$Dygnsmedel,\n    X2 = power$Bergsvärme\n  ) \n\nggplot(visData) + aes(x = X1, y = Residualer) + \n  geom_point(color = \"steelblue\") +\n  theme_bw() + labs(x = \"Temperatur\")\n\n\n\n\n\nResidualer mot förklarande variabler\n\n\n\n\nResidualerna mot temperatur har nu inte samma korsliknande mönster vilket har plockats upp av interaktionen dock syns ett svagt icke-linjärt mönster och framförallt problem med lika varians.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Komplexa samband</span>"
    ]
  },
  {
    "objectID": "01-regression/06-complex-predictors.html#polynom",
    "href": "01-regression/06-complex-predictors.html#polynom",
    "title": "7  Komplexa samband",
    "section": "7.2 Polynom",
    "text": "7.2 Polynom\nVi kan modellera vissa typer av icke-linjära samband mellan x och y genom att genomföra lämpliga transformationer av x, exempelvis polynomtermer. Vi simulerar ett datamaterial för att illustrera detta.\n\n## Simulera data\nset.seed(2323)\n\n# Skapa 100 observationer\nn &lt;- 100\n\n# Slumpa värden mellan -5 och 15 från den likformiga fördelningen\nx &lt;- runif(n = n, min = -5, max = 15)\n\n# Skapa responsvariabeln genom en kvadratisk funktion och lägg till slumpvariation med rnorm()\ny &lt;- 4-1*x+0.2*x^2 + rnorm(n = n)\n\nVi kan visualisera detta datamaterial för att se ett icke-linjärt samband mellan de två variablerna. Eftersom vi utför simulering vet vi också vad de sanna parametrarna för modellen ska vara, vilket vi kan stämma av i senare utskrifter.\n\n\nVisa kod\n## Lägg in de två variablerna i ett datamaterial för ggplot2\ndata &lt;- \n  tibble(\n    X = x,\n    Y = y\n  )\n\nggplot(data) + aes(x = X, y = Y) + \n  geom_point(color = \"steelblue\") + theme_bw()  \n\n\n\n\n\nExempel på icke-linjärt samband mellan X och Y\n\n\n\n\nOm vi testar att först anpassa en “vanlig” linjär regression och utvärderar residualerna kommer vi se att residualantagandet om linjäritet inte uppfylls.\n\n\nVisa kod\nmodel &lt;- lm(Y ~ X, data = data)\n\ndiagnosticPlots(model)\n\n\n\n\n\nResidualdiagram från en linjär modell med ett icke-linjärt samband\n\n\n\n\nDessa residualer ser inte bra ut, egentligen inte för någon utav antaganden, men det är främst residualerna mot de anpassade värdena som visar på det största problemet. Vi ser ett tydligt krökt mönster i punkterna som indikerar på att modellen inte är korrekt strukturerad.\nVi kan anpassa polynom på olika sätt. Ett enkelt sätt att göra är att inkludera en ny variabel i datamaterialet som är en transformation av den förklarande variabeln, till exempel skapa \\(X^2\\) som en ny kolumn.\n\n\nVisa kod\n# Sparar över det gamla materialet\ndata &lt;- \n  data %&gt;% \n  # Skapar en ny variabel som kvadraten av x\n  mutate(\n    X2 = x^2\n  )\n\n# Anpassa en ny modell\nmodel &lt;- lm(Y ~ ., data = data)\n\nsummary(model) %&gt;% \n  coef() %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\")) %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 7.2: Skattade koefficienter från en modell med polynom\n\n\n\n\n \n  \n    Variabel \n    Skattning \n    Medelfel \n    t-värde \n    p-värde \n  \n \n\n  \n    (Intercept) \n    4.240 \n    0.151 \n    28.103 \n    0 \n  \n  \n    X \n    -1.057 \n    0.042 \n    -24.930 \n    0 \n  \n  \n    X2 \n    0.204 \n    0.004 \n    55.630 \n    0 \n  \n\n\n\n\n\n\n\n\n\nVisa kod\ndiagnosticPlots(model)\n\n\n\n\n\nResidualdiagram från en modell med polynom\n\n\n\n\nDenna modell ser ut att uppfylla modellantaganden eftersom vi har lagt till en variabel som tar hänsyn till det icke-linjära samband som X har med Y. Parameterskattningarna som vi får från modellen stämmer också till stor del överens med den sanna modell som vi simulerat materialet ifrån.\n\n7.2.1 Centrering\nNär polynom används är det önskvärt att centrera eller standardisera grundvariablerna som används för polynomen. Detta görs för att minska de värden som modellen använder till sin anpassning (beräkningskomplexitet) och för att variablerna skapas utifrån varandra och har ett starkt beroende mellan sig (multikollinearitet, Avsnitt 8.1). Det finns många problem med starka beroenden mellan förklarande variabler och ett utav dem är att höga kovarianser leder till icke-informativ inferens.\n\n\nVisa kod\n# Skapa centrerad data\ndataCent &lt;- \n  data %&gt;% \n  mutate(\n    # Centrera variabeln x med hjälp av scale()\n    # Standardisering kan göras genom argument scale = TRUE \n    XCent = X %&gt;% scale(center = TRUE, scale = FALSE),\n    X2Cent = XCent^2\n  )\n\n\nVi kan med hjälp av colMeans() se medelvärden för de icke-centrerade och centrerade variablerna. Det finns en stor skillnad, främst för polynomens medelvärde vilket visar på syftet med centrering, att reducera värden som används inom modellanpassningen.\n\n\nVisa kod\ncolMeans(dataCent) %&gt;% \n  round(3) %&gt;% \n  kable(col.names = \"Medelvärde\") %&gt;% \n  kable_styling(full_width = FALSE)\n\n\nVariablernas medelvärden\n \n  \n     \n    Medelvärde \n  \n \n\n  \n    X \n    5.399 \n  \n  \n    Y \n    11.555 \n  \n  \n    X2 \n    63.871 \n  \n  \n    XCent \n    0.000 \n  \n  \n    X2Cent \n    34.727 \n  \n\n\n\n\nNär vi anpassar en modell med polynom finns det också ett alternativt sätt att göra det på. Vi har i de tidigare exemplen skapat polynomet som en ny variabel i datamaterialet och kan inkludera den variabeln (X2 eller X2Cent) i modellstrukturen för lm(). Vi behöver egentligen inte skapa en ny variabel, och det brukar vi inte heller göra i praktiken om det ska skapas flera polynom av olika grad. Istället kan vi i formeln ange hur vi vill transformera grundvariabler med hjälp av I(X^2) där exponenten anger graden av polynomet. Om vi inte använder I() runt vår beräkning kommer R inte skapa ett polynom.\n\n\nVisa kod\n# Anpassa ny modell med centrerad x\nmodelCent &lt;- lm(Y ~ XCent + X2Cent, data = dataCent)\n\n# Alternativt \nmodelCent &lt;- lm(Y ~ XCent + I(XCent^2), data = dataCent)\n\nsummary(modelCent) %&gt;% \n  coef() %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\")) %&gt;% \n  kable_styling(\"striped\")\n\n\n\n\nTabell 7.3: Skattade koefficienter från en modell med centrerade polynom\n\n\n\n\n \n  \n    Variabel \n    Skattning \n    Medelfel \n    t-värde \n    p-värde \n  \n \n\n  \n    (Intercept) \n    4.475 \n    0.168 \n    26.681 \n    0 \n  \n  \n    XCent \n    1.144 \n    0.019 \n    61.526 \n    0 \n  \n  \n    I(XCent^2) \n    0.204 \n    0.004 \n    55.630 \n    0 \n  \n\n\n\n\n\n\n\n\n\nVisa kod\ndiagnosticPlots(modelCent)\n\n\n\n\n\nResidualdiagram från en modell med centrerade polynom\n\n\n\n\nModellen får olika parameterskattningar för grundvariabeln jämfört med den icke-centrerade modellen (Tabell 7.2) eftersom variablerna som används till anpassningen har olika tolkningar. När vi centrerar en variabel tolkas lutningsparametern som när den förklarand variabelns avstånd från sitt medelvärde ökar med ett, förändras y med parameterns värde. Däremot ser vi att parametern för polynomet är densamma samt att residualerna från modellen också är det.\nEn centrering av variabler för polynom ändrar alltså inte hur bra modellen är på att anpassa responsvariabeln men förenklar bakomliggande beräkningar och förändrar tolkningar av parameterskattningar.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Komplexa samband</span>"
    ]
  },
  {
    "objectID": "01-regression/06-complex-predictors.html#sec-exercises-complex",
    "href": "01-regression/06-complex-predictors.html#sec-exercises-complex",
    "title": "7  Komplexa samband",
    "section": "7.3 Övningsuppgifter",
    "text": "7.3 Övningsuppgifter\nI detta kapitel introduceras två datamaterial som kommer återkomma i efterföljande kapitel.\n\n7.3.1 Infektionsrisker vid sjukhus\nSENIC står för the Study on the Efficacy of Nosocomial Infection Control (Haley m.fl. 1980) och behandlar olika sätt att identifiera och kontrollera infektioner som uppstår på sjukhus. Datamaterialet består utav ett slumpmässigt urval om 113 sjukhus från de 338 undersökta. Materialet inkluderar följande variabler:\n\nID: Ett ID nummer för respektive sjukhus,\nLength_of_stay: Genomsnittligt antal dagar en patient stannar på sjukhuset,\nAge: Genomsnittlig ålder (år) på en patient,\nInfection_risk: Genomsnittlig uppskattad sannolikhet (i procent) att smittas av en infection på sjukhuset,\nRoutine_culturing_ratio: Kvoten mellan antalet odlingar som genomförts med antalet patienter utan symtom på infektion (multiplicerat med 100),\nRoutine_chest_X_ray_ratio: Kvoten mellan antalet röntgenbilder som genomförts med antalet patienter utan symtom på lunginflammation (multiplicerat med 100),\nNumber_of_beds: Genomsnittlig antal sjukhussängar (platser) vid sjukhuset under undersökningsperioden,\nMedical_school_affiliation: Ja/Nej om sjukhuset är kopplat till en läkarutbildning (1 = Ja, 2 = Nej),\nRegion: Sjukhusets geografiska område (1 = Nordost, 2 = Mellanvästern, 3 = Syd, 4 = Väst),2\nAverage_daily_census: Genomsnittligt antal patienter vid sjukhuset under undersökningsperioden,\nNumber_of_nurses: Genomsnittligt antal heltidsanställda licensierade sjuksköterskor under undersökningsperioden (antal heltids + 0.5 antal deltidsanställda),\nAvailable_facilties_and_services: Andel av 35 möjliga anläggningar och tjänster ett sjukhus kan erjbuda.\n\nDatamaterialet kan laddas ner här.\nEfter att ha laddat ner datamaterialet, skapa en designmatris med variablerna:\n\n\\(X_1 =\\) Length_of_stay\n\\(X_2 =\\) Age\n\\(X_3 =\\) Routine_chest_X_ray_ratio\n\\(X_4 =\\) Medical_shool_affiliation\n\nKoda \\(X_4\\) så att 1 betyder att sjukhuset är kopplat till en läkarutbildning och 0 annars.\n\nVisualisera de parvisa samband mellan de fyra förklarande variablerna och responsvariabeln. Är det något i dessa diagram som sticker ut som motiverar att en mer komplex modell behöver anpassas?\nAnpassa en regressionsmodell med infektionsrisken (Infection_risk) som responsvariabel och alla variablerna i designmatrisen ni skapat som förklarande variabler. Utvärdera modellen med hjälp av residualanalys och fokusera på att kontrollera antagandet om linjäritet.\nVissa forskare tror att det kan finnas en interaktion mellan variablerna \\(X_2\\) och \\(X_4\\) samt mellan \\(X_3\\) och \\(X_4\\) i relation till responsvariabeln. Utgå från modellen i b) och lägg till lämpliga interaktionstermer till designmatrisen för dessa två samband och anpassa en ny modell (med sex förklarande variabler).\n\nUtvärdera modellen med hjälp av residualanalys och jämför med diagrammen från b). Hur har modellen blivit bättre?\nTesta med ett test om interaktionstermerna kan uteslutas.\n\n\n\n\n7.3.2 Bostadsuthyrning\nDatamaterialet för denna övning innehåller en responsvariabel (\\(Y\\) = uthyrningskostnad i tusentals dollar) och fyra förklarande variabler:\n\n\\(X_1\\) = ålder (år),\n\\(X_2\\) = driftkostnad och skatt (tusentals dollar),\n\\(X_3\\) = vakansgrad (andel),\n\\(X_4\\) = yta (kvadratfot)\n\nDatamaterialet kan laddas ner här.\n\nVisualisera de parvisa samband mellan de fyra förklarande variablerna och responsvariabeln. Är det något i dessa diagram som sticker ut som motiverar att en mer komplex modell behöver anpassas?\nAnpassa en regressionsmodell där Y förklaras av \\(X_1\\), \\(X_2\\) och \\(X_4\\). Utvärdera modellen med hjälp av residualanalys och fokusera på att kontrollera antagandet om linjäritet.\nAnpassa två regressionsmodeller:\n\nModell 1: \\(Y\\) som responsvariabel och \\(X_1\\), \\(X_1^2\\), \\(X_2\\) och \\(X_4\\) som förklarande variabler.\nModell 2: Samma variabler som i modell 1, men \\(X_1\\) centreras: \\(X_{1,c} = X_1 - \\bar{X}_1\\) där \\(\\bar{X}_1\\) är medelvärdet för \\(X_1\\).\n\nTa fram parameterskattningarna för de båda modellerna och jämför koefficienterna för de icke-centrerade och centrerade variablerna.\nBeräkna korrelationsmatrisen för designmatrisen från de båda modellerna, avrundade till 2 decimaler. Undersök hur de två matriserna skiljer sig åt och fundera kring vilken effekt som centrering haft.\n\nFöljande uppgifter använder sig av modell 2.\n\nUtvärdera modellen med hjälp av residualanalys och jämför med diagrammen från b). Hur har modellen blivit bättre?\nSkatta medelvärdet av \\(Y\\) med ett 95-procentigt konfidensintervall för följande observation \\(\\{X_1 = 8, X_2 = 16, X4 = 250 000\\}\\). Tolka intervallet.3",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Komplexa samband</span>"
    ]
  },
  {
    "objectID": "01-regression/06-complex-predictors.html#referenser",
    "href": "01-regression/06-complex-predictors.html#referenser",
    "title": "7  Komplexa samband",
    "section": "Referenser",
    "text": "Referenser\n\n\n\n\nHaley, Robert, DANA QUADE, HOWARD FREEMAN, och JOHN BENNETT. 1980. ”The SENIC Project. Study on the efficacy of nosocomial infection control (SENIC Project). Summary of study design”. American journal of epidemiology 111 (juni): 472–85. https://doi.org/10.1093/oxfordjournals.aje.a112928.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Komplexa samband</span>"
    ]
  },
  {
    "objectID": "01-regression/06-complex-predictors.html#footnotes",
    "href": "01-regression/06-complex-predictors.html#footnotes",
    "title": "7  Komplexa samband",
    "section": "",
    "text": "Tänk på att temperatur har ett negativt samband som blir ett värde närmare 0 med interaktionen.↩︎\nSe Wikipedia för en beskrivning av dessa regioner↩︎\nNotera att modellen utgår från ett centrerad \\(X_1\\), vilket innebär att vi måste centrera den nya observationens värde innan prediktionen beräknas.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Komplexa samband</span>"
    ]
  },
  {
    "objectID": "01-regression/07-multicollinearity.html",
    "href": "01-regression/07-multicollinearity.html",
    "title": "8  Multikollinearitet",
    "section": "",
    "text": "8.1 Multikollinearitet\nI en multipel linjär regression behöver vi inte bara ta hänsyn till sambandet mellan de förklarande variablerna (X) och responsvariabeln (Y) utan vi behöver också ta hänsyn till sambandet mellan de förklarande variablerna. Detta kallas för multikollinearitet. Om det huvudsakliga syftet med en regressionsmodell är att beskriva sambandet mellan \\(\\mathbf{X}\\) och Y, och flera \\(X_j\\) beskriver samma sorts samband, kommer modellen fokusera på en av dessa och anse att de övriga variablerna inte har något samband. Modellen kan också överskatta variansen i parameterskattningen vilket i sin tur leder till icke-informativ inferens.\nTill viss del relaterar denna sorts samband till användandet av kontrollvariabler som diskuterades i Avsnitt 1.3.1 där vi inkluderade andra variabler för att den förklarande variabeln av intresse ska uppvisa dens korrekta samband med responsvariabeln. När vi inte använder oss av kontrollvariabler för att korrigera den huvudsakliga effekten av intresse, kommer samband mellan de förklarande variablerna orsaka stora problem både för modellanpassningen och tolkningar av modellen.\nVi kommer i detta kapitel använda datamaterialet trees som går att ladda in i R genom data(trees). I hjälpdokumentationen finns det information om vilka variabler som inkluderas i datamaterialet trees. Vi kan nå denna sida genom att köra koden ?trees. Under rubriken Format får vi information om att datamaterialet innehåller tre stycken variabler, Girth, Height och Volume. Dessa tre variabler beskriver olika mått på 31 stycken fällda körsbärsträd och att Girth egentligen beskriver trädets diameter (i tum/inches) ca 137 cm ovanför marken (4 ft 6 in). De övriga två variablerna mäter trädets höjd (i fot/feet) och trädets volym (i kubikfot/cubic feet).\nVi börjar med att undersöka de parvisa sambanden mellan de två förklarande variablerna, trädets höjd och diameter, och responsvariabeln, trädets volym.\nVisa kod\ntrees %&gt;% \n  pivot_longer(!Volume) %&gt;% \n  ggplot() + aes(x = value, y = Volume) + geom_point(color = \"steelblue\") + \n  facet_wrap(vars(name), scale = \"free\") + theme_bw() +\n  labs(x = \"Förklarande variabel\")\n\n\n\n\n\nSamband mellan förklarande variabler och responsvariabeln\nBåda variablerna verkar ha ett måttligt starkt, positivt, och linjärt samband, där diameterns samband verkar vara starkare än höjden. Vi kan då ställa upp modellen med båda förklarande variablerna enligt:\n\\[\n\\begin{aligned}\n  Y_i &= \\beta_0 + \\beta_1 \\cdot X_{i1} + \\beta_2 \\cdot X_{i2} + E_i\\\\\n\\\\\n&\\text{eller i matrisform}\\\\\n\\\\\n\\mathbf{Y} &= \\mathbf{X} \\boldsymbol{\\beta} + \\mathbf{E}\n\\end{aligned}\n\\]\ndär \\[\n\\begin{aligned}\n  \\mathbf{Y} = \\begin{bmatrix}Y_1\\\\Y_2\\\\\\vdots\\\\Y_{31}\\end{bmatrix} \\quad \\mathbf{X} = \\begin{bmatrix}1 & X_{1,1} & X_{1,2} \\\\1 & X_{2,1} & X_{2,2} \\\\\\vdots & \\vdots & \\vdots \\\\1 & X_{31,1} & X_{31,2} \\end{bmatrix} \\quad \\boldsymbol{\\beta} = \\begin{bmatrix}\\beta_0\\\\\\beta_1\\\\\\beta_2\\end{bmatrix} \\quad \\mathbf{E} = \\begin{bmatrix}E_1\\\\E_2\\\\\\vdots\\\\E_{31}\\end{bmatrix}\n\\end{aligned}\n\\] Vi anpassar modellen in R och kan se de skattade koefficienterna i följande tabell:\nVisa kod\nmodel &lt;- lm(formula = Volume ~ ., data = trees)\n\nsummary(model) %&gt;% \n  coef() %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\")) %&gt;% \n  kable_styling(\"striped\")\n\n\nAnpassad modell där volymen av ett träd förklaras av dess diameter\noch dess höjd\n \n  \n    Variabel \n    Skattning \n    Medelfel \n    t-värde \n    p-värde \n  \n \n\n  \n    (Intercept) \n    -57.988 \n    8.638 \n    -6.713 \n    0.000 \n  \n  \n    Girth \n    4.708 \n    0.264 \n    17.816 \n    0.000 \n  \n  \n    Height \n    0.339 \n    0.130 \n    2.607 \n    0.014\nANOVA-tabellen visar hur responsvariabelns variation fördelar sig på modellens olika förklarande variabler och den oförklarade variationen (felet). Vi kan plocka ut denna information från modellobjektet genom anova().\nVisa kod\nanova(model) %&gt;% \n  kable(col.names = c(\"Källa\", \"df\", \"SS\", \"MS\", \"F-värde\", \"p-värde\")) %&gt;% \n  kable_styling(\"striped\")\n\n\nAnpassad modell där volymen av ett träd förklaras av dess diameter\noch dess höjd\n \n  \n    Källa \n    df \n    SS \n    MS \n    F-värde \n    p-värde \n  \n \n\n  \n    Girth \n    1 \n    7581.7813 \n    7581.78133 \n    503.15034 \n    0.000000 \n  \n  \n    Height \n    1 \n    102.3812 \n    102.38118 \n    6.79433 \n    0.014491 \n  \n  \n    Residuals \n    28 \n    421.9214 \n    15.06862\nVi kan läsa av de sekventiella kvadratsummorna \\(SS(Girth)\\) och \\(SS(Height|Girth)\\), alltså hur mycket förklarande variation diametern bidrar med och hur mycket förklarande variation höjden bidrar med givet att diametern redan finns med i modellen. Vi kan också uttrycka det som att höjden bidrar med ca 102.4 ytterligare unik förklarad variation av responsvariabeln som diametern inte redan har förklarat, vilket relativt den totala variationen på ca 8000 inte är mycket trots det starka parvisa sambandet.\nEftersom tabellen visar sekventiella kvadratsummor kommer värdena påverkas av vilken ordning variablerna inkluderas i modellen. Låt oss byta ordning på de förklarande variablerna när vi anpassar modellen:\nVisa kod\nmodel &lt;- lm(formula = Volume ~ Height + Girth, data = trees)\n\nanova(model) %&gt;% \n  kable(col.names = c(\"Källa\", \"df\", \"SS\", \"MS\", \"F-värde\", \"p-värde\")) %&gt;% \n  kable_styling(\"striped\")\n\n\nAnpassad modell där volymen av ett träd förklaras av dess diameter\noch dess höjd, men annan ordning på variablerna\n \n  \n    Källa \n    df \n    SS \n    MS \n    F-värde \n    p-värde \n  \n \n\n  \n    Height \n    1 \n    2901.1889 \n    2901.18887 \n    192.5318 \n    0 \n  \n  \n    Girth \n    1 \n    4782.9736 \n    4782.97364 \n    317.4129 \n    0 \n  \n  \n    Residuals \n    28 \n    421.9214 \n    15.06862\nI denna tabell ser vi att \\(SS(Height) = 2901.2\\) vilket är betydligt högre än \\(SS(Height|Girth) = 102.4\\). När dessa två kvadratsummor är olika indikerar det att de förklarande variablerna förklarar samma sak/del av responsvariabeln, där diametern verkar vara den variabel som enskilt har mest unik information, \\(SS(Girth) = 7581.7813\\).\nVi ser också att p-värden för de olika F-testen förändras beroende på ordningen och det är självklart eftersom de undersöker olika modeller. Alla testen som genomförs är partiella F-test, eftersom vi testar enskilda parametrar och inte hela modellen, men den kompletta och reducerade modellen förändras i de två tabellerna.\nExempelvis, \\(SS(Height)\\) betyder att den kompletta modellen endast inkluderar höjden medan den reducerade modellen är en tom modell. \\(SS(Height|Girth)\\) betyder att den kompletta modellen inkluderar två variabler medan den reducerade modellen endast inkluderar diametern. Vi kan därför dra slutsatsen att, med en procents signifikansnivå vardera, höjden bidrar till att förklara volymen om det är den enda variabeln i modellen, men att höjden inte bidrar någon ytterligare information om diametern redan inkluderats.\nNågonting som är lika i de två tabellerna är \\(SSE\\). Detta gäller för att den additiva egenskapen för kvadratsummor delar upp den totala variationen (\\(SSY\\)) i den förklarade variationen (\\(SSR\\)) och den oförklarade variationen (\\(SSE\\)). Vi har i båda tabellerna tagit med samma variabler så den totala och förklarade variationen har inte förändrats. Vi kan matematiskt uttrycka det som: \\[\n\\begin{aligned}\n    SSR &= SS(Height) + SS(Girth|Height) \\\\\n    &= SS(Girth) + SS(Height|Girth)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multikollinearitet</span>"
    ]
  },
  {
    "objectID": "01-regression/07-multicollinearity.html#sec-multicollinearity",
    "href": "01-regression/07-multicollinearity.html#sec-multicollinearity",
    "title": "8  Multikollinearitet",
    "section": "",
    "text": "8.1.1 Variance Inflating Factors (VIF)\nI en multipel linjär regression kan en förklarande variabel enskilt, eller flera förklarande variabler tillsammans, beskriva en annan förklarande variabel och enkla parvisa korrelationer eller spridningsdiagram kan inte på ett lätt sätt identifiera detta. Istället kan vi undersöka de förklarande variablerna effekt med varandra med hjälp av variance inflating factors, härmed kallad för VIF.\n\n\n\n\n\n\nNotera\n\n\n\nNamnet VIF uppkommer på grund av att variansen för parameterskattningarna inflateras om flera förklarande variabler har starka samband med varandra.\n\\[\n\\begin{aligned}\n  \\sigma^2_{\\boldsymbol{\\hat{\\beta}}} = (\\mathbf{X}'\\mathbf{X})^{-1} \\sigma^2\n\\end{aligned}\n\\] I värsta fall är \\((\\mathbf{X}'\\mathbf{X})\\) singulär och kan inte inverteras, som leder till att vi kan inte beräkna variansen överhuvudtaget.\n\n\nVIF beräknas genom att mäta hur mycket en förklarande variabel förklaras av de övriga förklarande variablerna. Detta har vi ju ett mått på sedan tidigare i relation till regressionsmodellen, nämligen förklaringsgraden (Avsnitt 5.3), men istället för att modellera responsvariabeln skapas en regressionsmodell per förklarande variabel som beskrivs av de övriga variablerna förutom responsvariabeln.\nVIF beräknas enligt: \\[\n\\begin{aligned}\n  VIF_j = \\frac{1}{1-R^2_{j}}\n\\end{aligned}\n\\] där \\(j\\) är den j:te förklarande variabeln och \\(R^2_j\\) är förklaringsgraden från en regressionsmodell med \\(X_j\\) som responsvariabel. Eftersom en förklaringsgrad är begränsad mellan 0 och 1 kan vi visualisera vilka värden på VIF som skapas för olika nivåer av samband mellan de förklarande variablerna.\n\n\nVisa kod\ntibble(\n  R2 = seq(0, 1, by = 0.001),\n  VIF = 1 / (1 - R2)\n  ) %&gt;% \n  ggplot() + aes(x = R2, y = VIF) + geom_line(color = \"steelblue\", linewidth = 1) + \n  theme_bw() + labs(x = expression(R[j]^2)) + \n  scale_x_continuous(breaks = seq(0, 1, by = 0.1)) + \n  scale_y_continuous(breaks = seq(0, 100, by = 10), limits = c(0, 100)) +\n  geom_hline(yintercept = 5, color = \"#d9230f\", linetype = 2)\n\n\n\n\n\n\n\n\nFigur 8.1: VIF för olika förklaringsgrader, där VIF = 5 är markerad\n\n\n\n\n\nTolkningen av VIF är väldigt subjektivt men Figur 8.1 visar att VIF-värden kring 5 eller större motsvarar en förklaringsgrad på 75% eller större. När vi tolkar förklaringsgraden för en “vanlig” regressionsmodell är 75-80% där vi kan säga att modellen beskriver responsvariabeln bra, och vi kan använda samma värde även här, fast vi nu menar något negativt. Vi kan använda följande tumregler:\n\nnär VIF för en enskild variabel överskrider 10\nnär genomsnittliga VIF för alla variabler överskrider 5\n\nOm modellen uppvisar någon av dessa bör vi undersöka modellens förklarande variabler vidare då risken för problem med multikollinearitet är hög.\nFrån paketet car får vi en funktion (vif()) som beräknar VIF för varje förklarande variabel i en regressionsmodell.\n\n\nVisa kod\nrequire(car)\n\nvif(model) %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"VIF\")) %&gt;% \n  kable_styling(\"striped\", full_width = FALSE)\n\n\n\n \n  \n    Variabel \n    VIF \n  \n \n\n  \n    Height \n    1.369 \n  \n  \n    Girth \n    1.369 \n  \n\n\n\n\nFör modellen över trädens volym verkar inte VIF indikera på några risker med multikollinearitet då alla värden är &lt;5.\n\n\n8.1.2 Generaliserade VIF (GVIF)\nNär vi använder kvalitativa förklarande variabler kommer förklaringsgraden i beräkningen för VIF inte kunna använda en linjär regressionsmodell då indikatorvariabler som skapas från den variabeln inte längre är kontinuerliga. Detta specialfall löses genom att skapa generaliserade VIF som tar hänsyn till den binära variabelns struktur. Istället för att använda förklaringsgraden \\(R^2_j\\) beräknas effekten som de övriga förklarande variablerna har med \\(X_j\\) med hjälp av determinanter av korrelationsmatriser mellan olika förklarande variabler. (Fox och Monette 1992)\nVärden på GVIF kan tolkas på likt VIF, vi vill inte ha höga värden och tumregeln &lt;5 för genomsnittet eller &lt;10 för enskilda parametrar indikerar på en modell med låg risk för multikollinearitetsproblem.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multikollinearitet</span>"
    ]
  },
  {
    "objectID": "01-regression/07-multicollinearity.html#specialfall-med-polynom-och-interaktioner",
    "href": "01-regression/07-multicollinearity.html#specialfall-med-polynom-och-interaktioner",
    "title": "8  Multikollinearitet",
    "section": "8.2 Specialfall med polynom och interaktioner",
    "text": "8.2 Specialfall med polynom och interaktioner\nOm en modell inkluderar polynom eller interaktioner har vi artificiellt skapat ett samband mellan variabler och då kommer VIF, eller GVIF, vara högre än vad som vi förväntar. Multikollinearitet medför problem med tolkningar och inferens av enskilda parametrar men en modell innehållande polynom eller interaktioner har redan detta problem. Om en variabel förekommer i flera termer av modellen kan en enskild lutningsparameter inte tolkas och inferens för variabelns effekt mot responsvariabeln omfattar fler parametrar än bara grundvariabelns enskilda effekt. Därför bör tolkningar av VIF fokusera på de enskilda variablerna.\nVi kan titta närmare på Tabell 7.1 och Tabell 7.2 som exempel. I dessa två modeller har vi skapat en interaktion och polynom vilket innebär att vi har skapat variabler som har ett tydligt samband med de övriga.\n\n\nVisa kod\nvif(braModell) %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"VIF\")) %&gt;% \n  kable_styling(\"striped\", full_width = FALSE)\n\n\nVIF för modellens variabler inklusive interaktionen\n \n  \n    Variabel \n    VIF \n  \n \n\n  \n    x1 \n    1.004 \n  \n  \n    x2 \n    5.422 \n  \n  \n    x1:x2 \n    5.424 \n  \n\n\n\n\n\n\n\n\n\n\nViktigt\n\n\n\nvif() varnar faktiskt när vi beräknar VIF på en modell innehållande interaktioner just för att den identifierar att vi skapat variabler av en högre “ordning” och grundvariablerna förekommer på flera ställen i modellen. Vi kan med hjälp av argumentet vif(type = \"predictor\") beräkna GVIF som grupperar sambandet endast mellan grundvariablerna.\n\n\nVisa kod\ngvif &lt;- vif(braModell, type = \"predictor\") \n\ngvif %&gt;% \n  tibble() %&gt;% \n  select(1:3) %&gt;% \n  round(3) %&gt;% \n  mutate(Variabel = rownames(gvif)) %&gt;% \n  relocate(Variabel) %&gt;% \n  kable() %&gt;% \n  kable_styling(\"striped\", full_width = FALSE)\n\n\nGeneraliserade VIF beräknad per variabel istället för per term i\nmodellen\n \n  \n    Variabel \n    GVIF \n    Df \n    GVIF^(1/(2*Df)) \n  \n \n\n  \n    x1 \n    1 \n    3 \n    1 \n  \n  \n    x2 \n    1 \n    3 \n    1 \n  \n\n\n\n\n\n\nNär polynom introduceras till en modell är det endast en variabel som bidrar till sambandet till skillnad från två, eller fler, i en interaktion. På grund utav det starka beroende som då uppkommer är centrering ett måste om vi vill kunna bedöma enskilda parametrars bidrag till modellen. Vi kan i följande två tabeller se effekten av centrering på VIF\n\n\nVisa kod\nvif(model) %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"VIF\")) %&gt;% \n  kable_styling(\"striped\", full_width = FALSE)\n\n\nVIF för en modell med icke-centrerade polynom\n \n  \n    Variabel \n    VIF \n  \n \n\n  \n    X \n    5.228 \n  \n  \n    X2 \n    5.228 \n  \n\n\n\n\n\n\nVisa kod\nvif(centModel) %&gt;% \n  round(3) %&gt;% \n  kable(col.names = c(\"Variabel\", \"VIF\")) %&gt;% \n  kable_styling(\"striped\", full_width = FALSE)\n\n\nVIF för en modell med centrerade polynom\n \n  \n    Variabel \n    VIF \n  \n \n\n  \n    XCent \n    1.006 \n  \n  \n    X2Cent \n    1.006",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multikollinearitet</span>"
    ]
  },
  {
    "objectID": "01-regression/07-multicollinearity.html#övningsuppgifter",
    "href": "01-regression/07-multicollinearity.html#övningsuppgifter",
    "title": "8  Multikollinearitet",
    "section": "8.3 Övningsuppgifter",
    "text": "8.3 Övningsuppgifter\nVi kommer återigen använda SENIC data från Avsnitt 7.3.\n\nAnpassa en modell som förklarar infektionsrisken vid sjukhuset med hjälp av följande variabler:\n\n\\(X_1\\) = Length_of_stay\n\\(X_2\\) = Average_daily_census\n\\(X_3\\) = Number_of_beds\n\\(X_4\\) = Routine_chest_X_ray_ratio\n\n\n\nBeräkna en korrelationsmatris för de förklarande variablerna och identifiera de tre största parvisa korrelationerna.\nVisualisera de parvisa sambanden mellan de förklarande variablerna och bedöm om korrelationerna i 2. är missvisande eller ej.\nJämför de riktningen av de skattade koefficienterna i 1. och signifikansen av de enskilda testen med parvisa samband mellan respektive förklarande variabel och responsvariabeln. Jämför resultaten för respektive variabel. Visar de på samma sorts samband?\nBeräkna VIF för modellen och bedöm, tillsammans med informationen i tidigare uppgifter, vilka variabler som verkar bidra allra mest till en hög risk för multikollinearitetsproblem.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multikollinearitet</span>"
    ]
  },
  {
    "objectID": "01-regression/07-multicollinearity.html#referenser",
    "href": "01-regression/07-multicollinearity.html#referenser",
    "title": "8  Multikollinearitet",
    "section": "Referenser",
    "text": "Referenser\n\n\n\n\nFox, John, och Georges Monette. 1992. ”Generalized Collinearity Diagnostics”. Journal of the American Statistical Association 87 (417): 178–83. http://www.jstor.org/stable/2290467.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Multikollinearitet</span>"
    ]
  },
  {
    "objectID": "01-regression/08-detailed-residuals.html",
    "href": "01-regression/08-detailed-residuals.html",
    "title": "9  Detaljerad residualanalys",
    "section": "",
    "text": "9.1 Avvikande observationer\nI Avsnitt 4.1 presenterades sätt att med hjälp av residualer bedöma om en modell uppfyller antaganden för linjär regression genom olika enkla visualiseringar. Residualer kan också användas för att identifiera observationer som vi anser påverka modellanpassningen mer än övriga samt att identifiera avvikande observationer som bör undersökas vidare.\nI detta kapitel kommer vi behandla simulerade datamaterial. Vi simulerar först ett datamaterial med olika former av brus.\nSpridningsdiagrammet visar att båda sambanden ser ut att följa samma linjära positiva trend men punkterna i y1 ett starkare samband mellan x och y (mindre brus). Det finns inga tydliga indikationer på extremvärden då alla punkter i båda grupperna ser ut att följa sambandet väl.\nNästa steg i simuleringen är att lägga till extremvärden på två olika positioner, en närmare mittpunkten och en i utkanten av x:s värdemängd. Extremvärdet skapas med ett annorlunda värde på y än de övriga punkterna med liknande värden på x.\nSammanfattningsvis har vi fyra olika responsvariabler:\nEnkla residualer visar det absoluta avståndet mellan varje observation och dess punkt på den anpassade regressionslinjen, \\(\\hat{E}_i = Y_i - \\hat{Y}_i\\). Stora värden på residualerna kan indikera på att observationen ligger långt ifrån de övriga och med visualiseringar kan vi se om det endast är några enstaka observationer som har stora residualer eller om alla residualer generellt har stora värden. Det är främst i det första fallet som vi bör undersöka specifika observationer vidare då om alla residualer har stora värden är det främst en indikation på en sämre modell.\nAvvikande observationer kan direkt påverka modellanpassningen till den grad att sambandet som anpassas inte speglar det övergripande samband som modellen ämnar att beskriva. Men bara för att en residual har ett stort absolutvärde betyder det inte alltid att residualen är en indikation på en avvikande observation. Ett lättare sätt att bedöma detta är att beräkna standardiserade residualer som också tar hänsyn till residualernas totala spridning istället för det absoluta avståndet från linjen.\nLåt oss anpassa fyra olika modeller, en för vardera simulerade responsvariabel y1-y4.\n## Anpassar modellen som ska undersökas\nmodel1 &lt;- lm(y1 ~ x, data = data)\nmodel2 &lt;- lm(y2 ~ x, data = data)\nmodel3 &lt;- lm(y3 ~ x, data = data)\nmodel4 &lt;- lm(y4 ~ x, data = data)\nVisa kod\ndiagnosticPlots(model1)\n\n\n\n\n\nResidualdiagram för modell 1\nVi har ett värde vid \\(\\hat{y} \\approx 20\\) och \\(\\hat{E} \\approx 6\\) som har ett något större residualvärde än de övriga, men det är inte ett jättetydligt extremvärde.\nVisa kod\ndiagnosticPlots(model2)\n\n\n\n\n\nResidualdiagram för modell 2\nI denna modell verkar vi återigen ha en observation vars residual avviker något från de övriga. Vi har också en ökad osäkerhet både i residualerna (större absolutbelopp) vilket uppkommer då datamaterialet generellt visar på ett större brus.\nVisa kod\ndiagnosticPlots(model3)\n\n\n\n\n\nResidualdiagram för modell 3\nModell 3 har en extremt tydlig avvikande observation som påverkar modellanpassningen negativt om vi jämför med modell 1.\nVisa kod\ndiagnosticPlots(model4)\n\n\n\n\n\nResidualdiagram för modell 4\nNär den avvikande observationer finns i utkanten av x:s värdemängd ser vi ännu tydligare en residual i diagrammen.\nOm vi sammanställer en tabell för alla de fyra anpassade modellerna kan vi tydligare se effekten av hur olika sorters brus och extremvärden påverkar modellanpassningen.\nVisa kod\nmodelJämför &lt;- \n  tibble(\n    `Sann modell` = c(\"5\", \"5\", \"-\"),\n    `Lite brus` = c(model1$coefficients, summary(model1)$r.squared),\n    `Stort brus` = c(model2$coefficients, summary(model2)$r.squared),\n    `Avvikande nära mitt` = c(model3$coefficients, summary(model3)$r.squared),\n    `Avvikande i ytterkant` = c(model4$coefficients, summary(model4)$r.squared)\n  ) %&gt;% \n  as.data.frame()\n\nrownames(modelJämför) &lt;- c(\"$\\\\hat{\\\\beta}_0$\", \"$\\\\hat{\\\\beta}_1$\", \"$R^2$\")\n\nmodelJämför %&gt;% \n  kable(caption = \"Skattade koefficienter för alla modeller.\", digits = 3, escape = FALSE) \n\n\n\n\nTabell 9.1: Skattade koefficienter för alla modeller.\n\n\n\n\nSkattade koefficienter för alla modeller.\n\n\n\n\n\n\n\n\n\n\n\nSann modell\nLite brus\nStort brus\nAvvikande nära mitt\nAvvikande i ytterkant\n\n\n\n\n\\(\\hat{\\beta}_0\\)\n5\n6.460\n12.257\n6.655\n11.425\n\n\n\\(\\hat{\\beta}_1\\)\n5\n4.852\n4.216\n4.916\n4.192\n\n\n\\(R^2\\)\n-\n0.986\n0.694\n0.951\n0.750\nVisa kod\np1 &lt;- \n  data %&gt;% \n  ggplot() + aes(x = x, y = y1) + \n  geom_point(size = 1,  color = \"steelblue\") + \n  geom_smooth(formula = y~x, method = \"lm\", se = FALSE, color = \"steelblue\", linewidth = 1) + \n  geom_abline(intercept = 5, slope = 5, color = \"#d9230f\", linewidth = 1, linetype = 2) + \n  theme_bw()\n\np2 &lt;- \n  data %&gt;% \n  ggplot() + aes(x = x, y = y2) + \n  geom_point(size = 1,  color = \"steelblue\") + \n  geom_smooth(formula = y~x, method = \"lm\", se = FALSE, color = \"steelblue\", linewidth = 1) + \n  geom_abline(intercept = 5, slope = 5, color = \"#d9230f\", linewidth = 1, linetype = 2) + \n  theme_bw()\n\np3 &lt;- \n  data %&gt;% \n  ggplot() + aes(x = x, y = y3) + \n  geom_point(size = 1,  color = \"steelblue\") + \n  geom_smooth(formula = y~x, method = \"lm\", se = FALSE, color = \"steelblue\", linewidth = 1) + \n  geom_abline(intercept = 5, slope = 5, color = \"#d9230f\", linewidth = 1, linetype = 2) + \n  theme_bw()\n\np4 &lt;- \n  data %&gt;% \n  ggplot() + aes(x = x, y = y4) + \n  geom_point(size = 1,  color = \"steelblue\") + \n  geom_smooth(formula = y~x, method = \"lm\", se = FALSE, color = \"steelblue\", linewidth = 1) + \n  geom_abline(intercept = 5, slope = 5, color = \"#d9230f\", linewidth = 1, linetype = 2) + \n  theme_bw()\n\ncowplot::plot_grid(p1, p2, p3, p4, nrow = 2)\n\n\n\n\n\nDe fyra anpassade modellerna och den sanna regressionslinjen\nVi ser att modell 1 med litet brus (y1) faller ganska nära det sanna modellen, \\(y = 5 + 5 \\cdot x\\), och detsamma gäller modellen med den avvikande observationen nära mittpunkten av den förklarande variabeln (y3). Däremot verkar modellerna där det finns ett stort brus överlag (y2) och en avvikande observation i ytterkanten av den förklarande variabeln (y4) hamna längre ifrån den sanna modellen och ha en större grad av osäkerhet eftersom förklaringsgraden är närmare 70 procent jämfört med 95-99 procent.\nVad detta resultat visar oss är att en avvikande observation behöver inte alltid generera en påverkan på modellanpassningen i stort men modellen kommer inte lyckas anpassa just den observationen bra. Vi behöver titta närmare på residualerna för att korrekt identifiera ifall en avvikande observation faktiskt påverkar modellen.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detaljerad residualanalys</span>"
    ]
  },
  {
    "objectID": "01-regression/08-detailed-residuals.html#avvikande-observationer",
    "href": "01-regression/08-detailed-residuals.html#avvikande-observationer",
    "title": "9  Detaljerad residualanalys",
    "section": "",
    "text": "9.1.1 Standardiserade residualer\nStandardiserade residualer sätter residualernas absoluta värden i relation till den generella residualspridningen. En residual med stort absolutvärde i en modell med stor generell residualspridning är mindre avvikande än en residual med stort absolutvärde i en modell med liten generell residualspridning.\n\\[\n\\begin{aligned}\n  z_i = \\frac{e_i}{s_{e_i}}\n\\end{aligned}\n\\]\n\n\nVisa kod\n## Funktion för att beräkna standardiserade residualer\nstandardResid &lt;- function(model) {\n  \n  ## Residualerna dividerat med residualspridningen\n  z &lt;- model$residuals / summary(model)$sigma\n  \n  return(z)\n}\n\n\n# Beräknar standardiserade residualer\nresidualData &lt;- \n  tibble(\n    `Lite brus` = standardResid(model1),\n    `Stort brus` = standardResid(model2),\n    `Avvikande nära mitt` = standardResid(model3),\n    `Avvikande i ytterkant` = standardResid(model4)\n  ) %&gt;% \n  mutate(\n    index = 1:n()\n  ) %&gt;% \n  as.data.frame()\n  \nresidualData %&gt;% \n  ## \"Roterar\" datamaterialet för att förenkla visualiseringar\n  pivot_longer(\n    cols = -index,\n    names_to = \"Data\",\n    values_to = \"resid\"\n  ) %&gt;% \n  mutate(\n    ## Konverterar grupperingsvariabeln till en factor med en angiven ordning på nivåerna\n    Data = factor(Data, levels = c(\"Lite brus\", \"Stort brus\", \"Avvikande nära mitt\", \"Avvikande i ytterkant\"))\n  ) %&gt;% \n  ggplot() + aes(x = index, y = resid) + \n  geom_point(size = 2, color = \"steelblue\") + theme_bw() + \n  facet_wrap(~Data, nrow = 2, ncol = 2) + \n  labs(y = \"Standard. residualer\")\n\n\n\n\n\nStandardiserade residualer för de olika modellerna.\n\n\n\n\nI figuren visas de standardiserade residualerna för respektive modell och här syns det tydligt vilka residualer som faktiskt är en avvikande observation och vilka som ändå ligger inom residualernas generella spridning. Det är främst i modellerna med extremvärden som de standardiserade residualerna uppvisar tydliga indikationer att dessa observationer är avvikande.\n\n\n9.1.2 Avvikande observationer i X\nI Tabell 9.1 såg vi att avvikande observationer i utkanten av X:s värdemängd verkar ha en större påverkan på modellanpassningen än avvikande observationer närmare mittpunkten av värdemängden. I en multipel linjär regressionsmodell kan denna jämförelse bli svår att genomföra med visualiseringar eller jämförelser mellan flera skattade lutningsparametrar. Istället kan leverage beräknas som visar hur långt bort den enskilda observationen (residualen) är från genomsnittet av alla förklarande variabler.\nLeverage beräknas utifrån hattmatrisen, \\(\\mathbf{H} = \\mathbf{X}(\\mathbf{X}'\\mathbf{X})^{-1}\\mathbf{X}'\\), specifikt diagonalelementen av matrisen. \\(h_i\\) är det i:te diagonalelementet från matrisen vars värden kan falla mellan 0 och 1, där 1 indikerar på stort avstånd från genomsnittet. Vi kan beräkna hattmatrisen i R med hjälp av matrisalgebra eller med hjälp av funktionen lm.influence() där objektet hat innehåller diagonalen av hattmatrisen.\n\n\nVisa kod\n## Skapar designmatrisen\nX &lt;- \n  model.matrix(y ~ x, data = data)\n\n## Beräknar hattmatrisen\nH &lt;- X %*% solve(t(X) %*% X) %*% t(X)\n\n## Plockar ut leverage\nleverage &lt;- diag(H)\n\n## Funktion för att plocka ut leverage\nleverage &lt;- lm.influence(model1)$hat\n\n\nI alla de fyra modellerna använder vi samma värden på den förklarande variabeln, så vi behöver endast skapa en visualisering som gäller för alla modeller.\n\n\nVisa kod\n## Skapar data för visualisering\nvisData &lt;- \n  tibble(\n    leverage = leverage\n  ) %&gt;% \n  mutate(\n    index = 1:n()\n  )\n\n## Visualiserar leverage\nggplot(visData) + aes(x = index, y = leverage) + \n  geom_point(size = 2, color = \"steelblue\") + \n  theme_bw() + \n  ## Anger en skala som går mellan 0 och 1 (möjliga värden av h)\n  scale_y_continuous(\n    limits = c(0, 1)\n  ) + \n  ## Skapar gränsvärdet för observationer som har för \"höga\" leverage och bör undersökas vidare\n  geom_hline(\n    yintercept = 2 * ncol(X) / nrow(X),\n    color = \"#d9230f\",\n    linewidth = 1,\n    linetype = 2\n  ) +\n  labs(x = \"Obs. index\", y = \"Leverage\")\n\n\n\n\n\nLeverage-värden för respektive observation\n\n\n\n\nDen rödstreckade linjen beskriver en tumregel som ger oss lite hjälp på traven att bedöma ifall en residual har ett “högt” leverage värde eller inte. Tumregeln beräknas som: \\[\n\\begin{aligned}\n  \\frac{2\\cdot (k+1)}{n} = \\frac{2 \\cdot p}{n}\n\\end{aligned}\n\\] Det finns två observationer, \\(i = 11\\) och \\(i = 24\\), som har leverage-värden som anses vara högre än tumregeln. Dessa två observationer är de som har minst värden på x, alltså de som ligger längst till vänster i Figur 9.1. Eftersom dessa punkter verkar följa det linjära samband som resten av punktsvärmen visar, finns det ingenting som tyder på att de är några observationer vi behöver oroa oss för.\n\n\n9.1.3 Jackknife-residualer\nEtt ytterligare sätt att använda leverage för att identifiera avvikande observationer är att beräkna Jackknife-residualer. Denna typ av residual beräknas genom att anpassa en modell utan observation \\(i\\) som sedan används för att skatta prediktera värdet på responsvariabeln och beräkna residualen. Eftersom en avvikande observation kan påverka modellanpassningen riskerar en vanlig eller standardiserad residual att underskatta avvikelsen då modellen dras mot den avvikande observationen. När en modell anpassas som inte inkluderar den specifika observationen kommer residualen ge en mer verklig bild av observationens faktiska avvikelse från det generella sambandet.\nIstället för att behöva anpassa n olika modeller där varje respektive observation plockas bort kan vi använda leverage och modellens SSE enligt:\n\\[\n\\begin{aligned}\n    r_{(-i)} = \\frac{e_i \\cdot \\sqrt{n - (k + 2)}}{SSE \\cdot (1 - h_i) - e_i^2}\n\\end{aligned}\n\\] Vi kan skapa denna funktion i R genom följande kod:\n\n\nVisa kod\n## Skapar en funktion som beräknar jackknife-residualer från en angiven modell\njackknife &lt;- function(model) {\n  \n  # Sparar modellens residualer och leverage\n  residuals &lt;- model$residuals\n  \n  leverage &lt;- lm.influence(model)$hat\n  \n  # Antal observationer\n  n &lt;- nrow(model$model)\n  \n  # Antal förklarande variabler (-1 för att ta hänsyn till y)\n  k &lt;- ncol(model$model) - 1\n  \n  # Sparar modellens kvadratsumma för felet\n  SSE &lt;- sum(residuals^2)\n  \n  # Beräknar jackknife residualen\n  jackknife &lt;- residuals * sqrt((n - k - 2) / (SSE * (1 - leverage) - residuals^2))\n  \n  return(jackknife)\n}\n\n\n\n\nVisa kod\nresidualData &lt;- \n  tibble(\n    `Lite brus` = jackknife(model1),\n    `Stort brus` = jackknife(model2),\n    `Avvikande nära mitt` = jackknife(model3),\n    `Avvikande i ytterkant` = jackknife(model4)\n  ) %&gt;% \n  mutate(\n    index = 1:n()\n  ) %&gt;% \n  as.data.frame()\n  \nresidualData %&gt;% \n  ## \"Roterar\" datamaterialet för att förenkla visualiseringar\n  pivot_longer(\n    cols = -index,\n    names_to = \"Data\",\n    values_to = \"resid\"\n  ) %&gt;% \n  mutate(\n    Data = factor(Data, levels = c(\"Lite brus\", \"Stort brus\", \"Avvikande nära mitt\", \"Avvikande i ytterkant\"))\n  ) %&gt;% \n  ggplot() + aes(x = index, y = resid) + \n  geom_point(size = 2, color = \"steelblue\") + theme_bw() + \n  facet_wrap(~Data, nrow = 2, ncol = 2) + \n  labs(y = \"Jackknife-residualer\")\n\n\n\n\n\n\n\n\nFigur 9.2: Jackknife residualer för de olika modellerna.\n\n\n\n\n\nMed hjälp av Jackknife-residualerna ser vi att de observationer med höga leverage-värden inte påverkar modellanpassningen då värdena är i linje med alla andra observationers värden. Däremot syns ett värde var i de två nedersta diagrammen som tydligt indikerar på de extremvärden som vi placerat in avviker från det generella sambandet, vilket vi också förväntar oss.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detaljerad residualanalys</span>"
    ]
  },
  {
    "objectID": "01-regression/08-detailed-residuals.html#inflytelserika-observationer",
    "href": "01-regression/08-detailed-residuals.html#inflytelserika-observationer",
    "title": "9  Detaljerad residualanalys",
    "section": "9.2 Inflytelserika observationer",
    "text": "9.2 Inflytelserika observationer\nTill viss del beskriver Jackknife-residualer huruvida en observation har ett inflytande på modellanpassningen genom att beräkna en mer rättvis avvikelse för varje observation från det generella sambandet. Däremot såg vi i Figur 9.2 att extremvärdet nära mittpunkten av X också fått ett relativt högt värde trots att vi i Tabell 9.1 inte såg att den observationen hade en påverkan på modellanpassningen. Dessa residualer är alltså inte alltid så bra att identifiera observationens effekt på modellanpassningen, mer än att de identifierar avvikande observationer. Istället kan vi använda andra mått såsom DFFITS och Cook’s Distance för att avgöra om en observation påverkar modellanpassningen och anses vara en inflytelserik observation.\n\n9.2.1 DFFITS\nVi kan mäta en observations inflytande på två olika sätt, antingen på sitt egna anpassade värde eller på alla anpassade värden. DFFITS undersöker om en observation har ett inflytande på sitt egna anpassat värde och använder sig utav Jackknife-residualerna som vi beräknade tidigare.\n\\[\n\\begin{aligned}\n  {DFFITS}_i = r_{(-i)} \\cdot \\sqrt{ \\frac{h_i}{1 - h_i}}\n\\end{aligned}\n\\]\n\n\nVisa kod\n## Funktion för att beräkna dffits\ndffits &lt;- function(model) {\n  \n  # Hämtar Jackknife-residualerna\n  jackknife &lt;- jackknife(model)\n  \n  # Sparar leverage\n  leverage &lt;- lm.influence(model)$hat\n  \n  # Beräknar DFFITS\n  dffits &lt;- jackknife * sqrt(leverage / (1 - leverage))\n  \n  return(dffits)\n  \n}\n\n\nGränsvärden för när vi anser ha identifierat en inflytelserik observation med DFFITS beräknas utifrån storleken på datamaterialet, där små till medelstora material har gränsvärdet 1 (heldragen linje i figuren nedan) eller \\(2\\cdot \\sqrt{\\frac{p}{n}}\\) för stora datamaterial (streckad linje).\n\n\nVisa kod\nresidualData &lt;- \n  tibble(\n    `Lite brus` = dffits(model1),\n    `Stort brus` = dffits(model2),\n    `Avvikande nära mitt` = dffits(model3),\n    `Avvikande i ytterkant` = dffits(model4)\n  ) %&gt;% \n  mutate(\n    index = 1:n()\n  ) %&gt;% \n  as.data.frame()\n  \nresidualData %&gt;% \n  ## \"Roterar\" datamaterialet för att förenkla visualiseringar\n  pivot_longer(\n    cols = -index,\n    names_to = \"Data\",\n    values_to = \"resid\"\n  ) %&gt;% \n  mutate(\n    Data = factor(Data, levels = c(\"Lite brus\", \"Stort brus\", \"Avvikande nära mitt\", \"Avvikande i ytterkant\"))\n  ) %&gt;% \n  ggplot() + aes(x = index, y = abs(resid)) + \n  geom_point(size = 2, color = \"steelblue\") + theme_bw() + \n  facet_wrap(~Data, nrow = 2, ncol = 2, scale = \"free_y\") + \n  labs(y = \"DFFITS\") + \n  geom_hline(\n    yintercept = 1,\n    linewidth = 1,\n    linetype = 1,\n    color = \"#d9230f\"\n  ) + \n  geom_hline(\n    yintercept = 2*sqrt(ncol(X) / nrow(X)),\n    linewidth = 1,\n    linetype = 2,\n    color = \"#d9230f\"\n  )\n\n\n\n\n\nAbsolutbelopp för DFFITS från de olika modellerna.\n\n\n\n\nVårt simulerade data kan anses vara litet (\\(n = 31\\)) och vi kan därför använda värdet 1 som gräns. Vi ser att observation 11 anses inflytelserik i modellerna utan extremvärden men att den inte anses det när vi lagt till en tydligt avvikande observation som istället tagit över allt inflytande.\n\n\n9.2.2 Cook’s Distance\nDet är nästan självklart att en avvikande observation kommer påverka sitt egna anpassade värde. Det som vi oftast är intresserad av att undersöka är ifall en avvikande observation ger oss en felaktig modellanpassning för det generella sambandet, alltså om andra observationers anpassning påverkas. Måttet Cook’s Distance visar hur mycket inflytande en observation har på alla anpassade värden.\nBeroende på vilka sorters residualer vi har tillhanda kan vi beräkna Cook’s Distance på två olika sätt. Studentiserade residualer kan delas upp i interna studentiserade och externa studentiserade. Den internt studentiserade residualen (angivet som \\(r_i\\) i Kleinbaum m.fl. (2013)) är en form av standardisering där vi också tar hänsyn till observationens leverage-värde inte bara residualspridningen.\n\\[\n\\begin{aligned}\n    r_i = \\frac{e_i}{\\sqrt{MSE \\cdot (1 - h_i)}} = \\frac{e_i}{s_{e_i} \\cdot \\sqrt{(1 - h_i)}}\n\\end{aligned}\n\\] Med hjälp av de internt studentiserade residualerna kan vi beräkna Cook’s Distance enligt: \\[\n\\begin{aligned}\n  d_i = \\left( \\frac{1}{k + 1} \\right) \\cdot \\left( \\frac{h_i}{1 - h_i}\\right)\\cdot r_i^2\n\\end{aligned}\n\\]\nExternt studentiserade residualer (det som funktionerna stats::rstudent() och MASS::studres() kallar enbart studentiserade residualer) standardiserar residualen baserat på en modell som saknar observation \\(i\\), vilket överensstämmer med definitionen av Jackkniferesidualer från Kleinbaum m.fl. (2013). I själva verket är det Jackknife residualerna som R använder sig utav i sina beräkningar av Cook’s Distance i cooks.distance() men vi kan få samma resultat genom att använda de (internt) studentiserade residualerna istället:\n\n\nVisa kod\n## Funktion för att beräkna Cook's Distance\ncooks &lt;- function(model) {\n  \n  # Sparar residualerna\n  residuals &lt;- model$residuals\n  \n  # Sparar residualspridningen\n  s &lt;- summary(model)$sigma\n  \n  # Sparar leverage\n  leverage &lt;- lm.influence(model)$hat\n  \n  # Sparar antalet variabler (-1 för att inte räkna y)\n  k &lt;- ncol(model$model) - 1\n  \n  # Beräknar studentiserade residualer\n  studentized &lt;- residuals / (s * sqrt(1 - leverage))\n  \n  # Beräknar Cook's Distance\n  cooks &lt;- (1 / (k + 1)) * (leverage / (1 - leverage)) * studentized^2 \n  \n  return(cooks)\n  \n}\n\n\nGränsvärdet för vad som anses vara en inflytelserik observation kan dras vid 1 (den heldragna linjen i figurerna nedan), men det finns också mer robusta gränsvärden (den streckade linjen) som har plockats fram av Muller och Mok (1997) som används likt kritiska värden i hypotesprövningar.1\n\n\nVisa kod\nresidualData &lt;- \n  tibble(\n    `Lite brus` = cooks(model1),\n    `Stort brus` = cooks(model2),\n    `Avvikande nära mitt` = cooks(model3),\n    `Avvikande i ytterkant` = cooks(model4)\n  ) %&gt;% \n  mutate(\n    index = 1:n()\n  ) %&gt;% \n  as.data.frame()\n  \nresidualData %&gt;% \n  ## \"Roterar\" datamaterialet för att förenkla visualiseringar\n  pivot_longer(\n    cols = -index,\n    names_to = \"Data\",\n    values_to = \"resid\"\n  ) %&gt;% \n  mutate(\n    Data = factor(Data, levels = c(\"Lite brus\", \"Stort brus\", \"Avvikande nära mitt\", \"Avvikande i ytterkant\"))\n  ) %&gt;% \n  ggplot() + aes(x = index, y = resid) + \n  geom_point(size = 2, color = \"steelblue\") + theme_bw() + \n  facet_wrap(~Data, nrow = 2, ncol = 2) + \n  labs(y = \"Cook's Distance\") + \n  geom_hline(\n    yintercept = 1,\n    linewidth = 1,\n    linetype = 1,\n    color = \"#d9230f\"\n  ) + \n  geom_hline(\n    # Gränsvärde enligt tabell A.10 i Kleinbaum där 17.18 hittas vid k = 1, n = 25 (närmast n = 31) och alpha = 0.05\n    # 29 är n - (k + 1)\n    yintercept = 17.18/29,\n    linewidth = 1,\n    linetype = 2,\n    color = \"#d9230f\"\n  )\n\n\n\n\n\nCook’s Distance för de olika modellerna.\n\n\n\n\nOm vi använder gränsvärdet 1, är det bara den tydligt avvikande observationen i ytterkanten på x:s värdemängd som anses vara inflytelserik. Om vi istället använder den mer robusta gränsen pekar det på att de små värden i det brusiga data utan tillagda extremvärden anses vara inflytelserika. Sedan tidigare har vi identifierat att observation 11 är en utav de observationer med minst värde på x vilket innebär att den också ligger i ytterkanten av värdemängden. Vad detta resultat då antyder är att en observation med högt leverage, avvikande långt bort från mittpunkten av X, eller en observation med en väldigt stor avvikelse i Y, kommer påverka modellanpassningen utöver sitt egna värde.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detaljerad residualanalys</span>"
    ]
  },
  {
    "objectID": "01-regression/08-detailed-residuals.html#övningsuppgifter",
    "href": "01-regression/08-detailed-residuals.html#övningsuppgifter",
    "title": "9  Detaljerad residualanalys",
    "section": "9.3 Övningsuppgifter",
    "text": "9.3 Övningsuppgifter\nAnvänd SENIC data som presenterades första gången i Avsnitt 7.3.\n\nAnpassa en modell som beskriver infektionsrisken med alla variabler förutom ID. Utvärdera den och kontrollera modellens antaganden på ett lämpligt sätt.\nBeräkna leverage och visualisera måtten i observationsordning. Beräkna och visa gränsvärdet i visualiseringen. Är det någon observation som identifieras som avvikande?\nBeräkna DFFITS och Cook’s Distance och visualisera måtten i observationsordning. Beräkna och visa respektive gränsvärde i visualiseringen. Är det någon observation som identifieras som inflytelserik för sitt egna anpassade värde? För modellen i sin helhet?\nSammanställ en tabell med alla de observationer som identifierades i b) och c) och markera vilka som är avvikande och/eller inflytelserika (kolumner med TRUE/FALSE). Motivera potentiella orsaker till att de anses påverka modellanpassningen.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detaljerad residualanalys</span>"
    ]
  },
  {
    "objectID": "01-regression/08-detailed-residuals.html#referenser",
    "href": "01-regression/08-detailed-residuals.html#referenser",
    "title": "9  Detaljerad residualanalys",
    "section": "Referenser",
    "text": "Referenser\n\n\n\n\nKleinbaum, D. G., L. L. Kupper, A. Nizam, och E. S. Rosenberg. 2013. Applied Regression Analysis and Other Multivariable Methods. Cengage Learning. https://books.google.se/books?id=v590AgAAQBAJ.\n\n\nMuller, Keith, och Mario Mok. 1997. ”The distribution of Cook’s D statistic”. Communications in statistics: theory and methods 26 (januari). https://doi.org/10.1080/03610927708831932.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detaljerad residualanalys</span>"
    ]
  },
  {
    "objectID": "01-regression/08-detailed-residuals.html#footnotes",
    "href": "01-regression/08-detailed-residuals.html#footnotes",
    "title": "9  Detaljerad residualanalys",
    "section": "",
    "text": "Tabell A.10 i Kleinbaum m.fl. (2013) innehåller de kritiska värdena som måste divideras med \\(n - (k + 1)\\) för att jämföras med våra beräknade värden på \\(d_i\\).↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Detaljerad residualanalys</span>"
    ]
  },
  {
    "objectID": "01-regression/09-variable-selection.html",
    "href": "01-regression/09-variable-selection.html",
    "title": "10  Modellvalidering och variabelselektion",
    "section": "",
    "text": "10.1 Modellvalidering\nOm ett datamaterial innehåller ett stort antal variabler finns det mängder med potentiella modeller av olika storlek som skulle kunna anpassas. Vi har i tidigare kapitel enbart fokuserat på enstaka modeller som baserat sin struktur utifrån ledtrådar som identifierats i det utforskande steget, men detta blir snabbt tidskrävande vid 10, 20, eller 50 förklarande variabler.\nFör att effektivisera processen med att hitta en lämplig modell behöver vi dels tydliga instruktioner för hur vi ska gå till väga för att utveckla/förbättra modellerna och olika sätt att kunna utvärdera modellerna i olika aspekter. Vi kommer i detta kapitel presentera olika variabelselektionsalgoritmer och introducera ytterligare mått som vi kan använda för att utvärdera en modell.\nEn bra regressionsmodell beskriver inte bara det stickprov som vi använt för att anpassa modellen utan kan också anpassa ny liknande data så bra som möjligt. “Så bra som möjligt” betyder i praktiken att vi vill ha säkra prediktioner för ny data, i fall där vi endast har de förklarande variablernas värden att utgå från. Till exempel skulle vi kunna ha anpassat en modell där responsvariabeln är dyr eller svår att mäta (identifiera elakartade tumörer) men de förklarande variablerna är enklare att samla in (andra medicinska mätningar såsom blodvärden etc.).\nEftersom vi inte har tillgång till all potentiell ny och okänd data behöver vi metoder för att utvärdera vår nuvarande modell givet den data vi har. Detta kallas för validering och kan delas upp i två olika sätt att validera modellens generaliserbarhet, det vill säga hur bra modellen är på att beskriva ny liknande data.\nIntern validering är mått som beskriver modellen på det data som används för modellanpassningen. Ofta baseras valideringen på något enkelt anpassningsmått, till exempel SSE, eller något mått som också straffar modellen för dess komplexitet, till exempel den justerade förklaringsgraden. Eftersom vi tittar på modeller av olika storlek är det vanligtvis lämpligare att använda mått som tar hänsyn till modellens komplexitet för att jämförelsen ska bli rättvis. I linjära modeller mäts komplexiteten av antalet förklarande variabler, ju fler variabler desto mer komplex är modellen, och valideringen blir då en avvägning mellan en bra modellanpassning och en lagom komplex modell.\nIntern validering beskriver endast modellens anpassning på det insamlade datamaterialet och undersöker inte hur modellen skulle prestera på ny information. Fördelen med intern validering är att den är enkel att använda, vi har faktiskt redan gjort detta i tidigare kapitel, men endast vissa av dessa mått kan användas för att dra slutsatser om hur bra modellen är på att generalisera sambandet, däribland AIC som beskrivs i Avsnitt 10.2.1.\nI extern validering utvärderar vi den anpassade modellen på ny okänd data som vi själva skapar genom att exempelvis slumpmässigt ta bort en del av observationerna i det insamlade materialet. Denna uppdelning av data medför att vi betecknar data som vi anpassar (tränar) modellen på för träningsmängd och data som vi utvärderar modellen på för validerings- eller testmängd beroende på vad syftet med utvärderingen är.\nEn valideringsmängd används för att jämföra modeller med varandra och undersöka vilken som är bäst på att generalisera sambandet medan en testmängd används för att få en väntevärdesriktig skattning på något mått i den slutgiltigt valda modellen.1\nFördelen med extern validering är att vi kan få mer information om modellens generaliserbarhet men det kräver att vi också har ny och okänd data att undersöka modellen på. Om vi har tillgång till tillräckligt många observationer i vårt stickprov och kan dela upp materialet i lagom stora mängder eller om vi under modellanpassningen också samlat in ny data, har vi tillfällen där extern validering kan användas.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modellvalidering och variabelselektion</span>"
    ]
  },
  {
    "objectID": "01-regression/09-variable-selection.html#modellvalidering",
    "href": "01-regression/09-variable-selection.html#modellvalidering",
    "title": "10  Modellvalidering och variabelselektion",
    "section": "",
    "text": "10.1.1 Generaliserbarhet\nEn modell som anses lämplig och innehåller variabler som alla verkar ha en signifikant påverkan på responsvariabeln, och på alla sätt och vis kan anses en bra modell för det urval vi har samlat in, behöver inte nödvändigtvis vara en modell som kan prestera lika bra på ny liknande data. Vi kan råka ut för både underanpassning (underfitting) eller överanpassning (overfitting), där den senare av de två är mest vanligt förekommande.\n\nUnderanpassning betyder att modellen är för enkel och inte fångar upp relevanta samband mellan responsvariablen och de förklarande variablerna, exempelvis att vi modellerar ett tredjegradspolynom med en linjär funktion.\nÖveranpassning betyder att modellen är för komplex eller avancerad och då börjar modellen att beskriva bruset som finns i data, vilket gör att generaliserbarheten minskar, exempelvis att vi modellerar ett tredjegradspolynom med ett sjättegradspolynom.\n\n\nNär fokus är att undersöka generaliserbarheten används extern validering där det är vanligt att vi slumpmässigt delar upp data i en träningsmängd och en valideringsmängd och förutsätter att vi har oberoende observationer i vårt data. Om vi inte har ett oberoende observationer kommer en slumpmässig uppdelning inte behålla det beroende som modellen ska försöka hantera och vi behöver istället använda speciella metoder för att skapa valideringdata, till exempel att i tidseriedata dela upp serien i två delar vid en viss tidpunkt.\nOfta väljer vi att träningsmängden ska innehålla minst 50% av alla observationer för att modellen som anpassas ska få hjälp av den största majoriteten av informationen. Valideringsmängden brukar få det som “blir över” men bör minst bestå av 10% av alla observationer för att också kunna ha nog mycket information att genomföra någon vettig validering. Det finns ingen “rätt andel” storlek på valideringsmängden som passar alla situationer utan vi styrs ofta utav antalet observationer. Har vi ett stort antal obsevationer brukar vi låta valideringsdata utgöra en mindre andel eftersom vi fortfarande får möjlighet att validera modellerna på många observationer.\nFör att skapa en slumpmässig uppdelning av data i R kan vi antingen använda oss utav slumpmässiga index eller randomisering för att dela upp observationerna.\n\n# Antalet observationer totalt\nn &lt;- nrow(penguins)\n\n# Antalet som tilldelas till träningsmängden utifrån en andel på 2/3\nnTrain &lt;- n*(2/3) \n\n# Sätter ett seed för reproducerbarhet\nset.seed(355)\n\n# Index (utvalda observationer) till träningsmängden\nindexTrain &lt;- sample(x = n, size = nTrain, replace = FALSE)\n\n# Plockar ut utvalda observationer från materialet med positiv \n# indexering (lägger till) för träning och negativ indexering \n# (tar bort) för validering\ndataTrain &lt;- penguins[indexTrain,]\ndataValid &lt;- penguins[-indexTrain,]\n\nVi kan också med hjälp av dplyr funktioner dela upp materialet:\n\n\nVisa kod\nlistaMedMängder &lt;- \n  penguins %&gt;% \n  # Skapar en variabel med 1/0 som indikerar på träningsmängden med 2/3\n  mutate(\n    split = rbinom(n = n(), size = 1, prob = 2/3)\n  ) %&gt;% \n  # Grupperar och delar upp materialet utefter denna nya variabel\n  group_by(split) %&gt;% \n  group_split()\n\n# Plockar ut de olika listorna till separata objekt\ndataTrain &lt;- listaMedMängder[[2]]\ndataValid &lt;- listaMedMängder[[1]]\n\n\nEfter att data är uppdelat kan vi anpassa ett antal modeller och jämföra utvärderingsmått mellan tränings- och valideringsmängden.\n\n\nVisa kod\nmodel1 &lt;- lm(bill_length_mm ~ species + bill_depth_mm + flipper_length_mm + body_mass_g + sex, \n             data =  dataTrain)\n\nmodel2 &lt;- lm(bill_length_mm ~ species + bill_depth_mm + sex, \n             data = dataTrain)\n\nmodel3 &lt;- lm(bill_length_mm ~ species * bill_depth_mm, \n             data = dataTrain)\n\n# Förklaringsgraden för modellerna anpassade på träningsmängden\ntibble(\n  Modell = c(1:3),\n  `$R^2_{adj}$` = c(summary(model1)$adj.r.squared,\n                    summary(model2)$adj.r.squared,\n                    summary(model3)$adj.r.squared),\n  MSE = c(summary(model1)$sigma^2,\n          summary(model2)$sigma^2,\n          summary(model3)$sigma^2)\n) %&gt;% \n  kable(digits = 3, escape = FALSE)\n\n\n\n\nTabell 10.1: Enkla utvärderingsmått för jämförelse av de tre anpassade modellerna på träningsdata\n\n\n\n\n\n\nModell\n\\(R^2_{adj}\\)\nMSE\n\n\n\n\n1\n0.843\n4.472\n\n\n2\n0.829\n4.869\n\n\n3\n0.798\n5.760\n\n\n\n\n\n\n\n\nTabell 10.1 visar att den första modellen har störst justerad förklaringsgrad och lägst MSE vilket motiverar att den modellen preseterar bäst på träningsmängden. När vi sedan ska utvärdera modellen på valideringsmängden kan vi till viss del använda samma enkla mått men vi behöver ta hänsyn till att modellen som anpassats inte har sett den nya datan. MSE:s motsvarighet för ny data är MSPR (Mean Squared Prediction Error) som beskriver det genomsnittliga felet som modellen gör på ny data.\n\\[\n\\begin{aligned}\n  MSPR = \\frac{\\sum_{i^*}{(Y_{i^*} - \\hat{Y}_{i^*})^2}}{n^*}\n\\end{aligned}\n\\] där \\(i^*\\) är observation \\(i\\) i valideringsmängden och \\(n^*\\) är antalet observationer totalt i valideringsmängden.\n\n\nVisa kod\n# Prediktera nya anpassade värden på Y för valideringsmängden\npredict1 &lt;- predict(object = model1, newdata = dataValid)\n\npredict2 &lt;- predict(object = model2, newdata = dataValid)\n\npredict3 &lt;- predict(object = model3, newdata = dataValid)\n\n# Beräkna ex. MSPR där y - yhat används\nMSPR &lt;- function(y, yhat){\n  (y - yhat)^2 %&gt;% \n    mean()\n}\n\ntibble(\n  Modell = c(1:3),\n  `$R^2_{adj}$` = c(summary(model1)$adj.r.squared,\n                    summary(model2)$adj.r.squared,\n                    summary(model3)$adj.r.squared),\n  MSE = c(summary(model1)$sigma^2,\n          summary(model2)$sigma^2,\n          summary(model3)$sigma^2),\n  MSPR = c(MSPR(dataValid$bill_length_mm, predict1),\n           MSPR(dataValid$bill_length_mm, predict2),\n           MSPR(dataValid$bill_length_mm, predict3))  \n) %&gt;% \n  kable(digits = 3, escape = FALSE)\n\n\n\n\nTabell 10.2: Enkla utvärderingsmått för jämförelse av de tre anpassade modellerna på valideringsdata\n\n\n\n\n\n\nModell\n\\(R^2_{adj}\\)\nMSE\nMSPR\n\n\n\n\n1\n0.843\n4.472\n5.894\n\n\n2\n0.829\n4.869\n6.005\n\n\n3\n0.798\n5.760\n6.487\n\n\n\n\n\n\n\n\nTabell 10.2 visar på samma relation mellan de tre modellerna, att den första är bäst, men vi ser generellt att felet har blivit större i valideringsmängden. Detta fenomen orsakas av att modellen inte längre har anpassats på det data som och att modellen då till viss del har överanpassats till data i träningsmängden. Om MSE och MSPR är nära varandra ger det en indikation på att modellen har lyckats generalisera sambandet bra och stora avvikelser betyder att vi har en mycket överanpassad modell. I just detta fall är skillnaderna inte jättestora så vi kan nog dra slutsatsen att modellen är någorlunda bra.\nAtt modellerna följer samma ordning för både tränings- och valideringsmängden är inte självklart. Vi kan se olika resultat beroende på hur under- eller överanpassad modellerna har blivit givet dess struktur och komplexitet, men fokus bör vara att jämföra valideringsmängdens mått.\n\n\nVisa kod\n# Antalet observationer totalt\nn &lt;- nrow(mtcars)\n\n# Antalet som tilldelas till träningsmängden utifrån en andel på 2/3\nnTrain &lt;- n*(2/3) \n\n# Sätter ett seed för reproducerbarheten\nset.seed(355)\n\n# Index (utvalda observationer) till träningsmängden\nindexTrain &lt;- sample(x = n, size = nTrain, replace = FALSE)\n\n# Plockar ut utvalda observationer från materialet med positiv indexering (lägger till) \n# för träning och negativ indexering (tar bort) för validering\ndataTrain &lt;- mtcars[indexTrain,]\ndataValid &lt;- mtcars[-indexTrain,]\n\n# Anpassa modellerna\nmodel1 &lt;- lm(mpg ~ disp + hp + wt + qsec, data =  dataTrain)\n\nmodel2 &lt;- lm(mpg ~ disp + hp, data = dataTrain)\n\nmodel3 &lt;- lm(mpg ~ hp * wt, data = dataTrain)\n\n# Prediktera nya anpassade värden på Y för valideringsmängden\npredict1 &lt;- predict(object = model1, newdata = dataValid)\n\npredict2 &lt;- predict(object = model2, newdata = dataValid)\n\npredict3 &lt;- predict(object = model3, newdata = dataValid)\n\ntibble(\n  Modell = c(1:3),\n  `$R^2_{adj}$` = c(summary(model1)$adj.r.squared,\n                    summary(model2)$adj.r.squared,\n                    summary(model3)$adj.r.squared),\n  MSE = c(summary(model1)$sigma^2,\n          summary(model2)$sigma^2,\n          summary(model3)$sigma^2),\n  MSPR = c(MSPR(dataValid$mpg, predict1),\n           MSPR(dataValid$mpg, predict2),\n           MSPR(dataValid$mpg, predict3))  \n) %&gt;% \n  kable(digits = 3, escape = FALSE)\n\n\n\nYtterligare exempel på datamaterialet mtcars\n\n\nModell\n\\(R^2_{adj}\\)\nMSE\nMSPR\n\n\n\n\n1\n0.783\n8.908\n6.538\n\n\n2\n0.786\n8.776\n11.789\n\n\n3\n0.862\n5.657\n3.608\n\n\n\n\n\n\n\n10.1.2 Korsvalidering\nIstället för att dela upp datamaterialet en gång i tränings- och valideringsmängd kan vi dela upp materialet i m lika stora grupper och successivt utvärdera en tränad modell på respektive grupp. Den tränade modellen använder då alla andra grupper som dess träningsmängd vilket innebär att vi får m stycken olika modeller och m stycken utvärderingar.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modellvalidering och variabelselektion</span>"
    ]
  },
  {
    "objectID": "01-regression/09-variable-selection.html#automatisk-variabelselektion",
    "href": "01-regression/09-variable-selection.html#automatisk-variabelselektion",
    "title": "10  Modellvalidering och variabelselektion",
    "section": "10.2 “Automatisk” variabelselektion",
    "text": "10.2 “Automatisk” variabelselektion\nArbetet med att hitta potentiella kandidatmodeller att jämföra med en valideringsmängd kan ta väldigt lång tid. Antalet potentiella modeller av olika storlekar ökar exponentiellt enligt \\(2^k -1\\). \\[\n\\begin{aligned}\n  2^5 -1 = 31 \\qquad 2^{10} -1 = 1023\\qquad 2^{20} -1 = 1048575\n\\end{aligned}\n\\] Om vi skulle genomföra alla dessa modellanpassningar för hand skulle det lätt gå överstyr och vi skulle säkerligen missa att anpassa några av de möjliga kandidaterna. Istället kan vi ta hjälp av algoritmer som systematiskt beskriver en process för hur vi kan anpassa möjliga modeller.\nEn utav de mest omfattande är best subset-algoritmen som undersöker alla modeller av olika storlekar, från 1 till \\(k\\), och redovisar ett urval av de bästa modellerna för respektive storlek givet ett valt utvärderingsmått. Denna algoritm kan vara lämplig när vill inte vill missa en potentiell bra modell då den faktiskt utforskar alla möjliga modeller som kan anpassas, men den kräver att vi inte har allt för många förklarande variabler att välja från. Olika utvärderingsmått, till exempel residualspridningen (S) eller den justerade förklaringsgraden (\\(R^2_{adj}\\)), kan också visa på olika modeller som “bäst” presterande inom de olika storlekarna vilket innebär att vi behöver väga samman olika utvärderingsmått eller genomföra ytterligare analyser, till exempel residualanalys, för att bedöma vilken modell som är bäst.\nUtöver den uttömmande algoritmen finns andra algoritmer som inte anpassar alla möjliga modeller utan utgår från en stegvis förbättring av modellen. Dessa delas upp i tre olika varianter;\n\nbakåteliminering: en algoritm som bara tar bort variabler,\nframåtvalsmetoden: en algoritm som bara lägger till variabler,\nstegvis regression: en algoritm som kan göra båda.\n\nAlgoritmerna väljer hur den ska gå vidare i modellanpassningen utifrån ett valt utvärderingsmått och anser sig “färdig” när utvärderingsmåttet inte förbättras. En stor nackdel med alla tre algoritmer är att de anses giriga eftersom de vill förbättra modellen bara “här och nu” och kan inte se flera steg framåt i processen. Det skulle mycket väl inträffa att en sämre förbättring just nu genererar en betydligt bättre slutgiltig modell än den “bästa” förbättringen just nu.\n\n\n\n\n\n\nViktigt\n\n\n\nIstället för ett utvärderingsmått kan modellerna förändras utefter vilken variabel som anses vara “minst”/“mest” signifikant, lägst eller högst p-värde. Denna process är dock väldigt känslig för problem med multikollinearitet och när det kommer till signifikans anser vi inte oss kunna gradera variablers effekt utefter p-värdet; antingen har en variabel en signifikant effekt (p-värde &lt; \\(\\alpha\\)) eller så har variabeln inte en signifikant effekt (p-värde &gt; \\(\\alpha\\)).\nResten av detta underlag kommer fokusera på utvärderingsmått i relation till dessa algoritmer.\n\n\nAlla dessa algoritmer har en stor nackdel; Att hitta det bästa värdet på ett valt utvärderingsmått betyder inte nödvändigtvis att modellen är lämplig!\nImplementationen av dessa algoritmer i programvaror kräver att den som använder metoderna inte tar resultaten som givna utan utvärderar modellerna i detalj sedan. Vi kan låta algoritmerna dra det tunga lasset att beräkna fram några förslag på modeller som är rimliga givet en större mängd förklarande variabler men vi måste själva genomföra det sista steget av utvärderingen, med bland annat residualanalys, ytterligare hypotesprövningar eller modellvalidering, för att komma fram till en modell som vi sedan vill använda.\nDetta är än mer viktigt om vi inkluderar polynom eller interaktioner i modellen då algoritmerna hanterar dessa som separata variabler och kan anse en modell med en variabel av högre ordning utan att inkludera grundvariablerna som “den bästa”. En sådan modell skulle inte kunna användas för att beskriva sambandet.\n\n10.2.1 Avancerade utvärderingsmått\nAlla dessa metoder utgår från att vi steg för steg undersöker kandidatmodeller av mindre/större storlek och väljer att ta bort/lägga till den variabel som ger den bästa förbättringen av ett valt utvärderingsmått. Vi har tidigare tittat på enkla mått som kan användas men i dessa algoritmer används mer avancerade mått som på ett bättre sätt tar hänsyn till både modellens prestanda och komplexitet.\nAkaike’s Information Criterion, \\(AIC_p\\), är ett mått som straffar modeller utefter deras komplexitet.\n\\[\n\\begin{aligned}\n  AIC_p = n \\cdot log\\left( \\frac{SSE}{n} \\right) + 2(p + 1)\n\\end{aligned}\n\\] där \\(n\\) är antalet observationer i träningsmängden och \\(p\\) är antalet parametrar (\\(k + 1\\)) i modellen.\nVi vill uppnå så små värden på AIC som möjligt.\n\n\n\n10.2.2 Implementation i R\nOlika paket och funktioner i R kan hjälpa till att använda dessa algoritmer. Vi kommer titta närmare på funktionerna i paketet olsrr men det finns andra paket med liknande funktioner, bland andra:\n\nleaps, se här,\nbigstep (bra för stora datamängder), se här,\nrms, se här,\nstep() från baspaketet, se här,\nnågra fler exempel här\n\nDet som kännetecknar funktionerna från olsrr är att vi alltid börjar med att ange den modell som vi anser vara den största möjliga modellen som kan anpassas. I det enkla fallet skulle det vara en modell med alla \\(k\\) variabler men om vi vill inkludera möjligheten för polynom och interaktioner i algoritmernas process behöver dessa inkluderas i den största modellen.\nAlla funktioner från olsrr hanterar kvalitativa variabler med fler än två kategorier som en grupp av variabler såvida variabeln är angiven som en factor i R. Detta är viktigt för att algoritmen inte ska inkludera enskilda indikatorvariabler i en modell som då får en otydlig referenskategori.\n\n\n10.2.3 Best subsets\nFunktionen ols_step_all_possible() och ols_step_best_possible() från paketet olsrr kan anpassa alla möjliga modeller av olika storlekar och presenterar resultatet i (en stor) tabell med många olika utvärderingsmått. Dessa funktioner kommer kräva mycket av programmet, speciellt om vi har många förklarande variabler. Vi måste som sagt börja med att ange den största möjliga modellen som vi tänker är en kandidat till analysen för att sedan låta algoritmen arbeta fram de olika modellerna som ska jämföras.\n\n\nVisa kod\nrequire(olsrr)\n\n# Anpassar den största modellen\ncompleteModel &lt;- lm(bill_length_mm ~ ., data = penguins)\n\n# Ger en lista med ALLA modellerna av olika storlek och tillhörande utvärderingsmått\nresult &lt;- ols_step_all_possible(completeModel)\n\nresult[[1]] %&gt;% \n  head(n = 5) %&gt;% \n  kable(digits = 3)\n\n\n\nDe första fem raderna från ett ols_step_all_possible() objekt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmindex\nn\npredictors\nrsquare\nadjr\nrmse\npredrsq\ncp\naic\nsbic\nsbc\nmsep\nfpe\napc\nhsp\n\n\n\n\n1\n1\n1\nspecies\n0.707\n0.705\n2.958\n0.701\n265.542\n1675.281\n726.132\n1690.514\n2931.122\n8.882\n0.297\n0.027\n\n\n4\n2\n1\nflipper_length_mm\n0.427\n0.425\n4.135\n0.421\n829.005\n1896.402\n947.524\n1907.827\n5728.294\n17.305\n0.580\n0.052\n\n\n5\n3\n1\nbody_mass_g\n0.347\n0.345\n4.411\n0.341\n988.694\n1939.421\n990.302\n1950.845\n6518.229\n19.692\n0.660\n0.059\n\n\n2\n4\n1\nisland\n0.143\n0.138\n5.056\n0.129\n1404.088\n2032.285\n1080.737\n2047.518\n8563.160\n25.948\n0.868\n0.078\n\n\n6\n5\n1\nsex\n0.118\n0.116\n5.127\n0.108\n1451.243\n2039.609\n1090.023\n2051.034\n8806.316\n26.604\n0.892\n0.080\n\n\n\n\n\nIstället för alla modeller av olika storlekar kan vi plocka ut de bästa modellerna för varje storlek som underlättar jämförelsen.\n\n\nVisa kod\n# Ger en lista med de \"bästa\" modellerna av olika storlekar\nresult &lt;- ols_step_best_subset(completeModel)\n\nresult[[1]] %&gt;% \n  head(n = 5) %&gt;% \n  kable(digits = 3)\n\n\n\nDe första fem raderna från ett ols_step_best_possible() objekt\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nmindex\nn\npredictors\nrsquare\nadjr\npredrsq\ncp\naic\nsbic\nsbc\nmsep\nfpe\napc\nhsp\n\n\n\n\n1\n1\nspecies\n0.707\n0.705\n0.701\n265.542\n1675.281\n726.132\n1690.514\n2931.122\n8.882\n0.297\n0.027\n\n\n2\n2\nspecies sex\n0.821\n0.819\n0.816\n36.570\n1512.791\n565.291\n1531.831\n1794.012\n5.452\n0.182\n0.016\n\n\n3\n3\nspecies flipper_length_mm sex\n0.832\n0.830\n0.826\n16.323\n1493.644\n546.481\n1516.493\n1688.762\n5.148\n0.172\n0.016\n\n\n4\n4\nspecies flipper_length_mm body_mass_g sex\n0.837\n0.834\n0.830\n9.077\n1486.444\n539.520\n1513.101\n1647.768\n5.038\n0.168\n0.015\n\n\n5\n5\nspecies bill_depth_mm flipper_length_mm body_mass_g sex\n0.839\n0.836\n0.831\n6.950\n1484.255\n537.500\n1514.720\n1632.158\n5.005\n0.167\n0.015\n\n\n\n\n\nDet finns väldigt mycket information i dessa tabeller som inte är relevant (vissa mått har vi aldrig har sett förr) utan vi bör sålla bland de angivna måtten, noggrannt avväga vilka mått som vi anser är viktigare än andra, och väga skillnaderna i måtten för att till slut komma fram till den modell som vi ska analysera vidare.\nOm vi plockar ut de mått som vi har sett tidigare får vi en tabell som är betydlig lättare att läsa av och jämföra modeller av olika storlek.\n\n\nVisa kod\nresult[[1]] %&gt;% \n  select(n, predictors, rsquare, adjr, aic) %&gt;% \n  kable(digits = 3, \n        col.names = c(\"Storlek\", \"Variabler\", \"$R^2$\", \"$R^2_{adj}$\", \"AIC\"), \n        escape = FALSE)\n\n\n\nDe fem första raderna från algoritmen med utvalda utvärderingsmått\n\n\n\n\n\n\n\n\n\nStorlek\nVariabler\n\\(R^2\\)\n\\(R^2_{adj}\\)\nAIC\n\n\n\n\n1\nspecies\n0.707\n0.705\n1675.281\n\n\n2\nspecies sex\n0.821\n0.819\n1512.791\n\n\n3\nspecies flipper_length_mm sex\n0.832\n0.830\n1493.644\n\n\n4\nspecies flipper_length_mm body_mass_g sex\n0.837\n0.834\n1486.444\n\n\n5\nspecies bill_depth_mm flipper_length_mm body_mass_g sex\n0.839\n0.836\n1484.255\n\n\n6\nspecies bill_depth_mm flipper_length_mm body_mass_g sex year\n0.839\n0.836\n1484.537\n\n\n7\nspecies island bill_depth_mm flipper_length_mm body_mass_g sex year\n0.840\n0.836\n1487.227\n\n\n\n\n\nFör både den justerade förklaringsgraden (högst) och AIC (lägst) är modellen med 5 förklarande variabler som den bästa och vi kan nu gå vidare med att utvärdera den med metoder från Avsnitt 4.1.\n\n\n10.2.4 Bakåteliminering\nDen första utav de stegvisa algoritmerna innebär att vi börjar med den absolut största modellen vi kan tänka oss och successivt tar bort variabler tills den reducerade modellen inte längre anses vara en bättre modell. Algoritmen väljer vilken variabel som ska plockas bort vid varje steg genom att anpassa alla modeller med en färre variabel och välja den modell vars utvärderingsmått är “bäst”. Om den största modellen är lagomt stor kommer denna algoritm fungera bra, men om den största modellen är alldeles för komplex kommer algoritmen få jobba mycket att anpassa alla modeller av storlek \\(k-1\\), \\(k-2\\) osv.\nMed hjälp av ols_step_backward_aic() används AIC som utvärderingsmått. Utskriften från denna funktion är väldigt omfattande, speciellt om vi använder argumentet details = TRUE, och bör inte presenteras utan används för internt bruk att förstå processen som algoritmen har tagit. Om vi sparar resultatet i ett separat R-objekt kan vi plocka ut förenklade tabeller med mått som vi förstår och kan tolka.\n\n\nVisa kod\n# Lägg till argumentet details = TRUE för att få mer detaljer i utskriften\nbakåtModell &lt;- ols_step_backward_aic(completeModel)\n\nbakåtModell$metrics %&gt;% \n  select(step, variable, r2, adj_r2, aic) %&gt;% \n  kable(digits = 3, \n        col.names = c(\"Steg\", \"Variabel\", \"$R^2$\", \"$R^2_{adj}$\", \"AIC\"),\n        escape = FALSE)\n\n\n\nResultat av bakåtelimineringens steg att plocka bort variabler\n\n\nSteg\nVariabel\n\\(R^2\\)\n\\(R^2_{adj}\\)\nAIC\n\n\n\n\n1\nisland\n0.839\n0.836\n1484.537\n\n\n2\nyear\n0.839\n0.836\n1484.255\n\n\n\n\n\n\n\nVisa kod\nbakåtModell$model %&gt;% \n  summary() %&gt;% \n  coef() %&gt;% \n  kable(digits = 3,\n        col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\"))\n\n\n\nDen utvalda modellen från bakåtelimineringen\n\n\nVariabel\nSkattning\nMedelfel\nt-värde\np-värde\n\n\n\n\n(Intercept)\n15.017\n4.374\n3.433\n0.001\n\n\nspeciesChinstrap\n9.566\n0.350\n27.351\n0.000\n\n\nspeciesGentoo\n6.404\n1.030\n6.215\n0.000\n\n\nbill_depth_mm\n0.313\n0.154\n2.032\n0.043\n\n\nflipper_length_mm\n0.069\n0.023\n2.961\n0.003\n\n\nbody_mass_g\n0.001\n0.000\n2.562\n0.011\n\n\nsexmale\n2.030\n0.389\n5.215\n0.000\n\n\n\n\n\nAIC för den största modellen är \\(AIC = 1487.227\\) och kan tas fram med hjälp av funktionen AIC(modellobjektet). Jämfört med det sista steget från algoritmen, \\(AIC = 1484.255\\), ser vi att AIC blivit mindre vilket är önskvärt. Att algoritmen inte längre väljer att ta bort några ytterligare variabler innebär att AIC har blivit så liten som den kan bli med denna modellstruktur.\n\n\n10.2.5 Framåtvalsmetoden\nI de fall där den största modellen är alldeles för stor för att ens anpassa starten av bakåtelimineringsalgoritmen kan vi istället börja med en tom modell och successivt lägga till variabler. Processen för varje steg är densamma, avseende hur algoritmen väljer att gå vidare till nästa steg, men vi tittar nu på kandidater med en fler variabel och väljer den modell som har minst AIC.\n\n\nVisa kod\n# Lägg till argumentet details = TRUE för att få mer detaljer i utskriften\nframåtModell &lt;- ols_step_forward_aic(completeModel)\n\nframåtModell$metrics %&gt;% \n  select(step, variable, r2, adj_r2, aic) %&gt;% \n  kable(digits = 3, \n        col.names = c(\"Steg\", \"Variabel\", \"$R^2$\", \"$R^2_{adj}$\", \"AIC\"),\n        escape = FALSE)\n\n\n\nResultat av framåtvalsmetodens steg att lägga till variabler\n\n\nSteg\nVariabel\n\\(R^2\\)\n\\(R^2_{adj}\\)\nAIC\n\n\n\n\n1\nspecies\n0.707\n0.705\n1675.281\n\n\n2\nsex\n0.821\n0.819\n1512.791\n\n\n3\nflipper_length_mm\n0.832\n0.830\n1493.644\n\n\n4\nbody_mass_g\n0.837\n0.834\n1486.444\n\n\n5\nbill_depth_mm\n0.839\n0.836\n1484.255\n\n\n\n\n\n\n\nVisa kod\nframåtModell$model %&gt;% \n  summary() %&gt;% \n  coef() %&gt;% \n  kable(digits = 3,\n        col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"t-värde\", \"p-värde\"))\n\n\n\nDen utvalda modellen från framåtvalsmetoden\n\n\nVariabel\nSkattning\nMedelfel\nt-värde\np-värde\n\n\n\n\n(Intercept)\n15.017\n4.374\n3.433\n0.001\n\n\nspeciesChinstrap\n9.566\n0.350\n27.351\n0.000\n\n\nspeciesGentoo\n6.404\n1.030\n6.215\n0.000\n\n\nsexmale\n2.030\n0.389\n5.215\n0.000\n\n\nflipper_length_mm\n0.069\n0.023\n2.961\n0.003\n\n\nbody_mass_g\n0.001\n0.000\n2.562\n0.011\n\n\nbill_depth_mm\n0.313\n0.154\n2.032\n0.043\n\n\n\n\n\nI just detta fall får vi samma modell som bakåtelimineringen men det är inte garanterat att inträffa. Ordningen av variablerna som läggs till behöver inte vara samma variabler som bakåtelimineringen utgår från när den ska ta bort en variabel.\n\n\n10.2.6 Stegvis regression\nNackdelen med de enkelriktade algoritmerna (bakåteliminering och framåtval) är att när en variabel lagts till eller tagits bort, är detta beslut permanent. Algoritmens girighet kan för hindra att vi hittar den bästa modellen efter några steg. Det kan mycket väl vara så att en variabel bidrar med multikollinearitet som resulterar i att en viktig variabel plockas bort eller att en interaktion mellan vissa variabler bidrar med information till modellen men som aldrig läggs till.\nLösningen är att släppa på begränsningen och tillåta algoritmen att vid varje steg både lägga till och ta bort variabler. Detta kan vi genomföra med hjälp av ols_step_both_aic().\n\n\nVisa kod\n# Lägg till argumentet details = TRUE för att få mer detaljer i utskriften\nstegModell &lt;- ols_step_both_aic(completeModel)\n\nstegModell$metrics %&gt;% \n  select(step, variable, r2, adj_r2, aic) %&gt;% \n  kable(digits = 3, \n        col.names = c(\"Steg\", \"Variabel\", \"$R^2$\", \"$R^2_{adj}$\", \"AIC\"),\n        escape = FALSE)\n\n\n\nResultat av stegvis regression\n\n\nSteg\nVariabel\n\\(R^2\\)\n\\(R^2_{adj}\\)\nAIC\n\n\n\n\n1\nspecies\n0.707\n0.705\n1675.281\n\n\n2\nsex\n0.821\n0.819\n1512.791\n\n\n3\nflipper_length_mm\n0.832\n0.830\n1493.644\n\n\n4\nbody_mass_g\n0.837\n0.834\n1486.444\n\n\n5\nbill_depth_mm\n0.839\n0.836\n1484.255\n\n\n\n\n\nAlgoritmen börjar från en tom modell och först lägger till variabler. I denna utskrift ser vi att algoritmen kommer fram till samma modell som framåtvalsmetoden, men det behöver inte alltid vara fallet.\n\n\n10.2.7 Visuell jämförelse av modellerna\nResultatet från algoritmen kan visualiseras i figurer istället för i en tabell. Funktionen plot() tar resultatet av modellvalsalgoritmen och visualiserar utvecklingen av utvärderingsmåtten för respektive modellstorlek. Beroende på vilken algoritm som har använts kommer resultatet visa olika diagram och för de stegvisa processerna visas utvecklingen av AIC för varje steg.\n\n\nVisa kod\nplot(bakåtModell)\n\n\n\n\n\nVisuell representation av de stegen som algoritmen tar och utvecklingen av utvärderingsmått",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modellvalidering och variabelselektion</span>"
    ]
  },
  {
    "objectID": "01-regression/09-variable-selection.html#övningsuppgifter",
    "href": "01-regression/09-variable-selection.html#övningsuppgifter",
    "title": "10  Modellvalidering och variabelselektion",
    "section": "10.3 Övningsuppgifter",
    "text": "10.3 Övningsuppgifter\nVi ska i dessa uppgifter använda samma SENIC material om sjukhusinfektioner från Avsnitt 7.3.\nVi anser att den största modellen som ska förklara infektionsrisken innehåller alla förklarande variabler, ID exkluderas, och interaktioner av ordning 2. Denna modell kan anpassas med lm(Infection_risk ~ (.)^2, data = senic %&gt;% select(!ID)).\n\nDela upp datamaterialet i en träningsmängd (2/3 av data) och en valideringsmängd (1/3 av data). Tänk på att använda set.seed() för att randomiseringen av data ska vara samma varje gång ni kör koden.\nAnpassa den största modellen på träningsmängden och beräkna modellens AIC.\nPresentera den “bästa” modellen enligt följande modellvalsalgoritmer. Visa “vägen” algoritmen gått för att komma fram till denna modell och visa en sammanfattning av modellen med dess tillhörande AIC-värde.\n\nFramåtval med AIC som kriterium. (Modell 1)\nBakåteliminering med AIC som kriterium. (Modell 2)\n\nSammanställ de tre modellernas (kompletta, modell 1 och 2) AIC värden. Kommentera och analysera resultatet. Vilken modell fick bäst AIC-värde?\nUtvärdera respektive modell avseende dess lämplighet med hjälp av residualanalys och analys av modellens variabler. Tänk på att en modell med interaktioner bör inkludera alla grundvariabler oavsett om de är signifikanta eller inte.\nGenomför ytterligare justeringar av varje modell så att ni anser var och en vara lämplig.\nBeräkna MSE i träningsmängden och MSPR i valideringsmängden för respektive justerad modell. Lägg till måtten i tabellen från d) och kommentera samt analysera resultatet. Skiljer sig jämförelsen mellan träning och valideringsmängden? Vad säger det om ev. överanpassning av modellerna?",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modellvalidering och variabelselektion</span>"
    ]
  },
  {
    "objectID": "01-regression/09-variable-selection.html#footnotes",
    "href": "01-regression/09-variable-selection.html#footnotes",
    "title": "10  Modellvalidering och variabelselektion",
    "section": "",
    "text": "Viss litteratur blandar dessa termer, man delar upp data i två delar och använder det ‘nya’ materialet som en valideringsmängd för att jämföra olika modeller men kallar den för testmängd.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Modellvalidering och variabelselektion</span>"
    ]
  },
  {
    "objectID": "01-regression/10-logistic-regression.html",
    "href": "01-regression/10-logistic-regression.html",
    "title": "11  Logistisk regression",
    "section": "",
    "text": "11.1 Binär responsvariabel\nDe tidigare kapitlen har fokuserat på modeller där responsvariabeln antas vara kvantitativ och kontinuerlig. Dessa modeller är begränsade till just detta fall men det går med enkla transformeringar att utöka modellerna att också anpassa modeller där responsvariabeln är en annan variabeltyp eller följer en annan skala. En utav dessa utökningar kallas för logistisk regression som modellerar en binär (två kategorier) kvalitativ responsvariabel.\nUtöver att modellen anpassar en annan form av responsvariabel behöver vi också justera hur vi kommer fram till modellens anpassade värden. Inom linjär regression är minsta kvadratmetoden den absolut enklaste anpassningsmetoden med simpla formler för att skatta modellens parametrar, men även maximum likelihoodmetoden (ML) kan användas med hjälp av en iterativ optimeringsalgoritm för att finna de parameterskattningar som motsvarar minsta kvadratmetoden. Fördelen med att använda ML-metoder i modellanpassningen är att metoden kan användas för mer komplexa modeller, däribland logistisk regression.\nMed en binär responsvariabel är det vanligast att vi kodar variabeln med 0 och 1, exempel: Om patienten tillfrisknade inom studieperioden så anger vi \\(Y_i = 1\\) annars \\(Y_i = 0\\). Inom statistik och maskininlärning kallar vi problem där vi har en kvalitativ reponsvariabel för klassificering där målet är att skapa en modell som kan ge så många korrekta klassificeringar (predikterade klasser) som möjligt utan att misklassificera observationer till fel klasser.\nIstället för att anta att \\(Y|X \\sim N(...)\\), antar vi istället att \\(Y|X \\sim Bernoulli(...)\\). Väntevärdet som modeller anpassar kommer inte längre direkt vara ett värde på responsvariabelns skala utan vi anser oss modellera sannolikheten att observationen antar värdet 1:\n\\[\n\\begin{aligned}\nE[Y] = P(Y_i = 1) = \\pi_i\n\\end{aligned}\n\\] På samma sätt som vi använde medelvärdet av Y som en form av grundmodell för en kontinuerlig responsvariabel kan vi i detta fall använda andelen 1:or som en grundmodell för den binära responsvariabeln. Men vi vill även här skapa modeller som kan ta hänsyn till annan information, de förklarande variablerna, för att förhoppningsvis förbättra förklaringen av responsvariabeln.\n\\[\n\\begin{aligned}\nE[Y|X] = P(Y_i = 1 | X_i)\n\\end{aligned}\n\\]",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistisk regression</span>"
    ]
  },
  {
    "objectID": "01-regression/10-logistic-regression.html#binär-responsvariabel",
    "href": "01-regression/10-logistic-regression.html#binär-responsvariabel",
    "title": "11  Logistisk regression",
    "section": "",
    "text": "11.1.1 Logistiska funktionen\nEftersom linjära samband är lätta att arbeta med och tolka så vill vi formulera denna betingade sannolikhet utifrån den linjära modellen. En linjär regressionsmodell formuleras enligt:\n\\[\n\\begin{aligned}\n\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\mathbf{E}\n\\end{aligned}\n\\] men vi kan också formulera enskilda \\(Y_i\\) i matrisform enligt: \\[\n\\begin{aligned}\n  Y_i = \\mathbf{X}_i'\\boldsymbol{\\beta} + E_i\n\\end{aligned}\n\\] där värden på \\(Y_i\\) täcker hela den reella tallinjen (\\(Y \\in \\mathbb{R}\\)). \\(\\mathbf{X}_i'\\) är den i:te raden från designmatrisen angiven som en kolumnvektor, därav behovet av att transponera till en radvektor.\nEn sannolikhet antar bara värden mellan 0 och 1, dvs. \\(\\pi \\in [0,1]\\), så vårt mål är att tvinga in den linjära regressionsmodellen från hela tallinjen till utfallsrummet \\([0,1]\\). Detta kan lösas med hjälp utav den logistiska funktionen som kan uttryckas på två olika sätt:\n\\[\n\\begin{aligned}\n  P(Y_i = 1|Z_i) &= \\frac{exp[Z_i]}{1 + exp[Z_i]}\\\\\n  \\\\\n\\text{alternativt}\\\\\n\\\\\n&= \\frac{1}{1 + exp[-Z_i]}\n\\end{aligned}\n\\] där \\(Z_i\\) är den anpassade linjära funktion som beror på de förklarande variablerna; \\(\\mathbf{X}_i'\\boldsymbol{\\beta}\\).\n\n\n\n\n\n\nNotera\n\n\n\nNotera att vi inte har någon felterm \\(\\mathbf{E}\\) här. Eftersom vi modellerar en sannolikhet för en viss händelse (\\(Y_i = 1\\)), placeras felet eller slumpmässigheten med den logistiska funktionen i just den sannolikhetsdefinitionen.\n\n\nVi kan se hur den logistiska funktionen ser ut för olika värden på \\(Z_i\\).\n\n\nVisa kod\ndata &lt;- \n  tibble(\n    z = seq(-10, 10, by = 0.01),\n    y = exp(z) / (1 + exp(z))\n  )\n\nggplot(data) + aes(x = z, y = y) + geom_line(linewidth = 1, color = \"steelblue\") +\n  theme_bw() + \n  geom_hline(yintercept = 0, linetype = 2, color = \"#d9230f\") + \n  geom_hline(yintercept = 1, linetype = 2, color = \"#d9230f\") +\n  labs(y = \"P(Y = 1)\", x = \"Z\")\n\n\n\n\n\nFormen på den logistiska funktionen.\n\n\n\n\nVi ser tydligt att värdena på \\(P(Y_i = 1)\\) nu begränsas till värden mellan 0 och 1 där extremt negativa värden av \\(Z_i\\) asymptotiskt går mot 0 och extremt positiva värden av \\(Z_i\\) asymptotiskt går mot 1.\nMed hjälp av den logistiska funktionen kan vi få ett uttryck för den logistiska regressionen ifall vi byter ut \\(Z_i\\) med den linjära regressionsmodellen: \\[\n\\begin{aligned}\n  P(Y_i = 1| \\mathbf{X}_i, \\boldsymbol{\\beta}) = \\frac{exp[\\mathbf{X}_i'\\boldsymbol{\\beta}]}{1 + exp[\\mathbf{X}_i'\\boldsymbol{\\beta}]}\n\\end{aligned}\n\\]\nFör en enkel logistisk regression innehållande en kontinuerlig förklarande variabel kan vi se följande effekter på den logistiska funktionens form givet olika parametervärden.\nI den enkla logistiska regressionsmodellen (med en förklarande variabel) kan vi se hur olika parameterskattningar påverkar denna form. I följande kod skapar vi fem olika linjära modeller med olika värden på interceptet och lutningen.\n\n\nVisa kod\n# Anger antalet observationer\nnObs &lt;- 200\n\n# Skapar en egen logistisk funktion som transformerar värden\nlogisticFun &lt;- function(z){\n  p &lt;- exp(z)/(1+exp(z))\n  return(p)\n}\n\ndata &lt;- \n  tibble(\n    # Skapar en variabel x\n    x = seq(-5, 5, length = nObs),\n    \n    # En linjär funktion där beta0 är 0 och beta1 är 1\n    z1 = 0 + 1*x,\n    \n    # En linjär funktion med ett nollskilt värde på interceptet\n    z2 = 1 + 1*x,\n    \n    # En linjär funktion med brantare lutning\n    z3 = 0 + 5*x,\n    \n    # En linjär funktion med ingen lutning\n    z4 = 0 + 0*x,\n    \n    # En linjär funktion med negativ lutning\n    z5 = 0 - 1*x\n  ) %&gt;% \n  # Roterar materialet för enklare visualisering\n  pivot_longer(\n    cols = -x,\n    names_to = \"Modell\", \n    values_to = \"z\"\n  ) %&gt;% \n  # Skapar sannolikheten utifrån den logistiska funktionen\n  mutate(\n    py = logisticFun(z)\n  )\n\nggplot(data) + aes(x = x, y = py) + geom_line(linewidth = 1, color = \"steelblue\") + \n  facet_grid(rows = vars(Modell)) + theme_bw() + \n  geom_hline(yintercept = 0.5, linetype = 2)\n\n\n\n\n\nOlika former på den logistiska funktionen givet olika värden på parametrar\n\n\n\n\nBeroende på parametervärdena får denna så kallade sigmoidkurva (kurvan ser ut som ett S) olika former.\n\nz1: Med ett intercept på 0 hamnar punkten där kurvans sannolikhet är 0.5 vid värdet \\(Z_i = 0\\).\nz2: När vi ändrar på \\(\\beta_0\\) flyttas också interceptet i den logistiska funktionen, ett positivt intercept innebär att kurvans sannolikhet är större än 0.5 vid värdet \\(Z_i = 0\\).\nz3: När \\(\\beta_1\\) blir brantare blir också den logistiska funktionen brantare och vi hamnar snabbare ute i extremerna, 0 och 1.\nz4: När \\(\\beta_1\\) är svag eller ligger nära 0 blir den logistiska funktionen mindre brant och vid 0 visas ingen förändring av sannolikheten. Vi kan jämföra detta med att i ett binärt fall vi har chansen att gissa rätt på 1 eller 0 hälften av tiden av ren slump. Om en variabel som vi lägger till i modellen inte bidrar med någon information, kvarstår denna rena gissning.\nz5: En negativ \\(\\beta_1\\) innebär att sannolikheten blir mindre ju större värden på \\(Z_i\\) vi har, vi vänder alltså på sigmoidkurvan.\n\n\n\n11.1.2 Logitlänken\nMed hjälp av länkfunktioner kan vi plocka fram den linjära modellen från den logistiska funktionen och andra varianter av funktioner som bygger vidare på den linjära modellen. Generellt kan vi säga att en länkfunktion är den transformering som sker från den linjära modellen till den modell som beskriver den icke-kontinuerliga responsvariabeln.\nFör logistisk regression används logitlänken: \\[\n\\begin{aligned}\n  log\\left( \\frac{\\pi_i}{1 - \\pi_i}\\right) = Z_i = \\mathbf{X}_i'\\boldsymbol{\\beta}\n\\end{aligned}\n\\]\nI denna litteratur betecknar \\(log()\\) alltid den naturliga logaritmen1. Vi kan uttrycka det som att den logistiska regresionssmodellen är linjär i sin logitlänk för sannolikheten \\(\\pi\\).\nDenna länk visar också hur vi bör tolka parametrar från den linjära modellen. Uttrycket inuti logaritmen beskriver ett odds, sannolikheten att något inträffar dividerat med sannolikheten att något inte inträffar, specifikt oddset att \\(Y_i = 1\\). Den linjära modellen beskriver då logodds och en lutningsparameter beskriver en förändring i logodds, även kallad en oddskvot, som vi kommer återkomma till senare.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistisk regression</span>"
    ]
  },
  {
    "objectID": "01-regression/10-logistic-regression.html#logistisk-regression",
    "href": "01-regression/10-logistic-regression.html#logistisk-regression",
    "title": "11  Logistisk regression",
    "section": "11.2 Logistisk regression",
    "text": "11.2 Logistisk regression\nTill skillnad från vanlig linjär regression kan vi inte längre använda minsta kvadratmetoden för att skatta modellens parametrar då vi inte längre har en linjär relation mellan de förklarande och responsvariabeln. Istället behöver vi använda responsvariabelns (log)likelihoodfunktion och iterativt optimera för att hitta de parametervärden som genererar det högsta värdet på funktionen.\n\nFör en Bernoulli-fördelad slumpvariabel kan vi skriva loglikelihoodfunktionen som: \\[\n\\begin{aligned}\nlogL(\\pi) &= log\\left[\\prod\\limits_{i = 1}^n \\left( \\pi^{Y_i} \\cdot (1 - \\pi)^{1 - Y_i}\\right) \\right]\n\\\\&= \\sum\\limits_{i = 1}^{n_1}log(\\pi) + \\sum\\limits_{i = n_1 + 1}^{n}log(1 - \\pi)\n\\end{aligned}\n\\]\ndär \\(\\pi\\) är sannolikheten för \\(P(Y=1)\\), \\(n\\) är antalet observationer och \\(n_1\\) är antalet 1:or i materialet2. När vi modellerar den Bernoullifördelade variabeln med en logistisk regression antar vi att \\(P(Y=1)\\) varierar beroende på värden av våra förklarande variabler, så vi byter ut \\(\\pi\\) med ett uttryck som förhåller sig till de förklarande variablerna och \\(\\beta\\). Detta ger loglikelihoodfunktionen: \\[\n\\begin{aligned}\nlogL(\\boldsymbol{\\beta}) = \\sum_{i = n_1 + 1}^{n} \\operatorname{-}\\mathbf{X}_i'\\boldsymbol{\\beta} - \\sum_{i=1}^n \\ln (1 + exp\\left[\\operatorname{-}\\mathbf{X}_i'\\boldsymbol{\\beta} \\right])\n\\end{aligned}\n\\] Denna funktion optimeras numeriskt, vanligtvis med Fisher Scoring Algorithm3. Det är denna algoritm som R använder sig utav när vi en logistisk regressionsmodell anpassas.\n\n11.2.1 glm()\nglm() används för att anpassa generaliserade linjära modeller, en mer flexibel typ av linjära modeller. Med hjälp av argumentet family kan vi ange vilken fördelning och länkfunktion som vi anser responsvariabeln behöver för att transformera den linjära modellen till den aktuella modellen för responsvariabeln.\nObjektet som glm() returnerna har många liknande delobjekt som lm(). Det går även att använda liknande funktioner såsom summary(), coef(), och residuals() för att plocka ut enskilda objekt som vi är vana vid att göra. Däremot kommer dessa objekt inte tolkas på samma sätt som vi har gjort i tidigare kapitel då vi måste ta hänsyn till den förändrade modellstrukturen.\nVi kan anpassa en modell baserat på mtcars där vi modellerar huruvida bilen har automat eller manuell växel am. I datamaterialet har variabeln redan kodats binärt där 0 är automatisk och 1 manuell växling. Vi använder tre variabler ur data för att modellera denna responsvariabel.\n\n\nVisa kod\n# Anpassar modellen\nmodel &lt;- \n  glm(\n    am ~ mpg + cyl + hp,\n    data = mtcars,\n    # Anger binomial som familj där logitlänken är länkfunktionen\n    family = \"binomial\"\n  )\n\n# Sammanfattar modellen\nsummary(model)\n\n\n\nCall:\nglm(formula = am ~ mpg + cyl + hp, family = \"binomial\", data = mtcars)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)  \n(Intercept) -27.66400   16.22158  -1.705   0.0881 .\nmpg           1.09425    0.58578   1.868   0.0618 .\ncyl          -0.63106    0.68703  -0.919   0.3583  \nhp            0.06299    0.03046   2.068   0.0386 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 43.230  on 31  degrees of freedom\nResidual deviance: 18.347  on 28  degrees of freedom\nAIC: 26.347\n\nNumber of Fisher Scoring iterations: 7\n\n\nI summary-utskriften får vi nu annan information än vad vi är vana vid. Koefficienttabellen finns fortfarande kvar med lite andra rubriker, men sedan saknas en modellutvärdering som vi är van att se. Istället presenteras modellens devians, ett tillhörande AIC-värde och ett resultat från optimeringsalgoritmen. I och med att vi nu genomför optimering måste vi kontrollera att optimeringen faktiskt har konvergerat, det vill säga nått sitt maximum, vilket innebär att vi behöver vara uppmärksamma på fel- eller varningsmeddelanden som R ger oss relaterat till konvergensen. I detta fall funkade allting utan problem och optimeringen har konvergerat efter 7 iterationer.\n\n\n\n\n\n\nViktigt\n\n\n\nOm en modell inte konvergerar kan vi öka antalet iterationer vi tillåter optimeringsalgoritmen att gå innan den stannar. Vi behöver då lägga till glm(..., control = list(maxit = 50)) eller något annat större värde. Standardargumentet är att algoritmen genomför 25 iterationer.\n\n\nTänk på att en utskrift direkt från R för denna modell inte är lämpligt att använda i presentationssyften utan vi behöver återigen plocka ut de olika delarna och skapa snyggare tabeller.\n\n\nVisa kod\nsummary(model) %&gt;% \n  coef() %&gt;% \n  kable(digits = 3, caption = \"Modellens skattade koefficienter.\", col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"z-värde\", \"p-värde\"))\n\n\n\nModellens skattade koefficienter.\n\n\nVariabel\nSkattning\nMedelfel\nz-värde\np-värde\n\n\n\n\n(Intercept)\n-27.664\n16.222\n-1.705\n0.088\n\n\nmpg\n1.094\n0.586\n1.868\n0.062\n\n\ncyl\n-0.631\n0.687\n-0.919\n0.358\n\n\nhp\n0.063\n0.030\n2.068\n0.039\n\n\n\n\n\n\n11.2.1.1 Lutningskoefficienter\nKoefficienttabellens lutningsparametrar tolkas inte som i en vanlig linjär regression eftersom länkfunktionen transformerar den linjära modellen till responsvariabelns skala, till exempel när antalet miles per gallon (mpg) ökar med ett ökar inte y med 1.094. Istället beskriver dessa parametrar, \\(\\beta_j\\), förändringen i logoddset för \\(Y = 1\\) och kan efter en transformering, \\(e^{\\beta_j}\\), beskriva oddskvoten för \\(Y=1\\) när den förklarande variabeln ökar med en enhet.\nFör just denna modell kan vi transformera parameterskattningen för mpg enligt \\(e^{1.094} = 2.987\\) som att när mpg ökar med en enhet, så är oddset att motorn är manuellt växlad (\\(Y = 1\\)) ca 3 gånger högre.\nMatematiskt kan vi skriva upp detta likt: \\[\n\\begin{aligned}\n  \\hat{\\beta}_1 &= \\frac{p(y = 1|x = 1)}{p(y = 1|x = 0)} = \\frac{log(\\frac{\\pi_{x = 1}}{1 - \\pi_{x = 1}})}\n    {log(\\frac{\\pi_{x = 0}}{1 - \\pi_{x = 0}})}\\\\\n    \\\\\n    e^{\\hat{\\beta}_1} &= \\frac{\\frac{\\pi_{x = 1}}{1 - \\pi_{x = 1}}}\n    {\\frac{\\pi_{x = 0}}{1 - \\pi_{x = 0}}} \\Rightarrow \\\\\n    \\hat{OR}_{1 vs 0} &= \\frac{Odds(y = 1|x = 1)}{Odds(y = 1|x = 0)}\n\\end{aligned}\n\\]\n\n\n11.2.1.2 Inferens\nGivet att en lämplig likelihoodfunktion används och ‘nog stort data’ anses testvariabeln \\(\\left(Z = \\frac{\\hat{\\beta}_j - \\beta_j}{SE_{\\hat{\\beta}_j}}\\right)\\) följa en standardiserad normalfördelning. Detta kallas för ett Wald-test och är de tester som vi ser i koefficienttabellen.4 Medelfelen för respektive parametrar tas från kovariansmatrisen för \\(\\hat{\\boldsymbol{\\beta}}\\) som beräknas genom att använda andraderivator från likelihoodfunktionen vilket medför att vi kan skapa tester och intervallskattningar för \\(\\boldsymbol{\\beta}\\).",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistisk regression</span>"
    ]
  },
  {
    "objectID": "01-regression/10-logistic-regression.html#utvärdering-av-logistisk-regression",
    "href": "01-regression/10-logistic-regression.html#utvärdering-av-logistisk-regression",
    "title": "11  Logistisk regression",
    "section": "11.3 Utvärdering av logistisk regression",
    "text": "11.3 Utvärdering av logistisk regression\nI vanlig regression kan vi utvärdera modellens lämplighet genom residualanalys där vi jämför \\(Y_i - \\hat{Y}_i\\) och undersöker om residualerna uppfyller modellantaganden. I logistisk regression kommer den observerade responsvariabeln bara anta två värden, 1 och 0, och modellens anpassade värden anta värden mellan 0 och 1 vilket innebär att vanliga residualer inte längre jämför samma sorts variabel.\nI ett klassificeringsproblem kan vi istället jämföra de observerade klasserna för \\(Y\\) med predikterade klasser \\(\\hat{Y}\\) i en korstabell, även kallad förväxlingsmatris. Eftersom modellen egentligen predikterar en sannolikhet för \\(Y = 1\\) och inte den faktiska klassen behöver vi gå ett steg längre för att faktiskt kunna skapa förväxlingsmatrisen. Vi kan tänka att sannolikheter större än 0.5 innebär att \\(Y = 1\\) är mer sannolikt att inträffa än \\(Y = 0\\) vilket leder oss till att också prediktera den klassen för dessa observationer, \\(\\hat{Y} = 1\\).\nNär vi skapar förväxlingsmatrisen räknar räknar frekvenserna av antalet \\(Y = 1\\) som blivit predikterade till de olika klasserna \\(\\hat{Y} = 1\\) (\\(f_{11}\\)) och \\(\\hat{Y} = 0\\) (\\(f_{10}\\)) och antalet \\(Y = 0\\) som blivit predikterade till respektive klass (\\(f_{01}\\) och \\(f_{00}\\)).\n\n\nFörväxlingsmatris med frekvenser av olika fall.\n\n\n\n\n\n\nPredikterad klass\n\n\n\n\n\n\n\\(\\hat{Y} = 1\\)\n\n\n\\(\\hat{Y} = 0\\)\n\n\n\n\n\n\nSann klass\n\n\n\\(Y = 1\\)\n\n\n\\(f_{11}\\)\n\n\n\\(f_{10}\\)\n\n\n\n\n\\(Y = 0\\)\n\n\n\\(f_{01}\\)\n\n\n\\(f_{00}\\)\n\n\n\n\nI R kan en sådan tabell enkelt fås fram genom table(y, yHat) där y innehåller de sanna värdena och yHat innehåller prediktionerna. Notera att dessa vektorer måste ha samma observationsordning för att korstabellen ska blir korrekt. Utifrån förväxlingsmatrisen kan ett antal utvärderingsmått beräknas som fokuserar på olika aspekter av modellens prestanda.\nDe två enklaste måtten är andelen korrekta prediktioner och andelen felaktiga prediktioner. Vi kallar andelen korrekta prediktioner för modellens träffsäkerhet (eng. Accuracy) och andelen felaktiga prediktioner för modellens felkvot (eng. Misclassification rate).\n\\[\n\\begin{aligned}\n  \\text{Träffsäkerhet} &= \\frac{f_{11} + f_{00}}{n} = \\frac{f_{11} + f_{00}}{f_{11} + f_{10} + f_{01} + f_{00}} \\\\\n  \\text{Felkvot} &= \\frac{f_{10} + f_{01}}{n} = \\frac{f_{10} + f_{01}}{f_{11} + f_{10} + f_{01} + f_{00}} = 1 - \\text{Träffsäkerhet} \\\\\n\\end{aligned}\n\\] När träffsäkerheten i modellen är hög kommer felkvoten vara låg och vice versa vilket gör att endast ett av dessa mått egentligen behöver beräknas. Problemet med att bara använda dessa mått som en indikation på modellens prestanda är att de lätt kan missa att modellen fokuserar sin anpassning på att prediktera en av klasserna bra. När vi arbetar med klassificering så spelar andelen av vår data som tillhör vardera klass roll, detta kallas för klassbalanser. När vi ska modellera en binär responsvariabel är det bra att först ta fram en tabell med andelen som tillhör klass 1 och andelen som tillhör klass 0 för att bilda en uppfattning om vilken och hur mycket information vi har om de båda.\nOm andelarna är balanserade, det vill säga nära 50% för de båda andelarna, kommer modellen ha lika mycket information om de båda klasserna och kan förmodligen anpassa en modell som tar hänsyn till att vi vill prediktera båda klasserna rätt. Om andelarna däremot är olika stora kommer problemet att modellera \\(P(Y = 1)\\) bli svårare, och svårighetsgraden avgörs av hur stor skillnad det är mellan andelarna. Om det är stor skillnad på andelarna säger vi att vi har obalanserade klasser vilket leder till svårigheter att hitta en bra och meningsfull modell. Exempelvis om vi har 95% 0:or och 5% 1:or kanske modellen tycker att den bästa prediktionen vi kan göra är att säga att alla observationer är 0, för då blir träffsäkerheten 95%.\nVi behöver därför titta på flera mått för att avgöra om modellen är överlag bra eller kanske bara fokuserar på att modellera den ena av klasserna. Med fokus på \\(Y = 1\\) beskriver sensitiviteten (eng. True Positive Rate, sensitivity, recall) hur stor andel av de observerade 1:orna som faktiskt också predikterades som 1:or. Motsatsen är specificiteten (eng. True Negative Rate, specificity) som beskriver hur stor andel obsrverade icke-1:or som också predikterades som icke-1:or.\n\\[\n\\begin{aligned}\n\\text{Sensitivitet} &= \\frac{f_{11}}{f_{11} + f_{10}}\\\\\n\\text{Specificitet} &= \\frac{f_{00}}{f_{01} + f_{00}}\n\\end{aligned}\n\\] Om det ena måttet är stort och det andra litet betyder det att modellen fokusera på endast någon av klasserna, medan om båda måtten är stora betyder det att modellen lyckats prediktera alla klasser lika bra.\nHur stora klassobalanser som är hanterbart avgörs dels av hur starkt sambandet mellan våra förklarande variabler och \\(Y\\) är, och dels av det totala antalet observationer som finns i data. Har vi ett starkt samband mellan våra förklarande variabler och \\(Y\\) så kan vi ha mer obalanserade klasser eftersom variablerna kan på ett bra sätt separera dem. På samma sätt, om vi har väldigt många observationer så kan vi ha mer obalanserade klasser då det ändå finns mycket information som modellen kan använda för att hitta en bra anpassning. Det är bra att beräkna sensitivitet och specificitet på tränings- och valideringsmängden för att få en förståelse för om man har problem med obalanserade klasser eller ej. Har vi problem med obalanserade klasser finns det olika metoder för det som kan användas i vissa fall, men som ligger utanför detta underlag.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistisk regression</span>"
    ]
  },
  {
    "objectID": "01-regression/10-logistic-regression.html#funktion-för-utvärdering",
    "href": "01-regression/10-logistic-regression.html#funktion-för-utvärdering",
    "title": "11  Logistisk regression",
    "section": "11.4 Funktion för utvärdering",
    "text": "11.4 Funktion för utvärdering\nVi kan skapa en funktion i R som sammanställer denna korstabell och utvärderingsmått åt oss:\n\n\nVisa kod\n## Funktion som skapar förväxlingsmatris med tillhörande mått för klassificeringsproblem\n\n# newData  : Materialet innehållande förklarande variabler \n# model    : Den skattade modellen\n# trueY    : Vektor innehållande de sanna klass-värden i samma ordning som observationerna i newData\n\nclassEvaluation &lt;- function(newData, model, trueY, type = \"class\", digits = 3){\n  # Predikterar klassen för newData givet den skattade modellen med gränsen 0.5\n  pred &lt;- ifelse(predict(model, newdata = newData, type = \"response\") &gt;= 0.5, 1, 0)\n  \n  # Konverterar de predikterade klasserna till en faktor med samma nivåer som de sanna \n  # klasserna\n  pred &lt;- factor(pred, levels = levels(factor(trueY)))\n  \n  # Skapar förväxlingsmatris med rader som indikerar sanna klassen och kolumnen som\n  # indikerar predikterade klassen\n  confusion &lt;- table(trueY, pred)\n  \n  # Träffsäkerhet är antalet korrekta prediktioner dividerat med antalet observationer\n  accuracy &lt;- sum(diag(confusion)) / sum(confusion)\n  \n  # Felkvoten är 1 - träffsäkerheten\n  misclass &lt;- 1 - accuracy\n  \n  # Sensitivitet är antalet korrekta prediktioner AV DEN NUVARANDE KLASSEN dividerat \n  # med antalet observationer AV DEN NUVARANDE KLASSEN\n  sensitivity &lt;- diag(confusion) / rowSums(confusion) \n  \n  # Specificitet är antalet korrekta prediktioner AV ICKE DEN NUVARANDE KLASSEN dividerat \n  # med antalet observationer AV ICKE DEN NUVARANDE KLASSEN\n  specificity &lt;- NULL\n  for(i in 1:nrow(confusion)){\n    specificity[i] &lt;- sum(confusion[-i, -i])/sum(confusion[-i, ])\n  }\n  \n  # Sammanställer alla resultat i en egen lista som sedan returneras\n  evaluation &lt;- list(confusionMatrix = confusion, \n                     overall = \n                       cbind(träffsäkerhet = accuracy, \n                             felkvot = misclass),\n                     classWise = \n                       rbind(sensitivitet = sensitivity,\n                             specificitet = specificity)\n  )\n  \n  return(evaluation)\n}\n\n\nMed hjälp av den skapade funktionen kan vi utvärdera modellen som anpassats på mtcars. Nu har vi endast en träningsmängd vilket innebär att utvärderingen endast kommer visa hur bra modellen är på det data den använt i sin anpassning, men ifall vi hade en valideringsmängd hade vi med funktionen kunnat lägga in valideringsmängdens data och responsvariabel i newData och trueY som också ger oss samma mått vilka vi kan använda för att bedöma modellens generaliserbarhet.\n\n\nVisa kod\nevaluation &lt;- \n  classEvaluation(\n    newData = mtcars %&gt;% \n      select(\n        mpg, cyl, hp\n      ),\n    model = model,\n    trueY = mtcars$am\n  )\n\nevaluation$confusionMatrix %&gt;% \n  kable(caption = \"Modellens förväxlingsmatris\")\n\n\n\nModellens förväxlingsmatris\n\n\n\n0\n1\n\n\n\n\n0\n17\n2\n\n\n1\n2\n11\n\n\n\n\n\nVisa kod\nevaluation$overall %&gt;% \n  kable(caption = \"Modellens övergripande mått\", col.names = c(\"Träffsäkerhet\", \"Felkvot\"), digits = 3)\n\n\n\nModellens övergripande mått\n\n\nTräffsäkerhet\nFelkvot\n\n\n\n\n0.875\n0.125\n\n\n\n\n\nVisa kod\nevaluation$classWise %&gt;% \n  kable(caption = \"Modellens klasspecifika mått\", digits = 3)\n\n\n\nModellens klasspecifika mått\n\n\n\n0\n1\n\n\n\n\nsensitivitet\n0.895\n0.846\n\n\nspecificitet\n0.846\n0.895\n\n\n\n\n\nI förväxlingsmatrisen ser vi att vi fått majoriteten av observationerna i diagonalen, det vill säga korrekta prediktioner. Träffsäkerheten är 87.5% vilket är högt, men det är fortfarande ett antal observationer som predikterats fel. Det är dock betydligt bättre än att slumpmässigt gissa sig till klassen (50%) vilket indikerar på att modellens förklarande variabler faktiskt bidrar till responsvariabeln. De klasspecifika måtten är jämna, 85-90% för respektive vilket antyder att modellen är lika bra på att prediktera klass 1 som den är att prediktera klass 0.\nOm vi har dålig anpassning på träningsdata så har vi troligen valt en felaktig eller för enkel modell till exempel att vi inte har med rätt förklarande variabler i modellen. Det kan också vara så att det finns en stor grad av slumpmässighet i vår responsvariabel, det vill säga att vi har mycket brus i data, vilket kan göra att det är svårt att hitta en bra modell. Vi kan tänka oss ett scenario där \\(\\pi_i\\) alltid ligger runt 0.5, oavsett värden på alla potentiella förklarande variabler vilket leder till att vår modell inte kan bli bättre än slumpmässig gissning av klasserna 0 och 1.\nOm våra utvärderingsmått är allmänt dåliga så är det inte relevant att göra vidare analyser med modellen, t.ex. undersöka vilka variabler som är signifikanta. Detta gäller speciellt om sensitivitet eller specificitet är nära noll på träningsdata. Då har vi klassificerat alla (eller nästan alla) observationer till endast en klass, och vår modell har inte förmågan att särskilja de två klasserna i responsvariabeln.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistisk regression</span>"
    ]
  },
  {
    "objectID": "01-regression/10-logistic-regression.html#likelihoodkvottest",
    "href": "01-regression/10-logistic-regression.html#likelihoodkvottest",
    "title": "11  Logistisk regression",
    "section": "11.5 Likelihoodkvottest",
    "text": "11.5 Likelihoodkvottest\nYtterligare en metod vi kan använda att utvärdera modeller, utöver förväxlingsmatrisen och dess mått eller AIC, är modellens likelihood. Likt när vi jämför den förklarande variationen mellan modeller i linjär regression kan vi anse en skillnad i likelihood beskriva hur mycket en eller flera variabler tillför till modellen, och likt ett partiellt F-test kan vi genomföra inferens på denna skillnad i likelihood.\nHypoteserna som undersöks formuleras på samma sätt som i ett partiellt F-test, i \\(H_0\\) anges de alla lika med 0 och mothypotesen är att minst en av parametrarna är signifikant skild från 0. Vi kan därefter definiera en komplett och reducerad modell som båda har ett tillhörande likelihood-värde, alltså hur troligt modellens parametrar har genererat det observerade data. Om vi sedan jämför dessa två likelihood får vi en bedömning av hur stor skillnaden är i relation till den kompletta modellens värde, därav namnet likelihoodkvottest (eng. Likelihood ratio test).\n\\[\n\\begin{aligned}\n  LR_{test} = -2 \\ln \\left(\\frac{L_R}{L_F}\\right) = -2 \\ln L_R - (-2 \\ln L_F)\n\\end{aligned}\n\\] där \\(L_R\\) och \\(L_F\\) kommer från den reducerade respektive kompletta modellen.\nI R kan vi ta ut loglikelihooden från en anpassad modell med funktionen logLik() vilket skulle motsvara \\(\\ln(L_R)\\) och \\(\\ln(L_F)\\) i formeln. Statistikan anses vara \\(\\chi^2\\)-fördelad med ‘antalet parametrar som undersöks’ frihetsgrader.\n\n\nVisa kod\n# En reducerad modell med två färre variabler\nmodel2 &lt;- glm(am ~ mpg, data = mtcars, family = \"binomial\")\n\n# Beräkning av teststatistikan, c() används för att endast plocka ut värdet av statistikan inte andra termer från logLik()\nLR &lt;- (-2*logLik(model2) - (-2*logLik(model))) %&gt;% c()\n\n# Beräkning av p-värdet\npValue &lt;- pchisq(q = LR, df = 2, lower.tail = FALSE)\n\n\nP-värdet för testet är 0.0035 vilket är mindre än en signifikansnivå på 5 procent och medför att vi kan förkasta \\(H_0\\). De två variabler som undersöks har minst en som bidrar med en signifikant effekt på responsvariabeln.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistisk regression</span>"
    ]
  },
  {
    "objectID": "01-regression/10-logistic-regression.html#footnotes",
    "href": "01-regression/10-logistic-regression.html#footnotes",
    "title": "11  Logistisk regression",
    "section": "",
    "text": "Detta gäller också för litteratur om regression och statistik i allmänhet. I de mer ovanliga fall när logaritmer med andra baser används brukar det anges explicit, ex. \\(log_2(x)\\).↩︎\nVi antar att vi summerar uttrycket först över alla 1:or med tillhörande sannolikhet \\(\\pi\\).↩︎\nEn algoritm som använder andraderivator för att succestivt hitta bättre värden för \\(\\boldsymbol{\\beta}\\). För mer detaljer, se .↩︎\nVi kan också använda att \\(Z^2 \\approx \\chi^2_{df = 1}\\) om \\(n\\) är stor.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Logistisk regression</span>"
    ]
  },
  {
    "objectID": "01-regression/11-other-link-functions.html",
    "href": "01-regression/11-other-link-functions.html",
    "title": "12  Andra länkfunktioner",
    "section": "",
    "text": "12.1 Multinomial logistisk regression\nPå samma sätt som logitlänken kan användas för att transformera den linjära regressionsmodellen till en logistisk regressionsmodell när vi vill anpassa en binär responsvariabel kan andra länkfunktioner användas om responsvariabeln är av en annan typ eller följer en annan skala.\nOm responsvariabeln är kategorisk men innehåller fler än två klasser kan vi utöka den logistiska regressionsmodellen till att hantera flera kategorier. Multinomial eller polytom logistisk regression används om responsvariabeln följer nominalskala, alltså kategorier som inte går att rangordna.\nBinär logistisk regression modellerar \\(\\pi = P(Y = 1)\\) vilket också innebär att vi på ett enkelt sätt får \\(P(Y = 0)\\) med hjälp av komplementregeln, \\(1 - \\pi\\). Nu när vi har \\(J\\) kategorier av responsvariabeln kan måste vi modellera flera sannolikheter för att täcka alla möjliga utfall. Summan av dessa sannolikheter måste bli 1 då de beskriver sannolikhetsfördelningen av Y.\n\\[\n\\begin{aligned}\n  P(Y = 0|\\mathbf{X}) \\quad P(Y=1|\\mathbf{X}) \\quad \\dots \\quad P(Y=J-1|\\mathbf{X})\n\\end{aligned}\n\\] Vi kan därefter anpassa \\(J-1\\) olika logitlänkar där samma referenskategori, ofta \\(P(Y = 0)\\), används för respektive “binära” jämförelser:\n\\[\n\\begin{aligned}\n\\frac{P(Y=1|\\mathbf{X})}{P(Y = 0|\\mathbf{X})} \\quad \\frac{P(Y=2|\\mathbf{X})}{P(Y = 0|\\mathbf{X})} \\quad \\dots\n\\end{aligned}\n\\]",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Andra länkfunktioner</span>"
    ]
  },
  {
    "objectID": "01-regression/11-other-link-functions.html#multinomial-logistisk-regression",
    "href": "01-regression/11-other-link-functions.html#multinomial-logistisk-regression",
    "title": "12  Andra länkfunktioner",
    "section": "",
    "text": "12.1.1 Modellanpassning\nI R kan vi modellera en multinomial logistisk modell med multinom från paketet nnet. Anta att vi vill anpassa en modell som beskriver hur olika egenskaper kan prediktera pingviners art.\n\nmodel &lt;- multinom(species ~ bill_length_mm, data = penguins)\n\n\n\nVisa kod\nsummary(model) %&gt;% \n  coef() %&gt;% \n  kable(digits = 3, caption = \"Modellens skattade koefficienter.\")\n\n\n\nModellens skattade koefficienter.\n\n\n\n(Intercept)\nbill_length_mm\n\n\n\n\nChinstrap\n-55.766\n1.266\n\n\nGentoo\n-49.258\n1.143\n\n\n\n\n\nEftersom att flera parameterskattningar fås för varje jämförelse kan utskrifter väldigt snabbt bli svåra att läsa av. Varje rad beskriver de tillhörande parametrarna för den angivna kategorin jämfört med referensgruppen, i detta fall Adelie-pingviner.\nUtskriften innehåller väldigt bristande information och vi behöver beräkna inferens manuellt efteråt med hjälp av Wald-test.\n\n\nVisa kod\n# Beräknar testvariabeln (Wald-test)\nz &lt;- summary(model)$coefficients/summary(model)$standard.errors\n\n# Beräknar dubbelsidiga p-värden\np &lt;- (1 - pnorm(abs(z), 0, 1)) * 2\n\np %&gt;% \n  kable(digits = 14, caption = \"p-värden för respektive parameter i modellen.\")\n\n\n\np-värden för respektive parameter i modellen.\n\n\n\n(Intercept)\nbill_length_mm\n\n\n\n\nChinstrap\n1.00e-14\n4.00e-14\n\n\nGentoo\n1.13e-12\n1.57e-12\n\n\n\n\n\nFör att tolka parameterskattningarna som oddskvoter behöver vi transformera de med hjälp av \\(e^{\\hat{\\beta}_j}\\).\nEn mer detaljerad genomgång av denna sorts modell kan hittas här.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Andra länkfunktioner</span>"
    ]
  },
  {
    "objectID": "01-regression/11-other-link-functions.html#ordinal-logistisk-regression",
    "href": "01-regression/11-other-link-functions.html#ordinal-logistisk-regression",
    "title": "12  Andra länkfunktioner",
    "section": "12.2 Ordinal logistisk regression",
    "text": "12.2 Ordinal logistisk regression\nIfall responsvariabeln har en ordning på sina kategorier kan vi, om lämpligt, använda ordinal logistisk regression istället där ordningen bibehålls även i modellen.\nVi kan anta att oddskvoterna är proportionella oavsett vilka kategorier av responsvariabeln som vi jämför, att oddset förändras lika mycket mellan kategori 1 och 0 som kategori 2 och 1. \\[\n\\begin{aligned}\nOdds_g &= \\frac{P(D \\ge g|\\mathbf{X})}{1 - P(D \\ge g|\\mathbf{X})}\n\\end{aligned}\n\\]\nAlla lutningsparametrar \\(\\beta_j\\) är samma för alla kategorier, men interceptet \\(\\beta_{0g}\\) är olika för varje jämförelse.\n\nEn mer detaljerad genomgång hur denna sorts modell anpassas i R ges här.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Andra länkfunktioner</span>"
    ]
  },
  {
    "objectID": "01-regression/11-other-link-functions.html#poissonregression",
    "href": "01-regression/11-other-link-functions.html#poissonregression",
    "title": "12  Andra länkfunktioner",
    "section": "12.3 Poissonregression",
    "text": "12.3 Poissonregression\nÄven om responsvariabeln är kvantitativ behöver inte alltid den linjära regressionsmodellen vara lämplig att använda, till exempel om responsvariabeln beskriver ett diskret antal kommer den linjära modellen längre anpassa rätt fördelning. Fördelen med de generaliserade linjära modellerna är att vi nu har tillgång till flexibla metoder som kan anpassa andra fördelningar av Y|X som är mer lämpliga att beskriva responsvariabelns form. Givet att responsvariabeln beskriver ett antal med en majoritet låga värden kan Poissonfördelningen vara en lämplig fördelning för modellanpassningen.\n\n\n\n\n\n\nTips\n\n\n\nPoissonfördelningen beskriver en diskret variabel, eller närmare bestämt en variabel som beskriver ett antal. Fördelningens form styrs utav dess väntevärde (\\(\\lambda\\)) som också är dess varians. Vi kan skapa ett slumpmässigt urval från en Poissonfördelning i R med hjälp av rpois().\n\n\nVisa kod\n# Anger väntevärdet\nlambda &lt;- 3\n\n# Anger antalet observationer som ska slumpas fram\nnobs &lt;- 400\n\n# Anger ett seed\nset.seed(12345)\n\n# Drar ett urval från den angivna fördelningen\ny &lt;- rpois(n = nobs, lambda = lambda)\n\n\nDen sanna Poisson-fördelningen med samma väntevärde kan beräknas utifrån dpois(). Vi kan visualisera det slumpmässiga urvalet tillsammans med den sanna fördelningen på följande sätt:\n\n\nVisa kod\n# Beräknar sannolikheter för de givna utfallen av y utifrån det angivna lambda\ntrueFreq &lt;- dpois(x = 0:max(y), lambda = lambda)\n\n# Skapar ett datamaterial för visualisering\nvisData &lt;- \n  data.frame(\n    table(y)/sum(table(y)),\n    trueFreq = trueFreq\n  )\n\n# Visualiserar fördelningen och urvalet\nggplot(visData) + aes(x = y, y = Freq) + \n  # Skapar grunden med stapel-/stolpdiagrammet\n  geom_bar(stat = \"identity\", fill = \"steelblue\") +\n  # Lägger till den sanna fördelningen som en linje\n  geom_line(aes(y = trueFreq, group = 1), linewidth = 2, color = \"#d9230f\") + \n  theme_bw()\n\n\n\n\n\nSkillnaden mellan observerade och teoretiska sannolikheter\n\n\n\n\nVi kan ändra värden på både lambda och nobs för att se hur det slumpmässiga urvalet förhåller sig till den sanna fördelningen.\n\n\nPå samma sätt som tidigare modeller vill vi anpassa \\(E[Y|X]\\) alltså väntevärdet av responsvariabelns fördelning, vilket i detta fall är \\(\\lambda\\). Vi vill fortfarande använda den linjära modellen på något sätt och vi kan därför använda loglänken för att transformera den linjära modellen till Poissonfördelningens väntevärde.\nLåt oss anta att vi vet en sann Poissonmodell med en förklarande variabel som använder sig av länkfunktionen. \\[\n\\begin{aligned}\n  \\ln(\\lambda_i) = \\beta_0 + \\beta_1 \\cdot X_i\n\\end{aligned}\n\\]\nAnta att de sanna populationsparametrarna är \\(\\beta_0 = 1\\) och \\(\\beta_1 = 0.5\\). Den sanna lutningsparametern tolkas därför som att när \\(X\\) ökar med en enhet, ökar \\(Y\\) med ungefär \\(e^{\\beta_1} = e^{0.5} = 1.65\\) gånger (eller ca \\(65\\) procent). Vi kan i R ange och skapa den sanna modellen via:\n\n\nVisa kod\n# Anger sanna värden för parametrarna i modellen\nbeta0 &lt;- 1\nbeta1 &lt;- 0.5\n\n# Anger hur många observationer som populationen innehåller\nnobs &lt;- 200\n\n# Anger ett seed\nset.seed(42)\n\n# Slumpar fram populationen av den *förklarande* variabeln utifrån angivna \n# min/max begränsningar\nx &lt;- runif(n = nobs, min = 0, max = 5)\n\n\n# Skapar populationens sanna lambda givet den modell som definierats\nlambdaTrue &lt;- exp(beta0 + beta1*x)\n\n\n# Drar ett slumpmässigt urval för varje enhet givet dess väntevärde\ny &lt;- rpois(n = nobs, lambda = lambdaTrue)\n\n\nObjektet lambdaTrue innehåller nu populationens sanna väntevärden och vi kan använda dessa för att dra ett slumpmässigt urval av Y för respektive observation. Detta blir en liknande process som när vi drar ett slumpmässigt urval från en Poissonfördelning med ett angivet väntevärde men när vi nu har mer information om observationerna, mer specifikt deras förklarande variabler utgår vi från \\(Y_i | X_i \\sim Po(\\lambda_i)\\) där varje observation har ett specifikt värde på \\(X\\), och därav får ett eget väntevärde \\(\\lambda_i\\). Detta motsvarar att vi i den linjära modellen antar att \\(Y_i | X_i \\sim N(\\mu_i)\\) och vi modellerar ett väntevärde på \\(Y\\) beroende på det angivna värdet på den förklarande variabeln.\nVi kan anpassa en Poissonmodell och visa de anpassade parametrarna:\n\n\nVisa kod\n# Anpassar Poissonmodellen\nmodel &lt;- glm(y ~ x, family = \"poisson\")\n\nsummary(model) %&gt;% \n  coef() %&gt;% \n  kable(digits = 3, caption = \"Modellens skattade koefficienter.\", col.names = c(\"Variabel\", \"Skattning\", \"Medelfel\", \"z-värde\", \"p-värde\"))\n\n\n\nModellens skattade koefficienter.\n\n\nVariabel\nSkattning\nMedelfel\nz-värde\np-värde\n\n\n\n\n(Intercept)\n0.870\n0.064\n13.541\n0\n\n\nx\n0.527\n0.017\n30.756\n0\n\n\n\n\n\n\n\n\n\n\n\nViktigt\n\n\n\nLikt för logistisk regression kommer denna modell anpassas med hjälp av optimering och vi måste därför säkerställa att modellen konvergerat. R producerar varnings- eller felmeddelanden när detta inte sker, så var uppmärksam!\n\n\nDen anpassade lutningsparametern tolkas som att när X ökar med en enhet ökar Y med \\(e^{0.527} = 1.694\\) gånger, eller ungefär 69.4 procent.\n\n12.3.1 Inferens\nOm vi vill jämföra en skattad koefficient med det sanna värdet (som vi i detta fall vet om), bör vi intervallskatta koefficienten och i detta fall kan vi se om det sanna värdet täcks av intervallet. Som alla andra konfidensintervall använder vi samma grundstruktur: \\(\\text{punktskattning} \\pm \\text{tabellvärde} \\cdot \\text{medelfel}\\). För ‘stora’ urval antar vi att ML skattningarna är approximativt normalfördelade1 vilket innebär att tabellvärdet i intervallskattningen tas från den standardiserade normalfördelningen. Både punktskattningen och medelfelet kan hittas i koefficienttabellen. \\[\n\\begin{aligned}\n  \\hat{\\beta} \\pm Z_{1-\\alpha/2} \\cdot S_{\\hat{\\beta}}\n\\end{aligned}\n\\]\nFör att tolka detta intervall behöver det transformeras med \\(e^{x}\\) på samma sätt som vi transformerar koefficienten för att tolka den. Vanligtvis brukar man därför beräkna: \\[\n\\begin{aligned}\n  e^{\\hat{\\beta} \\pm Z_{1-\\alpha/2} \\cdot S_{\\hat{\\beta}}}\n\\end{aligned}\n\\]\nFör den anpassade modellen får vi följande intervall: \\[\n\\begin{aligned}\ne^{0.52711 - 1.96 \\cdot 0.01714} \\le &e^{\\beta_1} \\le e^{0.52711 + 1.96 \\cdot 0.01714}\\\\\n  e^{0.4935179} \\le &e^{\\beta_1} \\le e^{0.5607021}\\\\\n  1.638 \\le &e^{\\beta_1} \\le 1.752\n\\end{aligned}\n\\] Med 95 procents säkerhet täcker intervallet 1.64 till 1.75 den sanna procentuella förändringen på Y när X ökar med en enhet.\n\n\n12.3.2 Prediktioner\nAnta att de 200 observationer som vi simulerade tidigare i detta kapitel innehåller information om sambandet mellan produktionstiden (\\(X\\)) i timmar för 1000 leksaker och antalet defekta leksaker (\\(Y\\)) som identifierats efter produktionen slutförts. Varje observation beskriver en produktion av 1000 leksaker där sannolikheten att producera en defekt leksak är väldigt låg och antalet leksaker som produceras är många. Detta är per definition en Poissonfördelad variabel. Vi vill nu kunna använda den anpassade modellen för att prediktera hur många defekta leksaker som vi kan förvänta oss givet en viss produktionstid.2\nPå samma sätt som när vi vill tolka \\(\\beta\\) måste prediktioner transformeras utifrån länk-funktionen för att vi ska kunna tolka dem. Vi kan beräkna en prediktion från modellen enligt: \\[\n\\begin{aligned}\n  \\lambda_i = e^{\\hat{\\beta}_0 + \\hat{\\beta}_1 \\cdot X^*}\n\\end{aligned}\n\\] där \\(X^*\\) är antalet timmar produktionen har tagit och vi vill prediktera. predict() i R beräknar prediktioner utifrån en angiven modell, men vi måste för modeller som använder sig utav länkfunktioner ange vilken form vi vill beräkna prediktionen.\n\n\nVisa kod\n# Generar log(lambda)\npredict(model, type = \"link\") %&gt;% \n  head() %&gt;% \n  kable(digits = 3, caption = \"Modellens anpassade log(lambda).\")\n\n\n\nModellens anpassade log(lambda).\n\n\nx\n\n\n\n\n3.281\n\n\n3.340\n\n\n1.624\n\n\n3.059\n\n\n2.561\n\n\n2.238\n\n\n\n\n\nVisa kod\n# Generar lambda\npredict(model, type = \"response\") %&gt;% \n  head() %&gt;% \n  kable(digits = 3, caption = \"Modellens anpassade väntevärde.\")\n\n\n\nModellens anpassade väntevärde.\n\n\nx\n\n\n\n\n26.603\n\n\n28.211\n\n\n5.074\n\n\n21.300\n\n\n12.953\n\n\n9.376\n\n\n\n\n\nYtterligare ett argument i denna funktion är newdata. Om inte detta argument anges får vi endast ut anpassade värden för datamaterialet som modellen anpassats för.\n\n\nVisa kod\n# Skapar ny data\nnewData &lt;- data.frame(x = 4)\n\n# Genererar prediktioner på den nya observationen\npred &lt;- predict(model, newdata = newData, type = \"response\")\n\n\nMed hjälp av den anpassade modellen, och argumentet type = \"response\", kan vi säga att vi förväntar oss att om det tar 4 timmar att tillverka 1000 leksaker så kommer ca 20 stycken vara defekta.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Andra länkfunktioner</span>"
    ]
  },
  {
    "objectID": "01-regression/11-other-link-functions.html#referenser",
    "href": "01-regression/11-other-link-functions.html#referenser",
    "title": "12  Andra länkfunktioner",
    "section": "12.4 Referenser",
    "text": "12.4 Referenser\n\n\n\n\nKleinbaum, D. G., L. L. Kupper, A. Nizam, och E. S. Rosenberg. 2013. Applied Regression Analysis and Other Multivariable Methods. Cengage Learning. https://books.google.se/books?id=v590AgAAQBAJ.",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Andra länkfunktioner</span>"
    ]
  },
  {
    "objectID": "01-regression/11-other-link-functions.html#footnotes",
    "href": "01-regression/11-other-link-functions.html#footnotes",
    "title": "12  Andra länkfunktioner",
    "section": "",
    "text": "Se kapitel 21.3 i Kleinbaum m.fl. (2013)↩︎\nKanske att modellen beskriver ett fenomen där en längre produktionstid innebär att någonting gått fel i processen som riskerar att skapa defekta leksaker.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL II - Regressionsanalys**",
      "<span class='chapter-number'>12</span>  <span class='chapter-title'>Andra länkfunktioner</span>"
    ]
  },
  {
    "objectID": "02-variance/index.html",
    "href": "02-variance/index.html",
    "title": "Förord",
    "section": "",
    "text": "Till denna del förutsätts att du har vissa förkunskaper för att ta till dig materialet på bästa sätt. Utöver förkunskaper från tidigare delar bör du nu också kunna:\nStatistik\n\nidentifiera variabler för regressionsmodellering\nanpassa regressionsmodeller med kvantitativa och kvalitativa förklarande variabler\nutvärdera lämpligheten i en regressionsmodell med hjälp av residualanalys och utvärderingsmått\ngenomföra inferens på hela och delar av en regressionsmodell\nidentifiera avvikande och inflytelserika observationer\nförstå konceptet bakom simultan inferens\nförstå innebörden av en interaktion mellan två eller fler variabler\n\nKänner du att du saknar vissa av dessa kunskaper, titta tillbaka på tidigare material innan du går vidare.\nFör alla dessa kapitel förutsätts att du har laddat paketet tidyverse som innehåller flera paket såsom readr, dplyr, ggplot2 med flera. Andra paket kan behövas installeras och laddas för olika kapitel men detta bör anges specifikt.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "Förord"
    ]
  },
  {
    "objectID": "02-variance/00-oneway-anova.html",
    "href": "02-variance/00-oneway-anova.html",
    "title": "13  Introduktion till variansanalys",
    "section": "",
    "text": "13.1 Envägs-ANOVA\nI Kapitel 1 studerade vi förhållandet mellan en responsvariabel och en eller flera förklarande variabler. Om en förklarande variabel är kvalitativ transformerade vi variabeln till indikatorvariabler för att kunna matematiskt hantera variabeln på ett korrekt sätt.\nOm en regressionsmodell endast skulle bestå utav kvalitativa variabler är regressionsmodellen ekvivalent med att jämföra medelvärden för varje värde av den kvalitativa variabeln. Att undersöka flera medelvärden med varandra kan också kallas för variansanalys och används ofta inom experimentella studier. I variansanalys kallas de förklarande variablerna för faktorer och dess kategorier för faktornivåer.\nEn regressionsmodell med en kontinuerligt kvantitativ responsvariabel och en kvalitativ faktor (förklarande variabel) kallas för en envägs-ANOVA. Eftersom detta är i grunden en regressionsmodell kan vi formulera modellen som vi gjort i del II:\n\\[\n\\begin{aligned}\n  Y_{ij} = \\beta_0 + \\beta_1 \\cdot X_{1j} + \\dots + \\beta_{A-1}\\cdot X_{(A-1)j} + E_{ij}\n\\end{aligned}\n\\] där\nNär alla indikatorvariabler är 0 identifieras den sista kategorin \\(i = A\\).\nI praktiken kommer denna modell prediktera ett och samma värde för varje observation som har samma nivå av faktorn eftersom högst en indikatorvariabel kan vara 1 och ge en effekt av det tillhörande \\(\\beta_i\\) på det anpassade värdet. Detta anpassade värde kommer beskriva respektive nivås medelvärde enligt:\n\\[\n\\begin{aligned}\nY_{i = 1} &= \\mu_1 = \\beta_0 + \\beta_1 \\\\\nY_{i = 2} &= \\mu_2 = \\beta_0 + \\beta_2 \\\\\n&\\vdots \\\\\nY_{i = A-1} &= \\mu_{A-1} = \\beta_0 + \\beta_{A-1} \\\\\nY_{i = A} &= \\mu_A = \\beta_0\n\\end{aligned}\n\\]\nI och med att en ANOVA-modell endast är ett specialfall av linjär regression gäller fortfarande att \\(E_{ij} \\sim N(0, \\sigma^2)\\) och att modellen bör utvärderas med hjälp av residualanalys från Kapitel 4 innan vi går vidare till inferensmetoder.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduktion till variansanalys</span>"
    ]
  },
  {
    "objectID": "02-variance/00-oneway-anova.html#envägs-anova",
    "href": "02-variance/00-oneway-anova.html#envägs-anova",
    "title": "13  Introduktion till variansanalys",
    "section": "",
    "text": "\\(j\\) är observationsindex som går mellan 1:\\(n_i\\) där \\(n_i\\) är antalet observationer inom nivå \\(i\\) av faktorn,\n\\(A\\) är antalet nivåer av faktorn,\nrespektive \\(X_{ij}\\) är indikatorkodade variabler som indikerar på nivå \\(i\\) av faktorn.\n\n\n\n\n\n\n\n\nNotera\n\n\n\nTill skillnad från den vanliga regressionsmodellen har \\(Y\\) nu fått två index, en för nivån av faktorn och en för observationerna inuti faktorn. Vi kommer se flera modeller inom variansanalys där vi ytterligare utökar index men det vi kan ha i åtanke är att det sista indexet alltid kommer vara observationsindex.\n\n\n\n\n\n\n\n\n\n\nNotera\n\n\n\nInom variansanalys kan denna sorts modell direkt modelleras utefter respektive nivås medelvärden istället för regressionsmodellen. Detta kallas för en cellmedelvärdesmodell som beräknar medelvärdet för varje cell av data, i envägs-ANOVA innebär detta för varje faktornivå.\n\\[\n\\begin{aligned}\nY_{ij} = \\mu_i + E_{ij}\n\\end{aligned}\n\\] där \\(j\\) är observationsindex och \\(\\mu_i\\) är cellmedelvärdet för nivå \\(i\\) av faktorn.\n\n\n\n\n13.1.1 Faktoreffektkodning av kvalitativa variabler\nEtt alternativt sätt att koda en kvalitativ variabel är att använda faktoreffektkodning. Istället för att parametern vid indikatorkodning mäter varje nivås effekt jämfört med en referenskategori, som i många fall väljs godtyckligt och påverkar varje parametervärde därefter, mäter parametern vid faktoreffektkodning effekten jämfört med det övergripande medelvärdet.\n\\[\n\\begin{aligned}\n  Y_{ij} = \\mu + \\beta_1 \\cdot X_{1j} + \\dots + \\beta_{A-1}\\cdot X_{(A-1)j} + E_{ij}\n\\end{aligned}\n\\tag{13.1}\\] där\n\n\\(\\mu\\) är det oviktade medelvärdet av \\(Y_{ij}\\) enligt: \\[\n\\begin{aligned}\n\\mu &= \\frac{\\mu_1 + \\mu_2 + \\cdots + \\mu_A}{A}\n\\end{aligned}\n\\]\n\\(\\beta_i\\) är skillnaden/effekten av nivå \\(i\\) på det övergripande medelvärdet \\(\\mu\\) enligt: \\[\n\\begin{aligned}\n  \\beta_i = \\mu_i - \\mu\n\\end{aligned}\n\\]\n\\(X_{ij}\\) är en faktoreffektkodad variabel enligt: \\[\n\\begin{aligned}\n  X_{ij} =\n  \\begin{cases}\n      1 \\quad &\\text{om nivå i}\\\\\n      -1      &\\text{om nivå A}\\\\\n      0       &\\text{annars}\n  \\end{cases}\n\\end{aligned}\n\\]\n\nMed hjälp av denna kodning kan vi beräkna fram nivå \\(A\\)s effekt som den negativa summan av de övriga parametrarna trots att den inte anges direkt i modellen.\n\\[\n\\begin{aligned}\n  \\beta_A = -(\\beta_1 + \\beta_2 + \\cdots + \\beta_{A-1}) = \\mu_A - \\mu\n\\end{aligned}\n\\]\n\n\n\n\n\n\nNotera 13.1\n\n\n\nViss litteratur börjar vid dessa modeller att byta beteckningar på parametrarna. Till exempel använder Kleinbaum m.fl. (2013) \\(\\alpha_i\\) som beteckning för faktoreffekten av nivå \\(i\\) och undviker att visa indikator/effektkodade variabler istället för att fortsätta med regressionsmodellens beteckningar. Detta underlag kommer bibehålla användandet av \\(\\beta\\) men beskriva parametrar och tillhörande variabler så att det går att tydligt särskilja modeller från varandra.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduktion till variansanalys</span>"
    ]
  },
  {
    "objectID": "02-variance/00-oneway-anova.html#analys-av-metoder-för-ogräsbekämpning",
    "href": "02-variance/00-oneway-anova.html#analys-av-metoder-för-ogräsbekämpning",
    "title": "13  Introduktion till variansanalys",
    "section": "13.2 Analys av metoder för ogräsbekämpning",
    "text": "13.2 Analys av metoder för ogräsbekämpning\nAnta att experiment genomförst som undersöker hur olika ogräsbekämpningar i Etiopien påverkar skörden av durra (i kg per hektar). Mer specifikt är de olika bekämpningsmetoderna:\n\n1 - Hacka, 1 ggr (hacka för hand en gång, fyra veckor efter att första grödan grott)\n2 - Hacka, 2 ggr (hacka för hand två gånger, fyra och åtta veckor efter att första grödan grott)\n3 - Samodling med kikärter (kikärter agerar som en täckningsgröda som motverkar tillväxten av ogräs)\n4 - Samodling med kikärter, hacka 1 ggr (kombination av samodling och hacka för hand en gång, fyra veckor efter att första grödan grott)\n5 - Ogräsfri kontroll (konstant bekämpning av ogräs med hacka)\n6 - Ingen bekämpning\n7 - Herbicid (ogräsmedlet 2,4-D appliceras sex veckor efter att första grödan grott)\n\nDatamaterialet kan laddas ner här. Mer information om detta material finns att läsa via denna länk.\nVi kan läsa in datamaterialet till R och döpa om variablerna till enklare namn för att underlätta vår senare kodning. Vi måste också säkerställa att faktorn av intresse också kodas som en kategorisk variabel i R.\n\nweeds &lt;- read.csv2(\"DIN SÖKVÄG/weeds.csv\") %&gt;% \n  rename(\n    metod = 1,\n    skörd = 2\n  ) |&gt; \n  # Måste säkerställa att den kvalitativa variabeln är en faktor\n  mutate(\n    metod = as.factor(metod)\n  )\n\nFör att få en bild av materialet och responsvariabeln uppdelat på de olika faktornivåerna kan vi visualisera responsvariabelns fördelning med grupperade histogram, lådagram eller fioldiagram.\n\n\nVisa kod\nweeds %&gt;% \n  ggplot() + aes(x = metod, y = skörd) + geom_boxplot(fill = \"steelblue\") +\n  theme_bw()\n\n\n\n\n\nFördelningen av skörd uppdelat på de olika bekämpningsnivåerna\n\n\n\n\nVi kan i visualiseringen se att den uppmätta skörden skiljer sig åt mellan de olika bekämpningsmetoderna.\nAnta att vi använder faktoreffektkodning för att skapa följande modell som ska anpassas: \\[\n\\begin{aligned}\n    Y_{ij} = \\mu + \\beta_1 \\cdot X_{1j} + \\beta_{2}\\cdot X_{2j} +\\dots + \\beta_{6}\\cdot X_{6j} + E_{ij}\n\\end{aligned}\n\\tag{13.2}\\] där \\[\n\\begin{aligned}\n    \\mu &= \\frac{\\mu_1 + \\mu_2 + \\dots + \\mu_6 + \\mu_7}{7} \\\\\n    X_{1j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om bekämpningsmetod 1}\\\\\n        -1      &\\text{om bekämpningsmetod 7}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    X_{2j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om bekämpningsmetod 2}\\\\\n        -1      &\\text{om bekämpningsmetod 7}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    X_{3j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om bekämpningsmetod 3}\\\\\n        -1      &\\text{om bekämpningsmetod 7}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    X_{4j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om bekämpningsmetod 4}\\\\\n        -1      &\\text{om bekämpningsmetod 7}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    X_{5j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om bekämpningsmetod 5}\\\\\n        -1      &\\text{om bekämpningsmetod 7}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    X_{6j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om bekämpningsmetod 6}\\\\\n        -1      &\\text{om bekämpningsmetod 7}\\\\\n        0       &\\text{annars}\n    \\end{cases}\n\\end{aligned}\n\\] och \\(E_{ij} \\sim N(0, \\sigma^2)\\).\n\n13.2.1 Kodning av faktorer\nEftersom standard i R är att koda kategoriska variabler med indikatorkodning (1/0) behöver vi först göra ytterligare ett steg innan vi anpassar modellen. R har flera sätt att ange hur en kategorisk variabel kodas, standard är att i bakgrunden köra contr.treatment(A) där A är antalet nivåer av faktorn.\n\ncontr.treatment(7)\n\n  2 3 4 5 6 7\n1 0 0 0 0 0 0\n2 1 0 0 0 0 0\n3 0 1 0 0 0 0\n4 0 0 1 0 0 0\n5 0 0 0 1 0 0\n6 0 0 0 0 1 0\n7 0 0 0 0 0 1\n\n\nDen resulterande matrisen visar strukturen för hur R indikatorkodar en faktor, där den första nivån blivit referenskategorin (alla kolumner är 0) och A-1 indikatorvariabler skapas.\nOm vi vill använda effektkodning behöver vi spara denna information i dataobjektet. Strukturen vi följer är att använda contrasts(variabel) &lt;- kodning. Effektkodning anges med hjälp av contr.sum(A).\n\ncontr.sum(7)\n\n  [,1] [,2] [,3] [,4] [,5] [,6]\n1    1    0    0    0    0    0\n2    0    1    0    0    0    0\n3    0    0    1    0    0    0\n4    0    0    0    1    0    0\n5    0    0    0    0    1    0\n6    0    0    0    0    0    1\n7   -1   -1   -1   -1   -1   -1\n\n\nvars struktur kan sparas i dataobjektet genom:\n\ncontrasts(weeds$metod) &lt;- contr.sum(7)\n\nMed effektkodning blir den sista nivån angiven som “den saknade” vilket nu stämmer överens med Ekvation 13.2. R kommer nu använda denna kodning när den linjära modellen anpassas.\n\n\n13.2.2 Modellanpassning\nEftersom envägs-ANOVA endast är ett specialfall av en regression används lm() för att anpassa modellen.\n\n\nVisa kod\nmodel &lt;- lm(skörd ~ metod, data = weeds)\n\nmodel %&gt;% \n  summary() %&gt;% \n  coef() %&gt;% \n  kable(digits = 3, caption = \"Modellens koefficienter\")\n\n\n\nModellens koefficienter\n\n\n\nEstimate\nStd. Error\nt value\nPr(&gt;|t|)\n\n\n\n\n(Intercept)\n998.119\n83.006\n12.025\n0.000\n\n\nmetod1\n-95.119\n203.323\n-0.468\n0.645\n\n\nmetod2\n500.159\n203.323\n2.460\n0.023\n\n\nmetod3\n-667.758\n203.323\n-3.284\n0.004\n\n\nmetod4\n90.214\n203.323\n0.444\n0.662\n\n\nmetod5\n1070.881\n203.323\n5.267\n0.000\n\n\nmetod6\n-625.619\n203.323\n-3.077\n0.006\n\n\n\n\n\nVi kan presentera modellens koefficienter i en tabell men eftersom kodningen har ändrats gentemot tidigare modeller, behöver vi också justera tolkningen. Till exempel får vi att den genomsnittliga skörden oavsett metod är ca 998.119 kg/hektar och metod 1 får i genomsnitt 95.119 kg/hektar mindre skörd än genomsnittet. Metod 7s effekt kan beräknas genom den negativa summan av alla lutningskoefficienter till -272.758 kg/hektar.\n\n\n\n\n\n\nNotera\n\n\n\nDet finns ett alternativt sätt att anpassa just en ANOVA-modell, genom att använda funktionen aov(). aov() är egentligen bara en kombination av lm() och anova() där objektet fokuserar på att presentera ANOVA-tabellen istället för koefficienterna. Andra paket och funktioner än vad som tas upp i detta kapitel inom variansanalys kan ibland förutsätta att vi skapat ett aov-objekt istället för ett lm-objekt.\n\n\nModellens predikterade värden kommer representera medelvärdesskattningar för respektive nivå och dessa kan beräknas enkelt med hjälp av paketet emmeans. Följande medelvärden beräknas:\n\\[\n\\begin{aligned}\n    \\hat{\\mu}_1 &= \\hat{\\mu} + \\beta_1\\\\\n    \\hat{\\mu}_2 &= \\hat{\\mu} + \\beta_2\\\\\n    &\\quad\\vdots\\\\\n    \\hat{\\mu}_6 &= \\hat{\\mu} + \\beta_6\\\\\n    \\hat{\\mu}_7 &= \\hat{\\mu} - \\sum_{i = 1}^{A-1}\\beta_i\n\\end{aligned}\n\\]\n\n\nVisa kod\nrequire(emmeans)\n\n# Anger vilka faktorer som medelvärden ska beräknas på\nmeans &lt;- emmeans(model, specs = ~metod) \n\nmeans %&gt;% \n  kable(digits = 3, caption = \"Faktornivåernas medelvärden\", \n        col.names = c(\"Metod\", \"Faktormedelvärde\", \"Medelfel\", \"Frihetsgrader\", \"Nedre KI gräns\", \"Övre KI gräns\"))\n\n\n\nFaktornivåernas medelvärden\n\n\n\n\n\n\n\n\n\n\nMetod\nFaktormedelvärde\nMedelfel\nFrihetsgrader\nNedre KI gräns\nÖvre KI gräns\n\n\n\n\n1\n903.000\n219.614\n21\n446.287\n1359.713\n\n\n2\n1498.278\n219.614\n21\n1041.565\n1954.991\n\n\n3\n330.361\n219.614\n21\n-126.352\n787.074\n\n\n4\n1088.333\n219.614\n21\n631.620\n1545.046\n\n\n5\n2069.000\n219.614\n21\n1612.287\n2525.713\n\n\n6\n372.500\n219.614\n21\n-84.213\n829.213\n\n\n7\n725.361\n219.614\n21\n268.648\n1182.074\n\n\n\n\n\nKonfidensintervallen som beräknas i detta resultat bör inte tolkas innan en residualanalys genomförts.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduktion till variansanalys</span>"
    ]
  },
  {
    "objectID": "02-variance/00-oneway-anova.html#residualanalys",
    "href": "02-variance/00-oneway-anova.html#residualanalys",
    "title": "13  Introduktion till variansanalys",
    "section": "13.3 Residualanalys",
    "text": "13.3 Residualanalys\nModellens lämplighet kan utvärderas på samma sätt som linjär regression från Kapitel 4. Då modellen endast består av kategoriska nivåer och de predikterade värdena är samma för varje observation inom respektive nivå, kommer dessa observationer få samma predikterade värde, \\(\\hat{\\mu}_i\\). Residualerna kommer därför att grupperas i de olika nivåerna.\n\n\nVisa kod\nresidualPlots(model)\n\n\n\n\n\nResidualdiagram för modellen\n\n\n\n\nWarning in residualPlots.default(model, ...): No possible lack-of-fit tests\n\n\nUtöver att modellerna grupperar residualerna baseras ofta experimentella studier på ett begränsat antal observationer jämfört med observationsstudier. Detta medför att slutsatser om modellens lämplighet är ibland rätt så svåra att bedöma på grund utav det låga stickprovsantalet.\nDen största avvikelsen som kan läsas i diagrammet är antagandet om lika varians där punktsvärmen för metod 1 har betydligt mindre varians än de övriga grupperna. Detta ger en antydan till att antagandet om lika varians inte uppfylls.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduktion till variansanalys</span>"
    ]
  },
  {
    "objectID": "02-variance/00-oneway-anova.html#inferens",
    "href": "02-variance/00-oneway-anova.html#inferens",
    "title": "13  Introduktion till variansanalys",
    "section": "13.4 Inferens",
    "text": "13.4 Inferens\nFör envägs-ANOVA är vi intresserade av två aspekter; bidrar faktorn överhuvudtaget med någon effekt som kan hjälpa till att förklara responsvariabeln och i sådana fall vilken (eller vilka) nivå(er) bidrar till denna effekt.\n\n13.4.1 F-test för faktoreffekt\nEftersom modellen endast består av en enstaka faktor kan ett F-test för modellen användas för att bedöma om faktorn har någon signifikant effekt. Vi undersöker: \\[\n\\begin{aligned}\n    H_0&: \\beta_1 = \\beta_2 = \\dots = \\beta_{A-1} = 0 \\\\\n    H_A&: \\text{Minst en av } \\beta_i \\text{ i } H_0 \\ne 0\n\\end{aligned}\n\\] Oavsett vilken kodning som används för att transformera den kvalitativa variabeln kommer \\(H_0\\) beskriva fallet när det inte finns någon effekt oberoende på vilken faktornivå som observerats.\n\n\n\n\n\n\nNotera\n\n\n\nEftersom vi kan förenkla modellen till att anpassa ett medelvärde för respektive nivå kan vi också formulera hypoteserna enligt: \\[\n\\begin{aligned}\n    H_0&: \\mu_1 = \\mu_2 = \\dots = \\mu_{A-1} = \\mu_A \\\\\n    H_A&: \\text{Minst två av } \\mu_i \\text{ i } H_0 \\text{ skiljer sig åt}\n\\end{aligned}\n\\]\nEn effekt av faktorn skulle i denna formulering visas som en skillnad mellan (minst) två nivåers medelvärden. Vi skulle kunna anse denna form av hypoteser som en utveckling av jämförelser mellan två medelvärden som används i grundkurser av statistik.\n\n\nNamnet variansanalys uppkommer då vi för dessa hypotesprövningar vill jämföra varianser av olika komponenter, likt vi gjort för regressionsmodeller i Kapitel 5. Mer specifikt undersöker vi relationen mellan den förklarande variationen och den oförklarande variationen vars formler vi nu kan förenkla när vi bara har kvalitativa förklarande variabler.\nVi kan definiera följande kvadratsummor för modellen:\n\\[\n\\begin{aligned}\n  SSY &= \\sum_{i=1}^A\\sum_{j=1}^{n_i}{(Y_{ij} - \\overline{Y})^2} \\\\\n  SSR &= \\sum_{i=1}^A{n_i \\cdot (\\overline{Y}_i - \\overline{Y})^2} \\\\\n  SSE &= \\sum_{i=1}^A\\sum_{j=1}^{n_i}{(Y_{ij} - \\overline{Y}_i)^2}\n\\end{aligned}\n\\tag{13.3}\\] där:\n\nSSY beskriver den totala variationen i hela datamaterialet, avståndet mellan varje observation, \\(Y_{ij}\\), och responsvariabelns medelvärde, \\(\\overline{Y}\\).\nSSR beskriver den förklarade variationen, avståndet mellan varje nivås medelvärde, \\(\\overline{Y}_i\\), och responsvariabelns medelvärde.\nSSE beskriver den oförklarade variationen, avståndet mellan varje observation, \\(Y_{ij}\\) och dess nivås medelvärde.\n\nVi kan se det som att den totala variationen beskriver Y bara genom sitt medelvärde, den förklarade variationen beskriver Y genom grupperade medelvärden, och den oförklarade variationen beskriver variationen inom respektive nivå.\nOm \\(H_0\\) är sann betyder det att alla medelvärden är lika, eller att nivåernas effekt inte skiljer sig från det övergripande medelvärdet, \\(\\beta_i = 0 \\text{ eller } \\mu_i = \\mu\\). Detta skulle synas i kvadratsummorna som att SSR är nära 0 och att SSE i princip är lika stor som SSY. Om \\(H_0\\) inte är sann betyder det att minst två medelvärden skiljer sig åt eller att minst en av nivåernas effekt är skild från det övergripande medelvärdet. Detta skulle synas i kvadratsummorna som att SSR är stort, närmare SSY, och att SSE är litet.\nTestvariabeln för denna hypotesprövning blir då en jämförelse mellan SSR och SSE enligt: \\[\n\\begin{aligned}\n  F_{test} = \\frac{SSR / df_R}{SSE / df_E} = \\frac{MSR}{MSE}\n\\end{aligned}\n\\] Testvariabeln anses följa F-fördelningen med \\(df_R\\) och \\(df_E\\) frihetsgrader. Tänk på att dessa tester alltid är enkelsidiga vilket innebär att vi letar upp kritiska värden till höger av fördelningen.\n\n13.4.1.1 Interaktiv visualisering\nI följande interaktiva visualisering simuleras ett urval av en kontinuerlig responsvariabel uppdelat på fyra olika nivåer. I menyn till vänster kan vi styra vilket medelvärde i populationen som respektive nivå har och visualiseringen till höger visar fördelningen av simulerade utfallet med ett histogram. Visualiseringarna innehåller också två linjer, en heldragen röd för det övergripande medelvärdet och streckade svarta linjer för respektive nivås medelvärde, \\(\\hat{\\mu}_i = \\overline{Y}_i\\). Titta specifikt på vad som händer med kvoten mellan de två medelkvadratsummorna när det simulerade datamaterialet har lika medelvärden och när de har olika medelvärden.\n#| '!! shinylive warning !!': |\n#|   shinylive does not work in self-contained HTML documents.\n#|   Please set `embed-resources: false` in your metadata.\n#| standalone: true\n#| viewerHeight: 1000\n\nrequire(shiny)\nrequire(bslib)\nrequire(ggplot2)\nrequire(tidyverse)\nrequire(stringr)\n\n# Define UI for app that draws a histogram ----\nui &lt;- page_sidebar(\n  sidebar = sidebar(open = \"open\",\n    sliderInput(\"group_1\", \"Medelvärde för Grupp 1\", min = -10, max = 10, value = 0, step = 0.1),\n    sliderInput(\"group_2\", \"Medelvärde för Grupp 2\", min = -10, max = 10, value = 0, step = 0.1),\n    sliderInput(\"group_3\", \"Medelvärde för Grupp 3\", min = -10, max = 10, value = 0, step = 0.1),\n    sliderInput(\"group_4\", \"Medelvärde för Grupp 4\", min = -10, max = 10, value = 0, step = 0.1),\n    numericInput(\"sample_size\", \"Stickprovsstorlek\", value = 30, min = 1, step = 1),\n    actionButton(\"new_sample\", \"Klicka här för ett nytt urval.\"),\n    uiOutput(\"variances\"),\n  ),\n  plotOutput(\"plot\", height = \"600px\")\n)\n\nserver &lt;- function(input, output, session) {\n  data_input &lt;- reactive({\n    means &lt;- c(input$group_1, input$group_2, input$group_3, input$group_4)\n    seed &lt;- today() + input$new_sample\n    set.seed(seed = seed)\n    samples &lt;- sapply(means, FUN = function(x) {\n        rnorm(n = input$sample_size, mean = x, sd = 1)\n    }) %&gt;% \n      as.data.frame()\n    data_samples &lt;- pivot_longer(samples, cols = everything()) %&gt;% \n      mutate(\n        name = str_replace(name, \"V\", \"Grupp \")\n      )\n  })\n  \n  output$plot &lt;- renderPlot({\n    data_samples &lt;- data_input()\n    sample_means &lt;- aggregate(value ~ name, data_samples, mean)\n\n    ggplot(data = data_samples) + aes(x = value) + \n    geom_histogram(binwidth = 0.25, color = \"black\", fill = \"steelblue\") +\n    geom_vline(data = sample_means, aes(xintercept = value), linetype = 2, linewidth = 1.2) +\n    geom_vline(aes(xintercept = mean(value)), color = \"#d9230f\", linewidth = 1) +\n            scale_x_continuous(breaks = seq(-20, 20, by = 1)) +\n            facet_grid(rows = vars(name)) + theme_bw() +\n            theme(strip.text.y = element_text(angle = 0, color = \"white\", size = 14),\n                  strip.background.y = element_rect(fill = \"black\"),\n                  axis.title.y = element_blank()) +\n            labs(x = \"Y\") \n  })\n\n  output$variances &lt;- renderUI({\n    data_samples &lt;- data_input()\n    sample_means &lt;- aggregate(value ~ name, data_samples, mean)\n    sample_sizes &lt;- aggregate(value ~ name, data_samples, length)\n\n    SSY &lt;- sum((data_samples$value - mean(data_samples$value))^2)\n\n    SSR &lt;- sum(sample_sizes$value * (sample_means$value - mean(data_samples$value))^2)\n    MSR &lt;- SSR/(nrow(sample_means) - 1)\n\n    SSE &lt;- SSY-SSR\n    MSE &lt;- SSE/(nrow(data_samples) - nrow(sample_means))\n    \n    pvalue &lt;- pf(\n      round(MSR / MSE, 3), \n      df1 = (nrow(sample_means) - 1), \n      df2 = (nrow(data_samples) - nrow(sample_means)),\n      lower.tail = FALSE\n    )\n\n    withMathJax(\n      paste(\"$$SSY = \", round(SSY, 3), \"\\\\\\\\\",\n            \"SSR = \", round(SSR, 3), \"\\\\\\\\\",\n            \"SSE = \", round(SSE, 3), \"\\\\\\\\\",\n            \"F_{test} = \", round(MSR / MSE, 3), \"\\\\\\\\\",\n            \"\\\\text{p-värde} = \", pvalue %&gt;% round(3), \"$$\")\n    )\n  })\n}\n\n# Create Shiny app ----\nshinyApp(ui = ui, server = server)\n\n\n\n\n13.4.2 Multipla jämförelser med familjekonfidens\nOm \\(H_0\\) förkastas anser vi att faktorn i sin helhet har en signifikant påverkan på responsvariabeln men vi har ingen uppfattning om exakt vilken eller vilka nivåer som ger denna effekt och ifall nivåernas effekter skiljer sig från varandra. I många av dessa fall betyder detta att jämföra flera par av medelvärden med varandra men där vi vill kunna dra slutsatser om alla jämförelser på en och samma gång. Vi introducerade konceptet av simultan inferens i Kapitel 6 och samma lösning kan vi nu tillämpa här.\nAntalet jämförelser som ska undersökas ökar drastiskt med antalet nivåer av faktorn enligt \\(\\binom{A}{2}\\) och för att kunna genomföra en sammanfattande tolkning utan risk för ett inflaterat typ I fel använder vi en familjekonfidens.\nVi kan definiera en parvis jämförelse som \\[\n\\begin{aligned}\n  \\hat{D}_{i i'} = \\overline{Y}_{i\\cdot} - \\overline{Y}_{i'\\cdot}\n\\end{aligned}\n\\] där \\(i \\ne i'\\).\nVariansen för denna jämförelse beräknas utifrån den anpassade modellen där vi använder MSE som ett mått på modellens osäkerhet. \\[\n\\begin{aligned}\nVar(\\hat{D}_{i i'}) = MSE \\cdot \\left(\\frac{1}{n_i} + \\frac{1}{n_{i'}}\\right)\n\\end{aligned}\n\\]\nDet finns olika metoder att skapa familjekonfidensen som alla är lämpliga för olika ändamål. Vi väljer metod utifrån vilken som ger det smalaste intervallbredden givet samma valda familjekonfidensgrad.\n\n13.4.2.1 Tukey\nTukey-Kramer-metoden används för att jämföra alla parvisa skillnader mellan gruppmedelvärden efter att ett F-test för hela faktorn har visat att det finns en signfikant effekt. Tabellvärdet kan beräknas som:\n\\[\n\\begin{aligned}\n  \\hat{D}_{i i'} \\pm \\frac{q_{A; n-A; 1 - \\alpha}}{\\sqrt{2}} \\cdot \\sqrt{Var(\\hat{D}_{ii'})}\n\\end{aligned}\n\\] där \\(q_{A; n-A; 1 - \\alpha}\\) är ett tabellvärde från den studentiserade variationsviddsfördelningen (eng. Studentized range distribution) med \\(A\\) respektive \\(n-A\\) frihetsgrader.\n\n\n\n\n\n\nTips\n\n\n\nFör att förstå den studentiserade variationsvidden, anta att vi har ett urval av storlek (\\(n\\)) från var och en av (\\(A\\)) populationer med samma normalfördelning (\\(N(\\mu, \\sigma^2)\\)). Om vi antar att (\\(\\overline{Y}{\\max}\\)) är det största av dessa urvalsmedelvärden och (\\(\\overline{Y}{\\min}\\)) är det minsta, och (\\(s^2\\)) är den poolade urvalsvariansen från dessa urval, så har följande statistika en studentiserad variationsviddsfördelning:\n\\[ q = \\frac{\\overline{Y}{\\max} - \\overline{Y}{\\min}}{s / \\sqrt{n}} \\]\n\n\nOm 0 täcks av intervallet innebär det att differensen inte är signifikant skild från varandra. Tukey-metoden genererar generellt smalare intervall än övriga metoder när alla par av jämförelser ska beräknas och anses därför vara “starkare.”\nBeräkningen av dessa parvisa jämförelser är ofta tidskrävande men med hjälp av paketet emmeans kan vi använda det skapade objektet med faktornivåmedelvärden (hädanefter kallad faktormedelvärden) för att sedan undersöka alla par av medelvärden.\n\n\nVisa kod\ntukey &lt;- \n  pairs(means, adjust = \"tukey\") \n\ntukey %&gt;% \n  as_tibble() %&gt;% \n  arrange(abs(estimate) %&gt;% desc()) %&gt;% \n  kable(digits = 3, caption = \"Parvisa jämförelser av faktormedelvärden med Tukey familjekonfidens\")\n\n\n\nParvisa jämförelser av faktormedelvärden med Tukey familjekonfidens\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nmetod3 - metod5\n-1738.639\n310.581\n21\n-5.598\n0.000\n\n\nmetod5 - metod6\n1696.500\n310.581\n21\n5.462\n0.000\n\n\nmetod5 - metod7\n1343.639\n310.581\n21\n4.326\n0.005\n\n\nmetod2 - metod3\n1167.917\n310.581\n21\n3.760\n0.017\n\n\nmetod1 - metod5\n-1166.000\n310.581\n21\n-3.754\n0.017\n\n\nmetod2 - metod6\n1125.778\n310.581\n21\n3.625\n0.023\n\n\nmetod4 - metod5\n-980.667\n310.581\n21\n-3.158\n0.061\n\n\nmetod2 - metod7\n772.917\n310.581\n21\n2.489\n0.213\n\n\nmetod3 - metod4\n-757.972\n310.581\n21\n-2.440\n0.231\n\n\nmetod4 - metod6\n715.833\n310.581\n21\n2.305\n0.287\n\n\nmetod1 - metod2\n-595.278\n310.581\n21\n-1.917\n0.492\n\n\nmetod1 - metod3\n572.639\n310.581\n21\n1.844\n0.536\n\n\nmetod2 - metod5\n-570.722\n310.581\n21\n-1.838\n0.539\n\n\nmetod1 - metod6\n530.500\n310.581\n21\n1.708\n0.618\n\n\nmetod2 - metod4\n409.944\n310.581\n21\n1.320\n0.835\n\n\nmetod3 - metod7\n-395.000\n310.581\n21\n-1.272\n0.857\n\n\nmetod4 - metod7\n362.972\n310.581\n21\n1.169\n0.898\n\n\nmetod6 - metod7\n-352.861\n310.581\n21\n-1.136\n0.909\n\n\nmetod1 - metod4\n-185.333\n310.581\n21\n-0.597\n0.996\n\n\nmetod1 - metod7\n177.639\n310.581\n21\n0.572\n0.997\n\n\nmetod3 - metod6\n-42.139\n310.581\n21\n-0.136\n1.000\n\n\n\n\n\nVi kan välja att sortera de parvisa jämförelserna i storleksordning eftersom vi så småningom når en gräns där skillnaden inte längre anses vara signifikant. Tolkningen av resultatet blir då enklare eftersom vi kan lista differenserna från “metod 3 mot metod 5” till “metod 2 mot metod 6” som signifikanta på fem procents signifikans.\n\n\n13.4.2.2 Bonferroni\nUndersöker \\(g\\) jämförelser. Använder sig av t-fördelningen men signifikansnivån beräknas \\(\\alpha / g\\). Anta att vi bara vill jämföra metoderna som innehåller hackning med varandra.\n\n\nVisa kod\nselectedMeans &lt;- means[c(1, 2, 4),]\n\nbonferroni &lt;- \n  pairs(selectedMeans, adjust = \"bonferroni\")\n\nbonferroni %&gt;% \n  as_tibble() %&gt;% \n  arrange(abs(estimate) |&gt; desc()) %&gt;% \n  kable(digits = 3, caption = \"Parvisa jämförelser av utvalda faktormedelvärden med Bonferroni familjekonfidens\")\n\n\n\nParvisa jämförelser av utvalda faktormedelvärden med Bonferroni familjekonfidens\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nmetod1 - metod2\n-595.278\n310.581\n21\n-1.917\n0.207\n\n\nmetod2 - metod4\n409.944\n310.581\n21\n1.320\n0.603\n\n\nmetod1 - metod4\n-185.333\n310.581\n21\n-0.597\n1.000\n\n\n\n\n\n\n\n13.4.2.3 Scheffé\n\nVi behöver inte begränsa våra jämförelser till att endast titta på par av nivåer. \\(\\hat{D}_{ii'}\\) är ett specialfall av en kontrast där endast två nivåer jämförs men vi kan formulera en generell kontrast som: \\[\n\\begin{aligned}\n  L = \\sum_{i = 1}^A{c_i \\cdot \\mu_i}\n\\end{aligned}\n\\] där \\(\\sum{c_i} = 0\\).\nI specialfallet med en parvis jämförelse mellan exempelvis metod 1 och 2 är kontrasten: \\[\n\\begin{aligned}\n    L &= 1 \\cdot \\mu_1 + (-1) \\cdot \\mu_2 + 0 \\cdot \\mu_3 + 0 \\cdot \\mu_4 + 0 \\cdot \\mu_5 + 0 \\cdot \\mu_6 + 0 \\cdot \\mu_7 \\\\\n    &= \\mu_1 -  \\mu_2\n\\end{aligned}\n\\] där \\(c_1 = 1\\), \\(c_2 = -1\\) och resterande \\(c_i = 0\\). Detta uppfyller begränsningen på konstanterna i kontrasten.\nVi kan skapa egna kontraster av många olika former, med begränsningen att konstanterna ska summera till 0, genom contrast(). Till exempel skulle det kanske vara intressant att undersöka följande jämförelse mellan de två nivåerna som innehöll hackning och nivån beskrivande endast samodling. \\[\n\\begin{aligned}\n  L = \\frac{\\mu_1 + \\mu_2}{2} - \\mu_3\n\\end{aligned}\n\\] där \\(c_1 = c_2 = \\frac{1}{2} = 0.5\\) och \\(c_3 = -1\\).\nFrån de skattade medelvärdena kan kontrasten skattas till: \\[\n\\begin{aligned}\n    \\hat{L} &= 0.5 \\cdot 903 + 0.5 \\cdot 1498.278 - 330.361\\\\\n&= 870.278\n\\end{aligned}\n\\] där värden tas från tabellen som emmeans() producerat. Medelfelet för denna jämförelse beräknas enligt: \\[\n\\begin{aligned}\nSE_{\\hat{L}} &= \\sqrt{1.929217\\times 10^{5} \\cdot \\left( \\frac{0.5^2}{4} + \\frac{0.5^2}{4} + \\frac{(-1)^2}{4}\\right)} \\\\\n&= 268.971\n\\end{aligned}\n\\] där \\(MSE = 1.929217\\times 10^{5}\\) är tagen från ANOVA-tabellen för den anpassade modellen.\nVi antar att denna kontrast är fördelad enligt: \\[\n\\begin{aligned}\n  \\sqrt{(A-1)\\cdot F_{A-1, n - A, 1-\\alpha}}\n\\end{aligned}\n\\]\n\n\nVisa kod\n# Scheffé kontraster\ncontr &lt;- \n  contrast(\n    means, \n    # Anger konstanterna för respektive nivå i kontrasten\n    list(\n      L1 = c(0.5, 0.5, -1, 0, 0, 0, 0)\n    ),\n    # Anger vilken familjekonfidensmetod som ska genomföras\n    adjust = \"scheffe\"\n  ) \n\n# Vi behöver säga till R att vi har A-1 \"rang\"\ncontr %&gt;% \n  summary(scheffe.rank = 6) %&gt;% \n  kable(digits = 3, caption = \"Beräknad kontrast med tillhörande p-värde.\")\n\n\n\nBeräknad kontrast med tillhörande p-värde.\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nL1\n870.278\n268.971\n21\n3.236\n0.16\n\n\n\n\n\nemmeans beräknar dock kontrasterna under antagandet att det endast är de angivna kontrasterna som modellen undersöker vilket vi i vissa lägen, till exempel detta tillfälle, inte vill använda. Vi behöver då säga till R att rangen av jämförelserna är \\(A-1\\) genom argumentet scheffe.rank = 6 i summary().\nMed hjälp av skattningen och medelfelet kan vi också beräkna ett konfidensintervall enligt formler från Kleinbaum m.fl. (2013).",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduktion till variansanalys</span>"
    ]
  },
  {
    "objectID": "02-variance/00-oneway-anova.html#övningsuppgifter",
    "href": "02-variance/00-oneway-anova.html#övningsuppgifter",
    "title": "13  Introduktion till variansanalys",
    "section": "13.5 Övningsuppgifter",
    "text": "13.5 Övningsuppgifter\nDet första datamaterial som behandlas i denna övning kommer från en undersökning av olika fodertyper på 21 slumpmässigt utvalda grisar på en bondgård. Fyra stycken olika fodertyper har undersökts för att se vilken som leder till den största viktökningen (i kg) av grisarna. Materialet finns att hämta här\n\nAnpassa en envägs-ANOVA modell med hjälp av lm().\nUndersök med hjälp av ANOVA-tabellen om den genomsnittliga viktökningen är densamma för de undersökta fodertyperna.\n\nI föregående uppgift ska ni ha kommit fram till att det finns skillnad mellan minst två av de undersökta fodertyperna med avseende på genomsnittlig viktökning. Då kan det vara intressant att undersöka mellan specifikt vilka fodertyper det finns skillnad.\n\nGenomför alla multipla jämförelser med hjälp av Tukey:s metod. Orientera er i utskriften och utred mellan vilka fodertyper det är en signifikant skillnad i genomsnittlig viktökning utifrån signifikansnivå 5 procent.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduktion till variansanalys</span>"
    ]
  },
  {
    "objectID": "02-variance/00-oneway-anova.html#referenser",
    "href": "02-variance/00-oneway-anova.html#referenser",
    "title": "13  Introduktion till variansanalys",
    "section": "Referenser",
    "text": "Referenser\n\n\n\n\nKleinbaum, D. G., L. L. Kupper, A. Nizam, och E. S. Rosenberg. 2013. Applied Regression Analysis and Other Multivariable Methods. Cengage Learning. https://books.google.se/books?id=v590AgAAQBAJ.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>13</span>  <span class='chapter-title'>Introduktion till variansanalys</span>"
    ]
  },
  {
    "objectID": "02-variance/01-random-factors.html",
    "href": "02-variance/01-random-factors.html",
    "title": "14  Slumpmässiga faktorer",
    "section": "",
    "text": "14.1 Modellens formulering\nI alla tidigare regressionsmodeller förutsätter vi till viss del att de nivåer som finns i det insamlade data är de nivåer som faktorn innehåller och som vi är intresserade att dra slutsatser om, detta kallas för fixa effekter. Det finns tillfällen där vi kan vilja inkludera en faktor som endast består av ett urval av faktorns alla nivåer, till exempel hur olika skolor kan påverka prestationsgraden inom ett visst ämne. Det kan vara så att vi har en faktor i vår undersökning som har ett stort antal nivåer, fler än vi kan undersöka, och vi väljer istället att dra ett urval av nivåer från populationen av alla nivåer. Det vore omöjligt att skapa ett experiment med alla olika skolor i Sverige, så istället dras ett urval av säg 10 skolor där vår undersökning genomförs. Detta är ett exempel på en slumpmässig faktor. Med en slumpmässig faktor är vi inte intresserad av skatta effekterna för just de nivåer som vi råkade dra i vårt urval, utan vi vill dra slutsater om faktorn generellt på populationsnivå.\nDet finns flera olika sätt att formulera en modell som innehåller en slumpmässig faktor, men det viktiga är att vi beskriver egenskaperna i modellens komponenter så att det blir tydligt, oavsett de beteckningar som används, att faktorn numera är slumpmässig. Givet att detta underlag grundar sig i regressionsformuleringen till skillnad från den “klassiska” variansanalysformuleringen hänvisad i Note 13.1, kommer en regressionsformulering fortsätta användas även för slumpmässiga faktorer.\nVi kan formulera en modell där vi tillåter responsvariabeln variera beroende på vilken nivå en observation tillhör som: \\[\n\\begin{aligned}\n  Y_{ij} &= \\beta_{0i} + E_{ij}\\\\\n  \\text{där}\\\\\n  \\beta_{0i} &= \\gamma_{00} + U_{0i}\n\\end{aligned}\n\\] där \\(i\\) är de uppmätta nivåerna av faktorn, \\(\\gamma_{00}\\) är det övergripande medelvärdet (motsvarande \\(\\mu\\) i Ekvation 13.1), och \\(U_{0i}\\) är den avvikelse som nivå \\(i\\) har på det övergripande medelvärdet.1\nOm vi skriver ut modellen i sin helhet: \\[\n\\begin{aligned}\n  Y_{ij} &= \\gamma_{00} + U_{0i} + E_{ij}\n\\end{aligned}\n\\tag{14.1}\\] ser vi tydliga likheter med den fixa modellen, men också några skillnader. Vi visar inga kodade variabler eftersom de enskilda effekterna \\(U_{0i}\\) är inte lika intressant att titta på som \\(\\beta_i\\) i den fixa modellen. Däremot kan vi beskriva att de enskilda effekterna är slumpmässigt dragna från en normalfördelad population med väntevärde 0 och en specifik varians: \\[\n\\begin{aligned}\n  U_{0i} \\sim N(0, \\sigma^2_A)\n\\end{aligned}\n\\] där \\(\\sigma^2_A\\) är variansen för faktorn.\nFortfarande råder att \\(E_{ij} \\sim N(0, \\sigma^2)\\) vilket innebär att vi har en modell bestående av två olika varianskomponenter, \\(\\sigma^2_A\\) och \\(\\sigma^2\\), som anses vara oberoende av varandra. Detta leder också att vi kan beskriva fördelningen av Y|X som: \\[\n\\begin{aligned}\n  Y_{ij}|\\mathbf{X_j} \\sim N(\\gamma_{00}, \\sigma^2_A + \\sigma^2)\n\\end{aligned}\n\\tag{14.2}\\]",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Slumpmässiga faktorer</span>"
    ]
  },
  {
    "objectID": "02-variance/01-random-factors.html#inferens-på-en-slumpmässig-faktor",
    "href": "02-variance/01-random-factors.html#inferens-på-en-slumpmässig-faktor",
    "title": "14  Slumpmässiga faktorer",
    "section": "14.2 Inferens på en slumpmässig faktor",
    "text": "14.2 Inferens på en slumpmässig faktor\nOm vi antar en modell som inte har någon faktor ser den ut som: \\[\n\\begin{aligned}\n  Y_j = \\gamma_{00} + E_{j}\n\\end{aligned}\n\\] där \\(j = 1, \\dots, n\\). Som en följd innebär det att responsvariabelns fördelning blir \\(Y_{j}\\sim N(\\gamma{00}, \\sigma^2)\\), det vill säga att den enda variationen runt väntevärdet kommer från felets variation. Skillnaden gentemot Ekvation 14.2 är att variationen också beror på variationen i den slumpmässiga faktorn. Om den slumpmässiga faktorn har en effekt på responsvariabeln betyder detta att \\(\\sigma^2_A &gt; 0\\), det vill säga det är inte bara felet som bidrar till osäkerheten.\nPå samma sätt som vi med kvadratsummor kan dela upp den totala variationen av en responsvariabel i modellens förklarade och oförklarade variation, kan vi med en slumpmässig faktor göra detsamma dock med några justeringar. Vi betecknar de olika delarna med komponenternas olika varianser och andelen förklarad variation beräknas som: \\[\n\\begin{aligned}\n  \\frac{\\sigma_A^2}{\\sigma^2_Y} = \\frac{\\sigma^2_A}{\\sigma^2 + \\sigma^2_A}\n\\end{aligned}\n\\] där \\(\\sigma^2_Y\\) är den totala varians som finns i responsvariabeln.\n\n\n\n\n\n\nNotera\n\n\n\nNågot som är speciellt med slumpmässiga faktorer är att observationerna inom en faktornivå inte är oberoende eftersom de uppkommer från samma delgrupp av faktorn. Vi kan beräkna kovariansen mellan observationer inom en faktornivå: \\[\n\\begin{aligned}\n  \\sigma(Y_{ij}, Y_{ij'}) = \\sigma^2_A\n\\end{aligned}\n\\] där \\(j \\ne j'\\).\nKovariansen mellan observationer i olika faktornivåer antas oberoende: \\[\n\\begin{aligned}\n  \\sigma(Y_{ij}, Y_{i'j'}) = 0\n\\end{aligned}\n\\] där \\(i \\ne i'\\).\nAnta att en faktor har två faktornivåer och tre observationer i varje cell (faktornivå). Om vi lägger dessa observationer i en vektor sorterade efter faktorn får vi följande kovariansmatris: \\[\n\\begin{aligned}\n\\sigma^2(\\mathbf{Y})= \\begin{bmatrix}\n        \\sigma^2 + \\sigma^2_A   & \\sigma^2_A              & \\sigma^2_A              & 0 & 0 & 0\\\\\n        \\sigma^2_A            & \\sigma^2 + \\sigma^2_A     & \\sigma^2_A              & 0 & 0 & 0\\\\\n        \\sigma^2_A            & \\sigma^2_A              & \\sigma^2 + \\sigma^2_A     & 0 & 0 & 0\\\\\n        0                       & 0                         & 0                         & \\sigma^2 + \\sigma^2_A & \\sigma^2_A          & \\sigma^2_A\\\\\n        0                       & 0                         & 0                         & \\sigma^2_A          & \\sigma^2 + \\sigma^2_A & \\sigma^2_A \\\\\n        0                       & 0                         & 0                         & \\sigma^2_A          & \\sigma^2_A          & \\sigma^2 + \\sigma^2_A\n    \\end{bmatrix}\n\\end{aligned}\n\\]\n\n\nFör att undersöka om den slumpmässiga faktorn bidrar med en signifikant effekt formuleras följande hypoteser: \\[\n\\begin{aligned}\n  &H_0: \\sigma^2_A = 0\\\\\n  &H_a: \\sigma^2_A &gt; 0\n\\end{aligned}\n\\] Om \\(H_0: \\sigma_A^2 = 0\\) är sann betyder det att alla dragningar från populationen av alla nivåer är lika, en konstant, och att faktorn därav inte har någon effekt. Om \\(H_a\\) är sann betyder det däremot att faktorn har en effekt och att dragningar från populationen av alla nivåer generar olika effekter.\nFör att beräkna testvariabeln för denna hypotesprövning används kvadratsummorna från den linjära modellen som en skattning av varianserna. Vi utgår från att de förväntade medelkvadratsummorna för \\(MSE\\) och \\(MSA\\)2 är: \\[\n\\begin{aligned}\n    E[MSE] &= \\sigma^2 \\\\\n    E[MSA] &= \\sigma^2 + n_i\\cdot \\sigma^2_A\n\\end{aligned}\n\\] Om \\(H_0\\) är sann betyder det att \\(E[MSE] = E[MSA]\\) men om \\(H_a\\) är sann betyder det att \\(E[MSA] &gt; E[MSE]\\) eftersom \\(n_i &gt; 0\\). En lämplig testvariabel formuleras då som: \\[\n\\begin{aligned}\n  F_{test} = \\frac{MSA}{MSE}\n\\end{aligned}\n\\] där \\(F_{test} \\sim F_{A - 1; A\\cdot(n_i - 1)}\\).\n\n\n\n\n\n\nNotera\n\n\n\nFrihetsgraderna för nämnaren är en omskrivning av “den vanliga” \\(n - (k + 1)\\) enligt: \\[\n\\begin{aligned}\n    n - (k + 1) &= \\\\\n    n - (A - 1 + 1) &=\\\\\n    n_i \\cdot A - A &= A \\cdot (n_i - 1)\n\\end{aligned}\n\\] där \\(n_i\\) är antalet observationer inom en nivå. Vi förutsätter att modellen är balanserad, det vill säga att alla nivåer har lika många observationer, \\(n_i = n / A\\).\n\n\nI R kommer denna hypotesprövning beräknas på samma sätt som ett övergripande F-test i en fix modell beskriven i Avsnitt 13.4.1 eftersom testvariabeln beräknas på samma sätt som det tidigare F-testet. Med en slumpmässig faktor kommer dock hypoteserna beskriva någonting annat och slutsatser som vi drar behöver ta hänsyn till variationen i faktorn, inte de enskilda faktormedelvärdena.\n\n\n\n\n\n\nViktigt\n\n\n\nOm \\(H_0\\) förkastas vill vi inte genomföra multipla jämförelser för att bedöma specifikt vilka nivåer som skiljer sig åt. Med en slumpmässig faktor är de utvalda nivåerna inte intressanta att jämföra.\n\n\n\n14.2.1 Varianskomponenter\nIstället för att beräkna multipla jämförelser för de uppmätta slumpmässiga effekterna kan vi istället skatta varianskomponenten för faktorn. Detta kommer ge oss en indikation på magnituden av variation som finns inuti faktorn. Med hjälp av omskrivningar av väntevärden kan vi beräkna skattningen genom: \\[\n\\begin{aligned}\n    s^2 &= MSE\\\\\n    s^2_A &= \\frac{MSA - MSE}{n}\n\\end{aligned}\n\\]\ndär \\(n\\) är antalet observationer inom en faktornivå. Kom ihåg att vi här behandlar en balanserad modell vilket betyder att \\(n_i = n\\).\n\n# Sparar ner ANOVA-tabellen som en data.frame\nanovaTabell &lt;- anova(model)\n\n# Plockar ut MSA och MSE från tabellen\nMSA &lt;- anovaTabell$`Mean Sq`[1]\nMSE &lt;- anovaTabell$`Mean Sq`[2]\n\n# Plockar ut antalet observationer per cell \nn &lt;- (sum(anovaTabell$Df) + 1) / (anovaTabell$Df[1] + 1)\n\n# Beräknar variansskattningarna\nsigmaEst &lt;- MSE\nsigmaAEst &lt;- (MSA - MSE) / n\n\n# Sammanställer skattningarna och presenterar som en tabell\ntibble(\n    Parameter = \n      c(\"$\\\\sigma^2$\",\"$\\\\sigma^2_A$\"),\n    Skattning =\n      c(sigmaEst,sigmaAEst)\n  ) %&gt;% \n  kable(\n    caption = \"Skattade varianser.\", \n    digits = 3\n  ) \n\nMed hjälp av dessa skattningar skulle vi kunna göra intervallskattningar för exempelvis \\(\\sigma_A^2\\) (se kapitel 6.1 i Teorikompendiet för Satterthwaite intervall).",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Slumpmässiga faktorer</span>"
    ]
  },
  {
    "objectID": "02-variance/01-random-factors.html#övningsuppgifter",
    "href": "02-variance/01-random-factors.html#övningsuppgifter",
    "title": "14  Slumpmässiga faktorer",
    "section": "14.3 Övningsuppgifter",
    "text": "14.3 Övningsuppgifter\nDessa övningar använder sig av ett datamaterial från en fabrik som skapar spolar (tråd som är lindad i en spiral för diverse elektronik). I fabriken väljs fyra maskiner slumpmässigt ut från alla maskiner som finns i fabriken. Sedan väljs 10 skapade spolar ut slumpmässigt från respektive maskin. Mätvariabeln (coil_characteristic) är en egenskap (oklart vad) hos spolarna. Materialet finns tillgängligt här.\n\nMotivera varför en modell med en slumpmässiga faktor är lämplig för att analysera detta material. Formulera modellen och beskriv varje komponent.\nUndersök om det finns en signifikant effekt av maskinerna på egenskaperna med 5 procents signifikans.\nSkatta \\(\\sigma^2_{A}\\) med ett 90% approximativt konfidensintervall med hjälp av Satterthwaites metod. Tolka intervallet.\nSkatta kvoten av \\(\\frac{\\sigma^2_{A}}{\\sigma^2_Y}\\) med ett 95% intervall. Tolka intervallet.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Slumpmässiga faktorer</span>"
    ]
  },
  {
    "objectID": "02-variance/01-random-factors.html#referenser",
    "href": "02-variance/01-random-factors.html#referenser",
    "title": "14  Slumpmässiga faktorer",
    "section": "Referenser",
    "text": "Referenser\n\n\n\n\nKleinbaum, D. G., L. L. Kupper, A. Nizam, och E. S. Rosenberg. 2013. Applied Regression Analysis and Other Multivariable Methods. Cengage Learning. https://books.google.se/books?id=v590AgAAQBAJ.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Slumpmässiga faktorer</span>"
    ]
  },
  {
    "objectID": "02-variance/01-random-factors.html#footnotes",
    "href": "02-variance/01-random-factors.html#footnotes",
    "title": "14  Slumpmässiga faktorer",
    "section": "",
    "text": "Detta är ekvivalent som \\(Y_{ij} = \\mu + A_i + E_{ij}\\) från Kleinbaum m.fl. (2013).↩︎\n\\(MSA\\) är specifikt medelkvadratsumman för faktorn. I en envägs-ANOVA är detta samma som \\(MSR\\), men i tvåvägs-ANOVA kommer vi vilja dela upp \\(MSR\\) i dess mindre beståndsdelar.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>14</span>  <span class='chapter-title'>Slumpmässiga faktorer</span>"
    ]
  },
  {
    "objectID": "02-variance/02-control-variables.html",
    "href": "02-variance/02-control-variables.html",
    "title": "15  Kontrollvariabler",
    "section": "",
    "text": "15.1 Kovariansanalys\nI Avsnitt 1.3.1 tog vi upp konceptet om kontrollvariabler, variabler som kan användas för att justera effekten av faktorn av intresse så att vi får parameterskattningar som ligger närmare sanningen. Inom experimentella studier används dessa frekvent för detta ändamål men vi gör skillnad på hur kvalitativa och kvantativa kontrollvariabler påverkar studien.\nKovariansanalys1 omfattar en modell där vi har kvantitativa kontrollvariabler, här kallad för kovariater, som vi vet på något sätt påverkar responsvariabeln och kanske också den kvalitativa faktorn som studien fokuserar på.\nAnta att vi vill jämföra olika skottkärror av fyra olika modeller, och bedöma vilken utav modellerna som är lättast att använda och vi mäter tiden det tar att flytta en mängd grus mellan två punkter. Vi kan visualisera relationen mellan de två variablerna i en graf:\nI detta experiment antas det rimligt att även vikten på gruset som skottkärran får påverkar tiden det tar. Vi kan förmodligen inte lasta exakt lika mycket grus varje gång för att hålla den variabeln konstant så istället lastar vi gruset i skottkärran när den står på en våg och noterar vikten av gruset (totalvikt - skottkärrans vikt).\nEffekten av skottkärran kommer då justeras med avseende på kontrollvariabeln.\nModellen som formuleras blir då: \\[\n\\begin{aligned}\n  Y_{ij} = \\mu + \\beta_1 \\cdot X_{1j} + \\beta_{2}\\cdot X_{2j} + \\beta_{3}\\cdot X_{3j} + \\beta_4 \\cdot (Z_{ij} - \\overline{Z}) + E_{ij}\n\\end{aligned}\n\\] där \\[\n\\begin{aligned}\n    \\mu &= \\frac{\\mu_1 + \\mu_2 + \\mu_3 + \\mu_4}{4} \\\\\n    X_{1j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om modell 1}\\\\\n        -1      &\\text{om modell 4}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    X_{2j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om modell 2}\\\\\n        -1      &\\text{om modell 4}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    X_{3j} &=\n    \\begin{cases}\n        1 \\quad &\\text{om modell 3}\\\\\n        -1      &\\text{om modell 4}\\\\\n        0       &\\text{annars}\n    \\end{cases} \\\\\n    \\overline{Z} &= \\frac{\\sum{Z_{ij}}}{n} \\\\\n    E_{ij} &\\sim N(0, \\sigma^2)\n\\end{aligned}\n\\] Anledningen till att kontrollvariabeln centreras i modellen är för att tillåta \\(\\mu\\) fortsätta vara det övergripande medelvärdet vilket underlättar beräkningar.\nI koden nedan skapas datamaterialet, den kvalitativa variabeln modell anges som en faktor med effektkodning och den kontinuerliga kontrollvariabeln centreras.\nVisa kod\nwheelbarrow &lt;- tibble(\n  Model = c(\"Model_A\", \"Model_A\", \"Model_A\", \"Model_A\", \"Model_A\",\n            \"Model_B\", \"Model_B\", \"Model_B\", \"Model_B\", \"Model_B\",\n            \"Model_C\", \"Model_C\", \"Model_C\", \"Model_C\", \"Model_C\",\n            \"Model_D\", \"Model_D\", \"Model_D\", \"Model_D\", \"Model_D\") %&gt;% factor(),\n  Weight = c(49.53, 49.53, 53.16, 51.53, 49.06,\n             51.09, 49.07, 49.07, 50.48, 46.17,\n             46.55, 48.88, 47.97, 50.63, 48.18,\n             47.18, 52.93, 49.55, 50.14, 47.15),\n  Time = c(15.66, 16.31, 15.41, 16.78, 15.55,\n           16.75, 16.24, 18.69, 16.97, 15.49,\n           18.30, 16.49, 17.83, 15.93, 16.31,\n           19.68, 20.79, 19.89, 19.66, 19.18)\n) %&gt;% \n  mutate(\n    Weight = scale(Weight, scale = FALSE)\n  )\n\ncontrasts(wheelbarrow$Model) &lt;- contr.sum(4)\nModellen anpassas på samma sätt som en envägs-ANOVA men vi lägger till den centrerade kovariaten.\nVisa kod\nmodel &lt;- lm(Time ~ Model + Weight, data = wheelbarrow)\n\nanova(model) %&gt;% \n  kable(digits = 3, caption = \"ANOVA-modell för kovariansmodellen\")\n\n\n\nANOVA-modell för kovariansmodellen\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nModel\n3\n42.948\n14.316\n17.311\n0.000\n\n\nWeight\n1\n0.233\n0.233\n0.281\n0.604\n\n\nResiduals\n15\n12.405\n0.827",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kontrollvariabler</span>"
    ]
  },
  {
    "objectID": "02-variance/02-control-variables.html#sec-ancova",
    "href": "02-variance/02-control-variables.html#sec-ancova",
    "title": "15  Kontrollvariabler",
    "section": "",
    "text": "G\n\n\n\nA\n\nModell\n\n\n\nB\n\nTid\n\n\n\nA-&gt;B\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 15.1: Relationen mellan modellen av skottkärra och den uppmätta tiden.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nG\n\n\n\nA\n\nModell\n\n\n\nB\n\nTid\n\n\n\nA-&gt;B\n\n\n\n\n\nC\n\nVikt\n\n\n\nC-&gt;B\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 15.2: Relationen mellan modellen av skottkärra och den uppmätta tiden där vi kontrollerar för lastens vikt.\n\n\n\n\n\n\n\n\n\n\n15.1.1 Inferens\nVi måste nu undersöka effekten av faktorn genom ett partiellt F-test då modellen innehåller fler komponenter. \\[\n\\begin{aligned}\n  &H_0: \\beta_1 = \\beta_2 = \\beta_3 = 0\\\\\n  &H_a: \\text{Minst en av } \\beta_i \\text{ i } H_0 \\ne 0\n\\end{aligned}\n\\]\nVi jämför alltså två modeller, den kompletta med faktorn och kovariaten och den reducerade med enbart kovariaten. Om vi ändrar ordningen på variablerna kan vi med hjälp av sekventiella kvadratsummor få både testvariabeln och p-värdet för testet i ANOVA-tabellen.\n\n\nVisa kod\nmodel &lt;- lm(Time ~ Weight + Model, data = wheelbarrow)\n\nanova(model) %&gt;% \n  kable(digits = 3, caption = \"ANOVA-modell för kovariansmodellen\")\n\n\n\nANOVA-modell för kovariansmodellen\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nWeight\n1\n0.070\n0.070\n0.085\n0.775\n\n\nModel\n3\n43.111\n14.370\n17.376\n0.000\n\n\nResiduals\n15\n12.405\n0.827\n\n\n\n\n\n\n\nInferens för kovariaten är inte relevant eftersom detta samband inte är intressant för undersökningens syfte utan inkluderas endast för att faktorns samband ska justeras.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kontrollvariabler</span>"
    ]
  },
  {
    "objectID": "02-variance/02-control-variables.html#randomiserade-blockförsök",
    "href": "02-variance/02-control-variables.html#randomiserade-blockförsök",
    "title": "15  Kontrollvariabler",
    "section": "15.2 Randomiserade blockförsök",
    "text": "15.2 Randomiserade blockförsök\nI fall där mätenheterna är heterogena men kan delas upp i mindre homogena grupper, är det lämpligt att genomföra ett randomiserat blockförsök. Detta motsvarar en kvalitativ kontrollvariabel.\nDessa homogena grupperna kallas för block och rent praktiskt tilldelas behandlingarna slumpmässigt inom varje block. För att relatera detta till urvalsundersökningar kan vi säga att komplett randomisering motsvarar ett OSU och randomiserade blockförsök motsvarar ett stratifierat urval. En modell kan innehålla ett block vars nivåer är en kombination av flera kontrollvariabler eller flera kontrollvariabler som separata block.\nModellen som anpassas försöker nu beskriva \\(Y_{ijk}\\) där \\(i \\in {1, \\dots, A}\\), \\(j \\in {1, \\dots, B}\\), och \\(k \\in {1, \\dots, n_{ij}}\\) för A nivåer av faktorn och B olika block.\nOm undersökningen endast består av en observation per cell, en observation per nivå av faktorn i vardera block, kan inte SSE beräknas enligt tidigare formler (Ekvation 13.3) då \\(\\left(Y_{ijk} - \\overline{Y}_{ij}\\right) = 0\\). Vi behöver då anta att modellen inte har någon interaktion och skatta den oförklarade variationen med interaktionens kvadratsumma.\n\\[\n\\begin{aligned}\nSSAB = \\sum_{i = 1}^A \\sum_{j=1}^B \\left(\\overline{Y}_{ij} - \\overline{Y}_{i} - \\overline{Y}_{j} + \\overline{Y}\\right)^2\n\\end{aligned}\n\\]\nOm undersökningen har flera observationer beräknas den oförklarade variationen som vanligt med hjälp av SSE.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kontrollvariabler</span>"
    ]
  },
  {
    "objectID": "02-variance/02-control-variables.html#footnotes",
    "href": "02-variance/02-control-variables.html#footnotes",
    "title": "15  Kontrollvariabler",
    "section": "",
    "text": "Även kallad ANACOVA eller ANCOVA för ANalysis of COVAriance.↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>15</span>  <span class='chapter-title'>Kontrollvariabler</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html",
    "href": "02-variance/03-twoway-anova.html",
    "title": "16  Tvåvägs-ANOVA",
    "section": "",
    "text": "16.1 Typer av kvadratsummor\nI Kapitel 13 studerade vi förhållandet mellan en responsvariabel och en förklarande faktor (med flera faktornivåer) och Kapitel 15 utökade vi modellen till att också inkludera kontrollvariabler för att justera effekten av faktorn och ta hänsyn till confounding effekter.\nEtt experiment behöver inte begränsa sig till endast en faktor av intresse utan kan utökas till flera förklarande faktorer. I detta kapitel utvidgar vi modellen till två förklarande faktorer och vi vill studera förhållandet mellan varje faktor och en kombination av dessa gentemot responsvariabeln.\nNär vi undersöker flera faktorer kan vi kombinera fixa och slumpmässiga faktorer i olika konstellationer och skillnaden mellan dessa modeller påverkar både den teoretiska grunden och hur vi genomför inferens på dess olika delar.\nI envägs-ANOVA kan vi undersöka faktorns effekt med ett F-test där kvadratsumman för faktorn är den enda komponenten i den förklarade variationen. Med en modell som nu inkluderar flera faktorer kommer den förklarade variationen bestå av flera komponenter, en för vardera faktor och en för interaktionen mellan dem, på samma sätt som i en multipel linjär regressionsmodell.\nI Avsnitt 5.1.1 beskrev vi sekventiella kvadratsummor (SS) som ett sätt att dela upp den förklarade variationen i dess mindre beståndsdelar. Sekventiella kvadratsummor är endast en variant av kvadratsumma som vi kan använda för att presentera den förklarade variationen.\nTyp I SS kallas oftast för sekventiella eller betingade kvadratsummor eftersom de beräknas enligt den ordning som variablerna läggs till i modellen. I en tvåvägs-ANOVA med interaktioner har modellen tre källor av variation. Notera att kategoriska variabler grupperas till en och samma källa oavsett hur många kodade variabler eller tillhörande parameterskattningar som den innehåller. Givet att vi skattar modellen lm(Y ~ A * B) där \\(A\\) och \\(B\\) är två faktorer beräknas SS av typ I som följer:\nOm vi vill undersöka faktor As huvudsakliga effekter kommer dessa SS endast ta hänsyn till Faktor A, alltså vi får samma värden som om vi hade anpassat en envägs-ANOVA med enbart faktor A. Detta är inte målet med en tvåvägs-ANOVA, vi vill ta hänsyn till båda faktorerna som modellen innehåller.\nTyp II SS beräknar kvadratsummor betingat på andra variabler av samma grad eller lägre. I praktiken betyder detta att huvudeffekterna är av grad 1 medan interaktionen är av grad 2 och betingade kvadratsummor för en huvudeffekt kommer endast ta hänsyn till den andra huvudeffekten.\nDenna kvadratsumma kommer undersöka de huvudsakliga effekterna under antagandet att det inte finns någon interaktion med i modellen, vilket i R beräkningsmässigt skulle motsvara en lm(Y ~ A + B) modell med typ III SS. Typ II SS ger oss dock möjligheten att få ut dessa värden utan att behöva skatta om modellen ifall interaktionseffekten visat sig vara icke-signifikant.\nTyp III SS beräknar kvadratsummor betingat på alla andra variabler som inkluderas i modellen oavsett ordningen vi lägger in dem.\nJämfört med typ II SS beräknas de betingade kvadratsummorna för huvudeffekterna med interaktionen i åtanke vilket innebär att dessa kvadratsummor för huvudeffekterna kommer vara korrekt ifall interaktionen är signifikant.\nTyp II och typ III SS har inte samma additiva egenskap som typ I SS vilket innebär att den totala förklarade variationen inte kan beräknas genom deras summa, utan vi behöver då beräkna \\(SSR = SSY - SSE\\).\nEn balanserad ANOVA-modell ger dock ett specialfall av dessa kvadratsummor, nämligen att de alla är lika varandra. Vad detta betyder för vår inferens är att vi kan undersöka den enskilda faktorns effekt direkt från ANOVA-tabellen oavsett vilken sorts kvadratsumma som används.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html#typer-av-kvadratsummor",
    "href": "02-variance/03-twoway-anova.html#typer-av-kvadratsummor",
    "title": "16  Tvåvägs-ANOVA",
    "section": "",
    "text": "Faktor A: \\(SS(A)\\)\nFaktor B: \\(SS(B | A)\\)\nInteraktion: \\(SS(AB | A, B)\\)\n\n\n\n\nFaktor A: \\(SS(A | B)\\)\nFaktor B: \\(SS(B | A)\\)\nInteraktion: \\(SS(AB | A, B)\\)\n\n\n\n\nFaktor A: \\(SS(A | B, AB)\\)\nFaktor B: \\(SS(B | A, AB)\\)\nInteraktion: \\(SS(AB | A, B)\\)\n\n\n\n\n\n\n\n\nViktigt\n\n\n\nFör typ III SS när interaktionen är inkluderad måste vi koda våra faktorer enligt effektkodning. Orsaken bakom detta är att för flervägs-ANOVA med interaktioner kräver att summan av kodningen för varje variabel är 0, annars undersöks fel hypoteser.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html#tvåvägs-anova",
    "href": "02-variance/03-twoway-anova.html#tvåvägs-anova",
    "title": "16  Tvåvägs-ANOVA",
    "section": "16.2 Tvåvägs-ANOVA",
    "text": "16.2 Tvåvägs-ANOVA\nAnta att vi genomför ett experiment för att mäta effekten av C-vitamin på tillväxten av tänder hos marsvin. De två faktorerna som undersöks är doseringen av vitamin (faktor A) och intagningsmetoden (faktor B).\nTre specifika doser undersöks:\n\n0.5 mg/dag\n1 mg/dag\n2 mg/dag\n\nTvå olika sätt att ge C-vitamin till marsvinen undersöks:\n\nApelsinjuice (kodad OJ)\nAskorbinsyra (kodad VC)\n\nModellen måste nu ta hänsyn till att vi har två index för faktorerna (\\(i\\) och \\(j\\)) och ett index för observationerna (\\(k\\)).\n\\[\n\\begin{aligned}\n  Y_{ijk} = \\mu + \\underbrace{\\beta_1 \\cdot X_{1jk} + \\beta_2 \\cdot X_{2jk}}_{\\text{Faktor A}} + \\underbrace{\\beta_3 \\cdot X_{i1k}}_{\\text{Faktor B}} + \\underbrace{\\beta_4 \\cdot X_{1jk} \\cdot X_{i1k} + \\beta_5 \\cdot X_{2jk} \\cdot X_{i1k}}_{\\text{Interaktion}}+ E_{ijk}\n\\end{aligned}\n\\tag{16.1}\\]\nNär vi lägger till ytterligare en faktor och interaktionen mellan de två innebär det att vi undersöker tre olika potentiella effekter; interaktionseffekter, och två huvudsakliga faktoreffekter, en för respektive faktor. Däremot kommer interaktionseffektens förekomst eller avsaknad påverka hur vi undersöker de huvudsakliga effekterna.\nVi kan visualisera en tvåvägs-ANOVA likt vi gjort tidigare, genom grupperade diagram, men vi måste också ta hänsyn till att interaktionen mellan de två faktorerna kan vara av intresse. Därför behöver vi gruppera diagrammet på båda faktorerna.\n\n\nVisa kod\nToothGrowth &lt;- \n  ToothGrowth  %&gt;% \n  mutate(\n    dose = factor(dose)\n  )\n\ncontrasts(ToothGrowth$dose) &lt;- contr.sum(3)\ncontrasts(ToothGrowth$supp) &lt;- contr.sum(2)\n\nggplot(ToothGrowth) + aes(x = dose, y = len, fill = supp) +\n  geom_violin() + theme_bw() + \n  scale_fill_manual(\n    \"Metod\",\n    values = c(\"steelblue\", \"#d9230f\")\n  ) + labs(x = \"Dosering\", y = \"Längd\")\n\n\n\n\n\nFördelning av längder för respektive kombination av dos och intagningssätt.\n\n\n\n\nMed detta fioldiagram kan vi se skillnader i faktormedelvärden, fördelningen för respektive färg, men för att tydligt kunna utläsa interaktioner behöver vi göra ett interaktionsdiagram. Ett interaktionsdiagram är ett linjediagram över cellmedelvärdena, alltså medelvärden för varje kombination av nivåer från respektive faktor.\n\n\nVisa kod\n# Beräknar cellmedelvärden\nmeans &lt;- \n  ToothGrowth %&gt;% \n  group_by(supp, dose) %&gt;% \n  summarize(\n    mean = mean(len)\n  )\n\n# Visar respektive cellmedelvärde\nggplot(ToothGrowth) + \n  aes(x = dose, y = len, group = supp, color = supp) + \n  geom_point(alpha = 0.5) + theme_bw() + \n  scale_color_manual(\"Metod\", values = c(\"steelblue\", \"#d9230f\")) + \n  geom_line(\n    data = means,\n    aes(y = mean), \n    linewidth = 1.2\n  ) + \n  labs(x = \"Dosering\", y = \"Längd\")\n\n\n\n\n\n\n\n\nFigur 16.1: Interaktionsdiagram över cellmedelvärden.\n\n\n\n\n\nVi kan identifiera en antydan till en interaktion genom icke-parallella linjer som i praktiken betyder att effekten av en faktor påverkas av vilken nivå av den andra faktorn som också ges. I just detta fall ser linjerna ut att korsas vid dos 2 vilket ger en svag antydan till att en interaktion förekommer. Som alla former av visualiseringar beskriver detta endast det urval som har genomförts och för att dra slutsatser om populationen behöver vi genomföra inferens.\n\n16.2.1 Modellanpassning i R\nAtt skatta en tvåvägs-ANOVA i R är inte svårare än att skatta en regressionsmodell med flera variabler. För att få en interaktion mellan de två faktorerna behöver vi använda * istället för +.\n\n\nVisa kod\nmodel &lt;- lm(len ~ supp*dose, data = ToothGrowth)\n\nanova(model) %&gt;% \n  kable(digits = 3, caption = \"Modellens ANOVA-tabell.\")\n\n\n\nModellens ANOVA-tabell.\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nsupp\n1\n205.350\n205.350\n15.572\n0.000\n\n\ndose\n2\n2426.434\n1213.217\n92.000\n0.000\n\n\nsupp:dose\n2\n108.319\n54.160\n4.107\n0.022\n\n\nResiduals\n54\n712.106\n13.187\n\n\n\n\n\n\n\n\n\n\n\n\n\nTips\n\n\n\nFör att visa att de sekventiella kvadratsummorna som R anger är lika de andra typerna av kvadratsumma kan vi ändra ordning på modellen och ändå få samma kvadratsummor för alla komponenter.\n\n\nVisa kod\nmodel &lt;- lm(len ~ dose*supp, data = ToothGrowth)\n\nanova(model) %&gt;% \n  kable(digits = 3, caption = \"Modellens ANOVA-tabell.\")\n\n\n\nModellens ANOVA-tabell.\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\ndose\n2\n2426.434\n1213.217\n92.000\n0.000\n\n\nsupp\n1\n205.350\n205.350\n15.572\n0.000\n\n\ndose:supp\n2\n108.319\n54.160\n4.107\n0.022\n\n\nResiduals\n54\n712.106\n13.187\n\n\n\n\n\n\n\n\n\n\n\n16.2.2 Inferens\nUtifrån tabellen kan vi dra slutsatser om respektive komponent i modellen men vi börjar alltid med interaktionseffekter.\nHypoteserna som undersöks för respektive del kan grupperas i flera partiella F-test utifrån Ekvation 16.1. Interaktionen består i detta exempel av parametrarna \\(\\beta_4\\) och \\(\\beta_5\\) så den formella hypotesen för interaktionseffekten är: \\[\n\\begin{aligned}\n  &H_0: \\beta_4 = \\beta_5 = 0\\\\\n  &H_a: \\text{Minst en av } \\beta \\text{ i } H_0 \\ne 0\n\\end{aligned}\n\\]\nTestvariabeln beräknas genom: \\[\n\\begin{aligned}\n  F_{test} = \\frac{MSAB}{MSE}\n\\end{aligned}\n\\] där \\(MSAB\\) är interaktionens medelkvadratsumma. Testvariabeln anses följa \\(F_{(A-1)(B-1), A \\cdot B(n-1), 1-\\alpha}\\).\nP-värdet för testet (0.0219) är mindre än fem procent vilket innebär att vi kan förkasta \\(H_0\\) att det inte finns någon interaktion mellan faktorerna.\nDetta kommer påverka våra nästa steg i analysen eftersom en interaktion innebär att sambandet mellan en faktor och mätvariabeln förändras beroende på den andra faktorn. Den direkta konsekvensen är att de huvudsakliga faktoreffekterna inte längre är relevant att undersöka eftersom de kommer ge missvisande resultat. Vi kommer inte vilja undersöka skillnader mellan specifika faktornivåer utan fokuserar på cellmedelvärdena, alltså skillnader i medelvärden när vi tar hänsyn till båda faktorerna.\nPaketet emmeans kan skapa cellmedelvärden genom:\n\n\nVisa kod\nmeans &lt;- emmeans(model, specs = ~supp*dose)\n\nmeans %&gt;% \n  kable(digits = 3, caption = \"Cellernas medelvärden\", \n        col.names = c(\"Metod\", \"Dosering\", \"Medelvärde\", \"Medelfel\", \"Frihetsgrader\", \"Nedre KI gräns\", \"Övre KI gräns\"))\n\n\n\n\nTabell 16.1: Cellernas medelvärden\n\n\n\n\nCellernas medelvärden\n\n\n\n\n\n\n\n\n\n\n\nMetod\nDosering\nMedelvärde\nMedelfel\nFrihetsgrader\nNedre KI gräns\nÖvre KI gräns\n\n\n\n\nOJ\n0.5\n13.23\n1.148\n54\n10.928\n15.532\n\n\nVC\n0.5\n7.98\n1.148\n54\n5.678\n10.282\n\n\nOJ\n1\n22.70\n1.148\n54\n20.398\n25.002\n\n\nVC\n1\n16.77\n1.148\n54\n14.468\n19.072\n\n\nOJ\n2\n26.06\n1.148\n54\n23.758\n28.362\n\n\nVC\n2\n26.14\n1.148\n54\n23.838\n28.442\n\n\n\n\n\n\n\n\nTabell 16.1 visar de specifika värden som vi såg i Figur 16.1. Inferens över multipla jämförelser innebär nu att vi skapar par av cellmedelvärden och genomför hypotesprövningar eller intervallskattningar med någon form av familjekonfidens. Formellt undersöks par av medelvärden med båda index, t.ex. \\(H_0: \\mu_{11} - \\mu_{12} = 0\\).\n\n\nVisa kod\ntukey &lt;- \n  pairs(means, adjust = \"tukey\") \n\ntukey %&gt;% \n  as_tibble() %&gt;% \n  arrange(abs(estimate) %&gt;% desc()) %&gt;% \n  kable(digits = 3, caption = \"Parvisa jämförelser av cellmedelvärden med Tukey familjekonfidens\")\nselectedMeans &lt;- means[c(1:4),]\n\nbonferroni &lt;- \n  pairs(selectedMeans, adjust = \"bonferroni\")\n\nbonferroni %&gt;% \n  as_tibble() %&gt;% \n  arrange(abs(estimate) |&gt; desc()) %&gt;% \n  kable(digits = 3, caption = \"Parvisa jämförelser av utvalda cellmedelvärden med Bonferroni familjekonfidens\")\n\n\n\n\nTabell 16.2: Parvisa jämförelser av utvalda cellmedelvärden med Bonferroni familjekonfidens\n\n\n\n\nParvisa jämförelser av cellmedelvärden med Tukey familjekonfidens\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nVC dose0.5 - VC dose2\n-18.16\n1.624\n54\n-11.182\n0.000\n\n\nVC dose0.5 - OJ dose2\n-18.08\n1.624\n54\n-11.133\n0.000\n\n\nVC dose0.5 - OJ dose1\n-14.72\n1.624\n54\n-9.064\n0.000\n\n\nOJ dose0.5 - VC dose2\n-12.91\n1.624\n54\n-7.949\n0.000\n\n\nOJ dose0.5 - OJ dose2\n-12.83\n1.624\n54\n-7.900\n0.000\n\n\nOJ dose0.5 - OJ dose1\n-9.47\n1.624\n54\n-5.831\n0.000\n\n\nVC dose1 - VC dose2\n-9.37\n1.624\n54\n-5.770\n0.000\n\n\nVC dose1 - OJ dose2\n-9.29\n1.624\n54\n-5.720\n0.000\n\n\nVC dose0.5 - VC dose1\n-8.79\n1.624\n54\n-5.413\n0.000\n\n\nOJ dose1 - VC dose1\n5.93\n1.624\n54\n3.651\n0.007\n\n\nOJ dose0.5 - VC dose0.5\n5.25\n1.624\n54\n3.233\n0.024\n\n\nOJ dose0.5 - VC dose1\n-3.54\n1.624\n54\n-2.180\n0.264\n\n\nOJ dose1 - VC dose2\n-3.44\n1.624\n54\n-2.118\n0.294\n\n\nOJ dose1 - OJ dose2\n-3.36\n1.624\n54\n-2.069\n0.319\n\n\nOJ dose2 - VC dose2\n-0.08\n1.624\n54\n-0.049\n1.000\n\n\n\n\n\n\nParvisa jämförelser av utvalda cellmedelvärden med Bonferroni familjekonfidens\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nVC dose0.5 - OJ dose1\n-14.72\n1.624\n54\n-9.064\n0.000\n\n\nOJ dose0.5 - OJ dose1\n-9.47\n1.624\n54\n-5.831\n0.000\n\n\nVC dose0.5 - VC dose1\n-8.79\n1.624\n54\n-5.413\n0.000\n\n\nOJ dose1 - VC dose1\n5.93\n1.624\n54\n3.651\n0.004\n\n\nOJ dose0.5 - VC dose0.5\n5.25\n1.624\n54\n3.233\n0.013\n\n\nOJ dose0.5 - VC dose1\n-3.54\n1.624\n54\n-2.180\n0.202",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html#slumpmässiga-faktorer",
    "href": "02-variance/03-twoway-anova.html#slumpmässiga-faktorer",
    "title": "16  Tvåvägs-ANOVA",
    "section": "16.3 Slumpmässiga faktorer",
    "text": "16.3 Slumpmässiga faktorer\nHittintills har vi bara ägnat oss åt modeller där vi endast har fixa effekter. I praktiken har vi många situationer där nivåerna på en faktor är dragna slumpmässigt från en population vilket innebär att inferensen som vi genomför tittar på hela population och inte bara de utvalda nivåerna. Detta är en modell med slumpmässiga effekter och i en flervägs-modell kan vi inkludera en blandning av fixa och slumpmässiga effekter (mixed effects model) eller enbart slumpmässiga (random effects model). I fallet med två slumpmässiga faktorer kan vi utveckla Ekvation 14.1 till att ta hänsyn till flera slumpmässiga effekter: \\[\n\\begin{aligned}\n  Y_{ijk} = \\gamma_{000} + U_{0i0} + U_{00j} + U_{0ij} + E_{ijk}\n\\end{aligned}\n\\tag{16.2}\\] där\n\n\\(i\\) är de uppmätta nivåerna av faktor A,\n\\(j\\) är nivåer av faktor B,\n\\(\\gamma_{000}\\) är det övergripande medelvärdet (motsvarande \\(\\mu\\) i Ekvation 13.1),\n\\(U_{0i0} \\sim N(0, \\sigma_A^2)\\) är den avvikelse som nivå \\(i\\) har på det övergripande medelvärdet,\n\\(U_{00j} \\sim N(0, \\sigma_B^2)\\) är den avvikelse nivå \\(j\\) har på medelvärdet,\n\\(U_{0ij} \\sim N(0, \\sigma_{AB}^2)\\) är den avvikelse respektive kombination av nivåer från de två faktorerna har på medelvärdet,\ntill sist \\(E_{ijk} \\sim N(0, \\sigma^2)\\).\n\nModellen innehåller nu fyra olika varianser, \\(\\sigma^2_A\\), \\(\\sigma^2_B\\), \\(\\sigma^2_{AB}\\) och \\(\\sigma^2\\) som tillsammans bildar den totala variansen av \\(Y\\).\n\n16.3.1 Inferens\nVi beräknar kvadratsummor på samma sätt som i fallet med en tvåvägs-ANOVA med två fixa faktorer. Däremot ser väntevärdena för kvadratsummorna annorlunda ut och påverkar hur testvariabeln beräknas för respektive faktor.\nPå samma sätt som i Kapitel 14 kommer inferens inte längre fokusera på de enskilda lutningsparametrarna utan istället undersöka variansen av respektive komponent. Till exempel ett test för signifikanta interaktionseffekter undersöker \\(H_0: \\sigma^2_{AB} = 0\\) mot \\(H_a: \\sigma_{AB}^2 &gt; 0\\).\nTestvariabeln utgår från följande väntevärden av medelkvadratsummor: \\[\n\\begin{aligned}\n    E[MSE] &= \\sigma^2 \\\\\n    E[MSAB] &= \\sigma^2 + n_{ij} \\sigma^2_{AB} \\\\\n    E[MSA] &= \\sigma^2 + n_{ij} \\sigma^2_{AB} + B \\cdot n_{ij} \\sigma^2_A\\\\\n    E[MSB] &= \\sigma^2 + n_{ij} \\sigma^2_{AB} + A \\cdot n_{ij} \\sigma^2_B\n\\end{aligned}\n\\] där \\(n_{ij}\\) är antalet i respektive cell vilket i en balanserad modell är samma värde för alla celler, \\(n_{ij} = \\frac{n}{A\\cdot B}\\).\n\n\n\n\n\n\nViktigt\n\n\n\nFör en obalanserad modell är dessa väntevärden mycket mer komplicerade eftersom varje cell ger en viktad effekt på variansen givet sin storlek.\n\n\nTestvariablerna kan nu skapas genom att ställa upp en kvot av två medelkvadratsummor som är lika om \\(H_0\\) är sann och större än 1 om \\(H_a\\) är sann. För interaktionen innebär det:\n\\[\n\\begin{aligned}\n    F_{test} = \\frac{MSAB}{MSE} = \\frac{\\sigma^2 + n_{ij} \\sigma^2_{AB}}{\\sigma^2}\n\\end{aligned}\n\\]\nTestvariabeln följer F-fördelningen med täljarens och nämnarens frihetsgrader.\nDet som är speciellt med slumpmässiga faktorer är hur vi undersöker de huvudsakliga faktoreffekterna för faktor A och B. Hypoteser för dessa komponenter fokuserar enbart på \\(\\sigma^2_A\\) eller \\(\\sigma_B^2\\) respektive och då räcker det inte att jämföra MSA med MSE som vi gör i en fix modell.\n\\[\n\\begin{aligned}\n  F_{test} = \\frac{MSA}{MSE} = \\frac{\\sigma^2 + n_{ij} \\sigma^2_{AB} + B \\cdot n_{ij} \\sigma^2_A}{\\sigma^2}\n\\end{aligned}\n\\] Med den “vanliga” testvariabeln skulle vi inte kunna särskilja om variansen från faktor A eller interaktionen leder till att \\(H_0\\) förkastas. Istället behöver vi jämföra med MSAB i nämnaren:\n\\[\n\\begin{aligned}\n  F_{test} = \\frac{MSA}{MSAB} = \\frac{\\sigma^2 + n_{ij} \\sigma^2_{AB} + B \\cdot n_{ij} \\sigma^2_A}{\\sigma^2 + n_{ij} \\sigma^2_{AB}}\n\\end{aligned}\n\\]\nNär vi använder R för att anpassa modellen och skapa ANOVA-tabeller kan vi inte läsa av tabellens F-test direkt då R inte vet om att vi har slumpmässiga faktorer.\n\n\n16.3.2 Exempel\nEn biolog vill undersöka om kackerlackor växer snabbare i varma och fuktiga miljöer. 27 identiska kackerlackor delas upp på nio olika kombinationer av temperatur och luftfuktighet. Det är inte just dessa temperaturer och luftfuktigheter som är av intresse, dessa olika kombinationer har blivit slumpmässigt valda av alla möjliga kombinatoner av luftfuktigheter och temperaturer. Kackerlackorna får vara i de olika förhållandena i två veckor, och efter dessa två veckor observeras deras längdökning i millimeter. Datamaterialet finns tillgängligt här.\nModellen anpassas på samma sätt som tidigare men vi behöver hålla koll på vad för värden som vi sedan tolkar.\n\n\n\n\n\n\nTips\n\n\n\nMan kan i lm ange hur vi vill att kvalitativa variabler ska kodas istället för att spara kodningen i datamaterialet. Vi kan i argumentet contrasts ange en namngiven lista med faktorer och vilken form av contr.X som ska användas.\nFör effektkodning anger vi contr.sum.\n\n\n\n\nVisa kod\nmodel &lt;- lm(\n  length_increase ~ humidity * temperature,\n    data = roach,\n    # Faktoreffektkodar faktorerna enbart för modellanpassningen\n    contrasts = \n      list(\n        humidity = \"contr.sum\",\n        temperature = \"contr.sum\"\n      )\n  )\n\nanova(model) %&gt;% \n  kable(digits = 3, caption = \"Modellens felaktiga ANOVA-tabell.\")\n\n\n\nModellens felaktiga ANOVA-tabell.\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nhumidity\n2\n1304.667\n652.333\n244.625\n0.000\n\n\ntemperature\n2\n356.222\n178.111\n66.792\n0.000\n\n\nhumidity:temperature\n4\n11.111\n2.778\n1.042\n0.413\n\n\nResiduals\n18\n48.000\n2.667\n\n\n\n\n\n\n\nTabellen visar endast ett korrekt test, det för interaktionseffekten, och vi behöver själv beräkna det korrekta testet för de huvudsakliga faktorerna\n\n# Skapar en korrigerad ANOVA-tabell utifrån en skattad tvåvägs-ANOVAmodell med två slumpmässiga faktorer\nmainEffectCorrection &lt;- function(model){\n  anovaTabell &lt;- anova(model)\n  \n  # Testvariabel för faktor A (MSA / MSAB)\n  anovaTabell[1,4] &lt;- anovaTabell[1,3] / anovaTabell[3,3]\n  \n  # Testvariabel för faktor B (MSB / MSAB)\n  anovaTabell[2,4] &lt;- anovaTabell[2,3] / anovaTabell[3,3]\n  \n  # Beräknar nya p-värden\n  anovaTabell[1:2,5] &lt;- \n    pf(\n      q = anovaTabell[1:2, 4], \n      df1 = anovaTabell[1:2,1], \n      df2 = anovaTabell[3,1], \n      lower.tail = FALSE\n    )\n  \n  return(anovaTabell)\n}\n\nmainEffectCorrection(model) %&gt;% \n  kable(digits = 3, caption = \"Modellens korrigerade ANOVA-tabell.\")\n\n\nModellens korrigerade ANOVA-tabell.\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nhumidity\n2\n1304.667\n652.333\n234.840\n0.000\n\n\ntemperature\n2\n356.222\n178.111\n64.120\n0.001\n\n\nhumidity:temperature\n4\n11.111\n2.778\n1.042\n0.413\n\n\nResiduals\n18\n48.000\n2.667\n\n\n\n\n\n\n\nDen korrigerade tabellen visar att interaktionen inte har någon signifikant effekt (p-värde = 0.413) medan de två huvudsakliga faktorerna har båda en signifikant effekt på mätvariabeln (p-värde &lt; 0.001 och 0.001 respektive).\nMed slumpmässiga faktorer är vi inte intresserade av att undersöka faktornivåerna vidare med multipla jämförelser eftersom de endast är ett slumpmässigt urval av alla nivåer vi vill dra slutsatser om. Däremot kan det vara av intresse att undersöka respektive varians ytterligare.\n\n\n16.3.3 Varianskomponenter\nEn tvåvägs-ANOVA med interaktion består av fyra stycken olika varianser där den totala variansen av Y, \\(\\sigma^2_Y\\) delas upp i dess mindre beståndsdelar. \\[\n\\begin{aligned}\n  Y &\\sim N(\\mu_{Y|\\mathbf{X}}, \\sigma^2_Y)\\\\\n  Y &\\sim N(\\mu_{Y|\\mathbf{X}}, \\sigma^2_A + \\sigma^2_B + \\sigma^2_{AB} + \\sigma^2)\n\\end{aligned}\n\\] Vi nu intresserade av att skatta varianserna för respektive komponent, istället för multipla jämförelser, för att få en indikation på hur stor del av den totala variansen (och hur stora skillnader vi kan förvänta oss bland valda nivåer av en faktor). Återigen används väntevärden för medelkvadratsummorna som grund för våra omskrivningar till skattningarna av variansen.\n\n\nVisa kod\n# Sparar ner ANOVA-tabellen\nanovaTabell &lt;- anova(model)\n\n# Plockar ut MSx från tabellen\nMSA &lt;- anovaTabell$`Mean Sq`[1]\nMSB &lt;- anovaTabell$`Mean Sq`[2]\nMSAB &lt;- anovaTabell$`Mean Sq`[3]\nMSE &lt;- anovaTabell$`Mean Sq`[4]\n\n# Sparar antalet nivåer för varje faktor\nA &lt;- anovaTabell$Df[1] + 1\nB &lt;- anovaTabell$Df[2] + 1\n\n# Sparar antalet observationer per cell \nn &lt;- (sum(anovaTabell$Df) + 1) / (A * B)\n\n# Beräknar variansskattningarna\nsigmaEst &lt;- MSE\n\nsigmaAEst &lt;- (MSA - MSAB) / (B*n)\nsigmaBEst &lt;- (MSB - MSAB) / (A*n)\nsigmaABEst &lt;- (MSAB - MSE) / n\n\n# Sammanställer skattningarna och presenterar som en tabell\ntibble(\n    Parameter = \n      c(\"$\\\\sigma^2_A$\",\"$\\\\sigma^2_B$\",\"$\\\\sigma^2_{AB}$\", \"$\\\\sigma^2$\"),\n    Skattning =\n      c(sigmaAEst,sigmaBEst,sigmaABEst, sigmaEst)\n  ) %&gt;% \n  kable(digits = 3)\n\n\n\n\n\nParameter\nSkattning\n\n\n\n\n\\(\\sigma^2_A\\)\n72.173\n\n\n\\(\\sigma^2_B\\)\n19.481\n\n\n\\(\\sigma^2_{AB}\\)\n0.037\n\n\n\\(\\sigma^2\\)\n2.667\n\n\n\n\n\nLikt den korrigerade ANOVA-tabellen visar dessa varianser att interaktionen är den minsta effekten av alla modellens komponenter. De skattade varianserna visar på att humidity (Faktor A) verkar vara den största källan till variation jämfört med temperature men detta bör säkerställas med lämpliga intervallskattningar1.\n\n\n16.3.3.1 Skatta varianser direkt i R\nAtt skatta varianserna för varje komponent som vi gjort tidigare är krångligt. Istället kan vi använda paketet lme4. Paketet är främst avsedd för mer komplicerade modeller men vi kan se våra ‘random effekt’-modeller som vi tittat på i denna övning som enkla tillämpningar.\nFunktionen lmer skattar en linjär mix-effekt modell, där vi kan styra vilka komponenter vi anser vara fixa och vilka vi anser vara slumpmässiga. I de tidigare modellerna från detta kapitel är alla komponenter slumpmässiga och det blir då en ren slumpmässig modell. För att kunna lägga till slumpmässiga effekter i modellen behöver vi omformulera modellens formel något. En slumpmässig effekt skapas via (1 | faktor) istället för bara faktor. Tvåvägs-ANOVAmodellen skrivs då som följer:\n\n\nVisa kod\nmodel &lt;- \n  lmer(\n    length_increase ~ \n      (1 | humidity) + \n      (1 | temperature) + \n      (1 | humidity:temperature), \n    data = roach\n  )\n\n\nDetta modellobjekt har inte lika struktur som objekt från lm eller aov vilket innebär att vi behöver hantera resultatet på ett annorlunda sätt. Till exempel kommer summary() visa två olika grupper av utskrifter än vad vi är vana vid.\n\n\nVisa kod\nsummary(model)\n\n\nLinear mixed model fit by REML ['lmerMod']\nFormula: \nlength_increase ~ (1 | humidity) + (1 | temperature) + (1 | humidity:temperature)\n   Data: roach\n\nREML criterion at convergence: 122.1\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-2.0519 -0.4454 -0.2116  0.4127  2.6173 \n\nRandom effects:\n Groups               Name        Variance Std.Dev.\n humidity:temperature (Intercept)  0.03704 0.1925  \n temperature          (Intercept) 19.48156 4.4138  \n humidity             (Intercept) 72.17450 8.4956  \n Residual                          2.66666 1.6330  \nNumber of obs: 27, groups:  \nhumidity:temperature, 9; temperature, 3; humidity, 3\n\nFixed effects:\n            Estimate Std. Error t value\n(Intercept)   14.667      5.537   2.649\n\n\nUtskriften delas upp i Random effects och Fixed effects med olika tabellstrukturer. Vår modell som anpassas är fortfarande Ekvation 16.2 där vi anser \\(\\gamma_{000}\\) vara en fix effekt, ett fixt intercept, och de andra komponenterna vara slumpmässiga effekter. Eftersom vi inte är intresserade av exakta parameterskattningar för de slumpmässiga effekterna, de är ju bara ett slumpmässigt urval av nivåer från hela faktorn, visas inte dessa i utskriften till skillnad från det fixa interceptet (se Estimate). Istället fokuserar de slumpmässiga effekterna på variansen av varje komponent, det som vi också fokuserat på tidigare i kapitlet.\nVi kan plocka ut dessa varianser i en separat tabell genom:\n\n\nVisa kod\nsummary(model) %&gt;% \n  # Tar ut varianskomponenterna\n  .$varcor %&gt;% \n  # Konverterar till en data.frame för kable\n  as.data.frame() %&gt;% \n  # Väljer ut relevanta delar av konverterade data.frame och byter namn\n  select(\n    Källa = grp,\n    Varians = vcov\n  ) %&gt;% \n  kable(\n    caption = \"Skattade varianskomponenter\", \n    digits = 3\n  ) \n\n\n\nSkattade varianskomponenter\n\n\nKälla\nVarians\n\n\n\n\nhumidity:temperature\n0.037\n\n\ntemperature\n19.482\n\n\nhumidity\n72.175\n\n\nResidual\n2.667\n\n\n\n\n\nVi kan se att denna tabell ser likadan ut som den tabell som skapades utifrån beräkningar från medelkvadratsummorna. Det är endast några få skillnader i tusendelen vilket orsakas av hur funktionen skattar dessa varianser. Istället för att använda medelkvadratsummorna, som endast går att använda när modellen använder sig av kategoriska variabler, använder sig lmer av en variant av maximum likelihood för att optimera parametrarna. Detta medför att funktionen kan anpassa betydligt mer komplexa modeller än en random effekt ANOVA.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html#obalanserad-tvåvägs-anova",
    "href": "02-variance/03-twoway-anova.html#obalanserad-tvåvägs-anova",
    "title": "16  Tvåvägs-ANOVA",
    "section": "16.4 Obalanserad tvåvägs-ANOVA",
    "text": "16.4 Obalanserad tvåvägs-ANOVA\nAntagandet om att experimentet undersöker lika många observationer i varje kombination av behandlingar är kanske inte alltid så rimligt. ANOVA-modeller går att tillämpa även på observationsstudier där det i de allra flesta fallen inte går att kontrollera att undersökningen blir balanserad. Även i experimentella studier kan observationer som antas medverka försvinna av olika anledningar vilket resulterar i ett obalanserat experiment.\nKonsekvensen av att analysera en obalanserad studie är att vi måste vara tydliga med vilken typ av SS som används då de inte kommer visa samma värden. Vanligast är att vi vill använda typ II eller III SS för att kunna genomföra lämplig inferens för de olika faktorerna.\nAnta att vi i en studie gett samma koffeindos till 18 personer där två faktorer uppmättes, ifall kaffet blandades med mjölk och vilken form av socker (riktig, artificiellt, ingen) det innehöll, och hur mycket personen i fråga “babblade” efter att ha druckit kaffet. Enheten och vad denna mätvariabel faktiskt betyder är inte viktig men vi kan anta att högre värden kopplas till en mer pratglad person. Datamaterialet finns att laddas ner här (Navarro (2018)).\n\n\nVisa kod\n# Beräknar cellmedelvärden\nmeans &lt;- \n  coffee %&gt;% \n  group_by(milk, sugar) %&gt;% \n  summarize(\n    mean = mean(babble)\n  )\n\n# Visar respektive cellmedelvärde\nggplot(coffee) + \n  aes(x = sugar, y = babble, group = milk, color = milk) + \n  geom_point(alpha = 0.5) + theme_bw() + \n  scale_color_manual(\"Mjölk\", values = c(\"steelblue\", \"#d9230f\")) + \n  geom_line(\n    data = means,\n    aes(y = mean), \n    linewidth = 1.2\n  ) + \n  labs(x = \"Socker\", y = \"Babblande\")\n\n\n\n\n\nInteraktionsdiagram av babblande uppdelat på två faktorer\n\n\n\n\nI interaktionsdiagrammet ser vi antydan till en interaktion, men vi ser också att antalet observationer för varje kombination av nivåer inte är lika, studien är obalanserad. Vi har inte kunnat kontrollera att lika många tar mjölk till kaffet och använder sig av samma sorts socker.\n\n\nVisa kod\nmodel &lt;- lm(babble ~ milk*sugar, data = coffee)\n\nanova(model) %&gt;% \n  kable(digits = 3, caption = \"Modellen ANOVA-tabell med typ I kvadratsummor.\")\n\n\n\nModellen ANOVA-tabell med typ I kvadratsummor.\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nmilk\n1\n1.444\n1.444\n5.479\n0.037\n\n\nsugar\n2\n3.070\n1.535\n5.824\n0.017\n\n\nmilk:sugar\n2\n5.944\n2.972\n11.277\n0.002\n\n\nResiduals\n12\n3.162\n0.264\n\n\n\n\n\n\n\nModellen anpassas på samma sätt som innan men ordningen av variablerna kommer nu påverka vad vi ser för värden på kvadratsummorna.\n\n\nVisa kod\nmodel2 &lt;- lm(babble ~ sugar*milk, data = coffee)\n\nanova(model2) %&gt;% \n  kable(digits = 3, caption = \"Annan ordning på modellens ANOVA-tabell med typ I kvadratsummor.\")\n\n\n\nAnnan ordning på modellens ANOVA-tabell med typ I kvadratsummor.\n\n\n\nDf\nSum Sq\nMean Sq\nF value\nPr(&gt;F)\n\n\n\n\nsugar\n2\n3.558\n1.779\n6.749\n0.011\n\n\nmilk\n1\n0.956\n0.956\n3.628\n0.081\n\n\nsugar:milk\n2\n5.944\n2.972\n11.277\n0.002\n\n\nResiduals\n12\n3.162\n0.264\n\n\n\n\n\n\n\nDen enda av faktorernas kvadratsummor som blivit samma är interaktionen eftersom den beräknas på samma sätt med de två olika modellordningarna och denna typ av kvadratsumma. Detta blir lite rörigt att hålla koll på om vi ska undersöka både interaktionseffekter och huvudsakliga effekter så istället kan vi titta på typ III SS.\nI paketet car får vi tillgång till funktionen Anova() (stort A) som ger oss möjligheten att ange vilken typ av SS som vi vill visa i ANOVA-tabellen.\n\n\nVisa kod\nAnova(model, type = 3) %&gt;% \n  kable(digits = 3, caption = \"Modellen ANOVA-tabell med typ III kvadratsummor.\")\n\n\n\nModellen ANOVA-tabell med typ III kvadratsummor.\n\n\n\nSum Sq\nDf\nF value\nPr(&gt;F)\n\n\n\n\n(Intercept)\n86.490\n1\n328.183\n0.000\n\n\nmilk\n1.763\n1\n6.691\n0.024\n\n\nsugar\n3.133\n2\n5.945\n0.016\n\n\nmilk:sugar\n5.944\n2\n11.277\n0.002\n\n\nResiduals\n3.162\n12\n\n\n\n\n\n\n\nANOVA-tabellen ser något annorlunda ut jämfört med vad vi är vana vid. Vi får en ny första rad (Intercept) som vi inte alls ska läsa av eller ta hänsyn till i vår analys, och vi saknar helt medelkvadratsummor. Dessa kan vi enkelt beräkna enligt \\(\\frac{SS}{df}\\) men det som vi kanske främst är intresserade av är testvariabeln och det tillhörande p-värdet. Alla dessa tester undersöker hur mycket ytterligare variation faktorn eller interaktionen bidrar med givet de andra faktorerna och interaktion redan inkluderad i modellen.\n\n16.4.1 Multipla jämförelser\nÄven för obalanserade modeller vill vi undersöka jämförelser mellan faktor- eller cellmedelvärden för att specifikt veta var skillnader råder.\n\n\nVisa kod\nmeans &lt;- emmeans(model, specs = ~milk*sugar)\n\ntukey &lt;- \n  pairs(means, adjust = \"tukey\") \n\ntukey %&gt;% \n  as_tibble() %&gt;% \n  arrange(abs(estimate) %&gt;% desc()) %&gt;% \n  kable(digits = 3, caption = \"Parvisa jämförelser av cellmedelvärden med Tukey familjekonfidens\")\n\n\n\nParvisa jämförelser av cellmedelvärden med Tukey familjekonfidens\n\n\ncontrast\nestimate\nSE\ndf\nt.ratio\np.value\n\n\n\n\nyes none - no real\n-2.175\n0.392\n12\n-5.547\n0.001\n\n\nyes fake - yes none\n2.100\n0.469\n12\n4.481\n0.008\n\n\nno none - yes none\n1.850\n0.469\n12\n3.948\n0.019\n\n\nyes none - yes real\n-1.400\n0.419\n12\n-3.340\n0.052\n\n\nno fake - no real\n-1.225\n0.363\n12\n-3.375\n0.049\n\n\nno fake - yes fake\n-1.150\n0.445\n12\n-2.587\n0.174\n\n\nno fake - yes none\n0.950\n0.392\n12\n2.423\n0.222\n\n\nno fake - no none\n-0.900\n0.445\n12\n-2.024\n0.384\n\n\nno real - yes real\n0.775\n0.392\n12\n1.977\n0.407\n\n\nyes fake - yes real\n0.700\n0.469\n12\n1.494\n0.674\n\n\nno fake - yes real\n-0.450\n0.392\n12\n-1.148\n0.852\n\n\nno none - yes real\n0.450\n0.469\n12\n0.960\n0.922\n\n\nno none - no real\n-0.325\n0.445\n12\n-0.731\n0.974\n\n\nyes fake - no none\n0.250\n0.513\n12\n0.487\n0.996\n\n\nyes fake - no real\n-0.075\n0.445\n12\n-0.169\n1.000\n\n\n\n\n\nTill skillnad från Tabell 16.2 ser vi att varje medelfel är olika på grund av att vi har olika antal observationer i varje cell. Argumentet adjust kan ändras till bonferroni eller scheffe beroende på vilken familjekonfidens vi vill beräkna. Liknande funktioner för kontraster som vi tidigare använt är också användbara här.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html#övningsuppgifter",
    "href": "02-variance/03-twoway-anova.html#övningsuppgifter",
    "title": "16  Tvåvägs-ANOVA",
    "section": "16.5 Övningsuppgifter",
    "text": "16.5 Övningsuppgifter\nAnta en studie där forskare vill undersöka variationen i bränsleeffektivitet (mätt i miles per gallon) för olika bilar som körs av olika förare. De två faktorerna i denna studie är:\n\nFörare: Fyra slumpmässigt utvalda förare (Faktor A)\nBilar: Fem slumpmässigt utvalda bilar av samma modell (Faktor B)\n\nVarje förare kör varje bil två gånger på samma testbana. Datamaterialet finns att hämta här\n\nSkriv upp modellen som anpassas och beskriv alla komponenter.\nTesta om det finns interaktionseffekt med 5% siginifikans.\nTesta på 5 procents signifikans om förare och/eller bil har en effekt på bränsleförbrukningen.\nSkatta variansen för förare med ett 90% approximativt Satterthwaites konfidensintervall. Visa beräkningarna och tolka intervallet.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html#referenser",
    "href": "02-variance/03-twoway-anova.html#referenser",
    "title": "16  Tvåvägs-ANOVA",
    "section": "Referenser",
    "text": "Referenser\n\n\n\n\nNavarro, Danielle. 2018. Learning Statistics with R: A tutorial for psychology students and other beginners. Danielle Navarro. https://learningstatisticswithr.com/.",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  },
  {
    "objectID": "02-variance/03-twoway-anova.html#footnotes",
    "href": "02-variance/03-twoway-anova.html#footnotes",
    "title": "16  Tvåvägs-ANOVA",
    "section": "",
    "text": "Se teorikompendiets formler↩︎",
    "crumbs": [
      "Programmering i R",
      "**DEL III - Variansanalys**",
      "<span class='chapter-number'>16</span>  <span class='chapter-title'>Tvåvägs-ANOVA</span>"
    ]
  }
]